{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "877c2677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c059e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96739d01",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0397420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os.path as op\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8cc09ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model,Sequential,load_model\n",
    "from keras.layers import Input, Embedding\n",
    "from keras.layers import Dense, Bidirectional\n",
    "from keras.layers.recurrent import LSTM\n",
    "import keras.metrics as metrics\n",
    "import itertools\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from decimal import Decimal\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv1D,MaxPooling1D,Flatten,Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f9474e",
   "metadata": {},
   "source": [
    "# Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7450b0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.50000e+02 1.90401e+05 7.25000e+02 2.75500e+01 8.03900e+01]\n",
      " [1.50000e+02 1.90401e+05 8.25000e+02 2.75600e+01 8.03300e+01]\n",
      " [1.50000e+02 1.90401e+05 9.25000e+02 2.75800e+01 8.02400e+01]\n",
      " ...\n",
      " [6.10000e+01 1.91020e+05 1.94532e+05 2.93700e+01 7.52100e+01]\n",
      " [6.10000e+01 1.91020e+05 1.94632e+05 2.93500e+01 7.52700e+01]\n",
      " [6.10000e+01 1.91020e+05 1.94732e+05 2.93400e+01 7.53000e+01]]\n",
      "[[ 28.     3.   -52.   ...  16.97  19.63  20.06]\n",
      " [ 28.    15.   -53.   ...  16.63  19.57  23.06]\n",
      " [ 31.    16.   -55.   ...  17.24  19.98  20.24]\n",
      " ...\n",
      " [ 76.    12.   -76.   ...   3.47   3.95   4.35]\n",
      " [ 75.    13.   -76.   ...   3.88   4.33   4.42]\n",
      " [ 76.    12.   -75.   ...   3.46   4.07   4.28]]\n"
     ]
    }
   ],
   "source": [
    "A1=np.empty((0,5),dtype='float32')\n",
    "U1=np.empty((0,7),dtype='float32')\n",
    "node=['150','149','147','144','142','140','136','61']\n",
    "mon=['Apr','Mar','Aug','Jun','Jul','Sep','May','Oct']\n",
    "for j in node:\n",
    "  for i in mon:\n",
    "    inp= pd.read_csv('data_gkv/AT510_Node_'+str(j)+'_'+str(i)+'19_OutputFile.csv',usecols=[1,2,3,15,16])\n",
    "    out= pd.read_csv('data_gkv/AT510_Node_'+str(j)+'_'+str(i)+'19_OutputFile.csv',usecols=[5,6,7,8,17,18,19])\n",
    "    \n",
    "    inp=np.array(inp,dtype='float32')\n",
    "    out=np.array(out,dtype='float32')\n",
    "    \n",
    "    A1=np.append(A1, inp, axis=0)\n",
    "    U1=np.append(U1, out, axis=0)\n",
    "\n",
    "print(A1)\n",
    "print(U1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ca5e86",
   "metadata": {},
   "source": [
    "# Min Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41ae9a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "scaler_obj=MinMaxScaler()\n",
    "X1=scaler_obj.fit_transform(A1)\n",
    "Y1=scaler_obj.fit_transform(U1)\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "X1=X1[:,np.newaxis,:]\n",
    "Y1=Y1[:,np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da37491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1edf627",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d05d8053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 7)                 364       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7)                 28        \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 448\n",
      "Trainable params: 434\n",
      "Non-trainable params: 14\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(keras.Input(shape=(1,5)))\n",
    "model1.add(tf.keras.layers.LSTM(7,activation=\"tanh\",use_bias=True,kernel_initializer=\"glorot_uniform\",bias_initializer=\"zeros\"))\n",
    "model1.add(Dense(7))\n",
    "model1.add(keras.layers.BatchNormalization(axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,\n",
    "                                beta_initializer=\"zeros\",gamma_initializer=\"ones\",\n",
    "                                moving_mean_initializer=\"zeros\",moving_variance_initializer=\"ones\",trainable=True))\n",
    "model1.add(keras.layers.ReLU())\n",
    "model1.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5), loss='binary_crossentropy',metrics=['accuracy','mse','mae',rmse])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb37916d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "571/571 [==============================] - 252s 439ms/step - loss: 0.6914 - accuracy: 0.0134 - mse: 0.0722 - mae: 0.1448 - rmse: 0.2206 - val_loss: 0.2356 - val_accuracy: 0.0060 - val_mse: 0.0201 - val_mae: 0.0750 - val_rmse: 0.1165\n",
      "Epoch 2/50\n",
      "571/571 [==============================] - 252s 441ms/step - loss: 0.6704 - accuracy: 0.0099 - mse: 0.0658 - mae: 0.1312 - rmse: 0.2070 - val_loss: 0.6566 - val_accuracy: 0.0072 - val_mse: 0.0621 - val_mae: 0.1221 - val_rmse: 0.1962\n",
      "Epoch 3/50\n",
      "571/571 [==============================] - 250s 438ms/step - loss: 0.6523 - accuracy: 0.0066 - mse: 0.0613 - mae: 0.1185 - rmse: 0.1950 - val_loss: 0.6402 - val_accuracy: 0.0059 - val_mse: 0.0587 - val_mae: 0.1102 - val_rmse: 0.1850\n",
      "Epoch 4/50\n",
      "571/571 [==============================] - 250s 437ms/step - loss: 0.6366 - accuracy: 0.0042 - mse: 0.0582 - mae: 0.1065 - rmse: 0.1846 - val_loss: 0.6267 - val_accuracy: 0.0038 - val_mse: 0.0563 - val_mae: 0.0994 - val_rmse: 0.1760\n",
      "Epoch 5/50\n",
      "571/571 [==============================] - 250s 438ms/step - loss: 0.6240 - accuracy: 0.0026 - mse: 0.0560 - mae: 0.0959 - rmse: 0.1757 - val_loss: 0.6165 - val_accuracy: 0.0028 - val_mse: 0.0543 - val_mae: 0.0902 - val_rmse: 0.1683\n",
      "Epoch 6/50\n",
      "571/571 [==============================] - 250s 438ms/step - loss: 0.6148 - accuracy: 0.0021 - mse: 0.0541 - mae: 0.0873 - rmse: 0.1682 - val_loss: 0.6087 - val_accuracy: 0.0034 - val_mse: 0.0529 - val_mae: 0.0830 - val_rmse: 0.1628\n",
      "Epoch 7/50\n",
      "571/571 [==============================] - 252s 441ms/step - loss: 0.6077 - accuracy: 0.0023 - mse: 0.0528 - mae: 0.0801 - rmse: 0.1620 - val_loss: 0.6027 - val_accuracy: 0.0031 - val_mse: 0.0519 - val_mae: 0.0764 - val_rmse: 0.1569\n",
      "Epoch 8/50\n",
      "571/571 [==============================] - 249s 437ms/step - loss: 0.6027 - accuracy: 0.0030 - mse: 0.0522 - mae: 0.0750 - rmse: 0.1565 - val_loss: 0.5982 - val_accuracy: 0.0049 - val_mse: 0.0513 - val_mae: 0.0719 - val_rmse: 0.1508\n",
      "Epoch 9/50\n",
      "571/571 [==============================] - 249s 436ms/step - loss: 0.5992 - accuracy: 0.0043 - mse: 0.0516 - mae: 0.0716 - rmse: 0.1508 - val_loss: 0.5947 - val_accuracy: 0.0067 - val_mse: 0.0509 - val_mae: 0.0682 - val_rmse: 0.1447\n",
      "Epoch 10/50\n",
      "571/571 [==============================] - 252s 441ms/step - loss: 0.5960 - accuracy: 0.0063 - mse: 0.0511 - mae: 0.0685 - rmse: 0.1455 - val_loss: 0.5921 - val_accuracy: 0.0090 - val_mse: 0.0504 - val_mae: 0.0655 - val_rmse: 0.1401\n",
      "Epoch 11/50\n",
      "571/571 [==============================] - 251s 440ms/step - loss: 0.5934 - accuracy: 0.0093 - mse: 0.0506 - mae: 0.0659 - rmse: 0.1409 - val_loss: 0.5903 - val_accuracy: 0.0132 - val_mse: 0.0501 - val_mae: 0.0644 - val_rmse: 0.1380\n",
      "Epoch 12/50\n",
      "571/571 [==============================] - 251s 440ms/step - loss: 0.5918 - accuracy: 0.0121 - mse: 0.0503 - mae: 0.0640 - rmse: 0.1377 - val_loss: 0.5895 - val_accuracy: 0.0139 - val_mse: 0.0501 - val_mae: 0.0637 - val_rmse: 0.1370\n",
      "Epoch 13/50\n",
      "571/571 [==============================] - 252s 441ms/step - loss: 0.5909 - accuracy: 0.0143 - mse: 0.0501 - mae: 0.0630 - rmse: 0.1360 - val_loss: 0.5888 - val_accuracy: 0.0134 - val_mse: 0.0500 - val_mae: 0.0629 - val_rmse: 0.1357\n",
      "Epoch 14/50\n",
      "571/571 [==============================] - 250s 437ms/step - loss: 0.5902 - accuracy: 0.0157 - mse: 0.0501 - mae: 0.0622 - rmse: 0.1348 - val_loss: 0.5880 - val_accuracy: 0.0156 - val_mse: 0.0501 - val_mae: 0.0622 - val_rmse: 0.1346\n",
      "Epoch 15/50\n",
      "571/571 [==============================] - 250s 437ms/step - loss: 0.5895 - accuracy: 0.0165 - mse: 0.0501 - mae: 0.0616 - rmse: 0.1339 - val_loss: 0.5875 - val_accuracy: 0.0169 - val_mse: 0.0498 - val_mae: 0.0612 - val_rmse: 0.1329\n",
      "Epoch 16/50\n",
      "571/571 [==============================] - 252s 442ms/step - loss: 0.5889 - accuracy: 0.0169 - mse: 0.0502 - mae: 0.0610 - rmse: 0.1329 - val_loss: 0.5868 - val_accuracy: 0.0161 - val_mse: 0.0501 - val_mae: 0.0607 - val_rmse: 0.1323\n",
      "Epoch 17/50\n",
      "571/571 [==============================] - 252s 441ms/step - loss: 0.5882 - accuracy: 0.0171 - mse: 0.0503 - mae: 0.0605 - rmse: 0.1322 - val_loss: 0.5859 - val_accuracy: 0.0168 - val_mse: 0.0502 - val_mae: 0.0607 - val_rmse: 0.1323\n",
      "Epoch 18/50\n",
      "571/571 [==============================] - 254s 445ms/step - loss: 0.5875 - accuracy: 0.0178 - mse: 0.0504 - mae: 0.0600 - rmse: 0.1315 - val_loss: 0.5854 - val_accuracy: 0.0191 - val_mse: 0.0502 - val_mae: 0.0600 - val_rmse: 0.1312\n",
      "Epoch 19/50\n",
      "571/571 [==============================] - 250s 438ms/step - loss: 0.5869 - accuracy: 0.0180 - mse: 0.0505 - mae: 0.0595 - rmse: 0.1308 - val_loss: 0.5848 - val_accuracy: 0.0182 - val_mse: 0.0504 - val_mae: 0.0595 - val_rmse: 0.1305\n",
      "Epoch 20/50\n",
      "571/571 [==============================] - 250s 438ms/step - loss: 0.5863 - accuracy: 0.0187 - mse: 0.0506 - mae: 0.0591 - rmse: 0.1302 - val_loss: 0.5841 - val_accuracy: 0.0179 - val_mse: 0.0505 - val_mae: 0.0590 - val_rmse: 0.1298\n",
      "Epoch 21/50\n",
      "571/571 [==============================] - 250s 438ms/step - loss: 0.5856 - accuracy: 0.0191 - mse: 0.0507 - mae: 0.0588 - rmse: 0.1298 - val_loss: 0.5839 - val_accuracy: 0.0184 - val_mse: 0.0507 - val_mae: 0.0584 - val_rmse: 0.1291\n",
      "Epoch 22/50\n",
      "571/571 [==============================] - 250s 438ms/step - loss: 0.5850 - accuracy: 0.0189 - mse: 0.0509 - mae: 0.0583 - rmse: 0.1291 - val_loss: 0.5829 - val_accuracy: 0.0188 - val_mse: 0.0510 - val_mae: 0.0582 - val_rmse: 0.1288\n",
      "Epoch 23/50\n",
      "571/571 [==============================] - 252s 442ms/step - loss: 0.5844 - accuracy: 0.0189 - mse: 0.0511 - mae: 0.0577 - rmse: 0.1285 - val_loss: 0.5823 - val_accuracy: 0.0163 - val_mse: 0.0510 - val_mae: 0.0578 - val_rmse: 0.1284\n",
      "Epoch 24/50\n",
      "571/571 [==============================] - 252s 442ms/step - loss: 0.5837 - accuracy: 0.0180 - mse: 0.0513 - mae: 0.0576 - rmse: 0.1283 - val_loss: 0.5818 - val_accuracy: 0.0167 - val_mse: 0.0511 - val_mae: 0.0574 - val_rmse: 0.1279\n",
      "Epoch 25/50\n",
      "571/571 [==============================] - 252s 442ms/step - loss: 0.5832 - accuracy: 0.0178 - mse: 0.0515 - mae: 0.0572 - rmse: 0.1279 - val_loss: 0.5813 - val_accuracy: 0.0163 - val_mse: 0.0513 - val_mae: 0.0567 - val_rmse: 0.1271\n",
      "Epoch 26/50\n",
      "571/571 [==============================] - 254s 444ms/step - loss: 0.5826 - accuracy: 0.0178 - mse: 0.0516 - mae: 0.0569 - rmse: 0.1275 - val_loss: 0.5808 - val_accuracy: 0.0179 - val_mse: 0.0515 - val_mae: 0.0565 - val_rmse: 0.1267\n",
      "Epoch 27/50\n",
      "571/571 [==============================] - 249s 436ms/step - loss: 0.5821 - accuracy: 0.0178 - mse: 0.0519 - mae: 0.0564 - rmse: 0.1270 - val_loss: 0.5803 - val_accuracy: 0.0153 - val_mse: 0.0519 - val_mae: 0.0563 - val_rmse: 0.1267\n",
      "Epoch 28/50\n",
      "571/571 [==============================] - 249s 436ms/step - loss: 0.5816 - accuracy: 0.0175 - mse: 0.0521 - mae: 0.0560 - rmse: 0.1266 - val_loss: 0.5799 - val_accuracy: 0.0155 - val_mse: 0.0521 - val_mae: 0.0556 - val_rmse: 0.1260\n",
      "Epoch 29/50\n",
      "571/571 [==============================] - 249s 436ms/step - loss: 0.5811 - accuracy: 0.0173 - mse: 0.0523 - mae: 0.0556 - rmse: 0.1261 - val_loss: 0.5794 - val_accuracy: 0.0161 - val_mse: 0.0522 - val_mae: 0.0551 - val_rmse: 0.1253\n",
      "Epoch 30/50\n",
      "571/571 [==============================] - 249s 436ms/step - loss: 0.5806 - accuracy: 0.0174 - mse: 0.0526 - mae: 0.0551 - rmse: 0.1257 - val_loss: 0.5789 - val_accuracy: 0.0150 - val_mse: 0.0526 - val_mae: 0.0547 - val_rmse: 0.1252\n",
      "Epoch 31/50\n",
      "571/571 [==============================] - 250s 438ms/step - loss: 0.5801 - accuracy: 0.0170 - mse: 0.0528 - mae: 0.0548 - rmse: 0.1254 - val_loss: 0.5784 - val_accuracy: 0.0147 - val_mse: 0.0528 - val_mae: 0.0544 - val_rmse: 0.1249\n",
      "Epoch 32/50\n",
      "571/571 [==============================] - 248s 435ms/step - loss: 0.5796 - accuracy: 0.0169 - mse: 0.0530 - mae: 0.0544 - rmse: 0.1250 - val_loss: 0.5782 - val_accuracy: 0.0141 - val_mse: 0.0530 - val_mae: 0.0541 - val_rmse: 0.1246\n",
      "Epoch 33/50\n",
      "571/571 [==============================] - 249s 436ms/step - loss: 0.5792 - accuracy: 0.0165 - mse: 0.0532 - mae: 0.0541 - rmse: 0.1249 - val_loss: 0.5777 - val_accuracy: 0.0134 - val_mse: 0.0530 - val_mae: 0.0539 - val_rmse: 0.1244\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 248s 435ms/step - loss: 0.5789 - accuracy: 0.0162 - mse: 0.0534 - mae: 0.0538 - rmse: 0.1246 - val_loss: 0.5772 - val_accuracy: 0.0171 - val_mse: 0.0533 - val_mae: 0.0534 - val_rmse: 0.1240\n",
      "Epoch 35/50\n",
      "571/571 [==============================] - 248s 434ms/step - loss: 0.5785 - accuracy: 0.0161 - mse: 0.0536 - mae: 0.0535 - rmse: 0.1244 - val_loss: 0.5769 - val_accuracy: 0.0158 - val_mse: 0.0534 - val_mae: 0.0533 - val_rmse: 0.1239\n",
      "Epoch 36/50\n",
      "571/571 [==============================] - 248s 434ms/step - loss: 0.5782 - accuracy: 0.0161 - mse: 0.0537 - mae: 0.0532 - rmse: 0.1242 - val_loss: 0.5766 - val_accuracy: 0.0156 - val_mse: 0.0538 - val_mae: 0.0530 - val_rmse: 0.1239\n",
      "Epoch 37/50\n",
      "571/571 [==============================] - 248s 434ms/step - loss: 0.5780 - accuracy: 0.0165 - mse: 0.0539 - mae: 0.0529 - rmse: 0.1239 - val_loss: 0.5765 - val_accuracy: 0.0167 - val_mse: 0.0537 - val_mae: 0.0524 - val_rmse: 0.1232\n",
      "Epoch 38/50\n",
      "571/571 [==============================] - 248s 434ms/step - loss: 0.5777 - accuracy: 0.0167 - mse: 0.0540 - mae: 0.0527 - rmse: 0.1238 - val_loss: 0.5761 - val_accuracy: 0.0144 - val_mse: 0.0538 - val_mae: 0.0527 - val_rmse: 0.1236\n",
      "Epoch 39/50\n",
      "571/571 [==============================] - 249s 436ms/step - loss: 0.5775 - accuracy: 0.0165 - mse: 0.0541 - mae: 0.0526 - rmse: 0.1237 - val_loss: 0.5759 - val_accuracy: 0.0157 - val_mse: 0.0542 - val_mae: 0.0523 - val_rmse: 0.1235\n",
      "Epoch 40/50\n",
      "571/571 [==============================] - 249s 436ms/step - loss: 0.5773 - accuracy: 0.0174 - mse: 0.0542 - mae: 0.0523 - rmse: 0.1236 - val_loss: 0.5758 - val_accuracy: 0.0149 - val_mse: 0.0542 - val_mae: 0.0524 - val_rmse: 0.1235\n",
      "Epoch 41/50\n",
      "571/571 [==============================] - 249s 437ms/step - loss: 0.5771 - accuracy: 0.0175 - mse: 0.0543 - mae: 0.0522 - rmse: 0.1235 - val_loss: 0.5757 - val_accuracy: 0.0146 - val_mse: 0.0543 - val_mae: 0.0522 - val_rmse: 0.1234\n",
      "Epoch 42/50\n",
      "571/571 [==============================] - 249s 436ms/step - loss: 0.5770 - accuracy: 0.0180 - mse: 0.0543 - mae: 0.0521 - rmse: 0.1234 - val_loss: 0.5755 - val_accuracy: 0.0174 - val_mse: 0.0544 - val_mae: 0.0520 - val_rmse: 0.1233\n",
      "Epoch 43/50\n",
      "571/571 [==============================] - 249s 436ms/step - loss: 0.5768 - accuracy: 0.0186 - mse: 0.0544 - mae: 0.0519 - rmse: 0.1233 - val_loss: 0.5754 - val_accuracy: 0.0168 - val_mse: 0.0543 - val_mae: 0.0520 - val_rmse: 0.1231\n",
      "Epoch 44/50\n",
      "571/571 [==============================] - 248s 435ms/step - loss: 0.5767 - accuracy: 0.0189 - mse: 0.0544 - mae: 0.0518 - rmse: 0.1232 - val_loss: 0.5753 - val_accuracy: 0.0188 - val_mse: 0.0543 - val_mae: 0.0518 - val_rmse: 0.1229\n",
      "Epoch 45/50\n",
      "571/571 [==============================] - 249s 436ms/step - loss: 0.5766 - accuracy: 0.0198 - mse: 0.0544 - mae: 0.0517 - rmse: 0.1231 - val_loss: 0.5751 - val_accuracy: 0.0172 - val_mse: 0.0544 - val_mae: 0.0517 - val_rmse: 0.1230\n",
      "Epoch 46/50\n",
      "571/571 [==============================] - 249s 435ms/step - loss: 0.5764 - accuracy: 0.0207 - mse: 0.0544 - mae: 0.0516 - rmse: 0.1231 - val_loss: 0.5750 - val_accuracy: 0.0213 - val_mse: 0.0543 - val_mae: 0.0513 - val_rmse: 0.1227\n",
      "Epoch 47/50\n",
      "571/571 [==============================] - 249s 435ms/step - loss: 0.5763 - accuracy: 0.0218 - mse: 0.0545 - mae: 0.0515 - rmse: 0.1230 - val_loss: 0.5750 - val_accuracy: 0.0258 - val_mse: 0.0543 - val_mae: 0.0513 - val_rmse: 0.1226\n",
      "Epoch 48/50\n",
      "571/571 [==============================] - 249s 435ms/step - loss: 0.5762 - accuracy: 0.0225 - mse: 0.0545 - mae: 0.0514 - rmse: 0.1229 - val_loss: 0.5748 - val_accuracy: 0.0203 - val_mse: 0.0543 - val_mae: 0.0512 - val_rmse: 0.1226\n",
      "Epoch 49/50\n",
      "571/571 [==============================] - 248s 435ms/step - loss: 0.5761 - accuracy: 0.0244 - mse: 0.0545 - mae: 0.0513 - rmse: 0.1229 - val_loss: 0.5748 - val_accuracy: 0.0230 - val_mse: 0.0545 - val_mae: 0.0514 - val_rmse: 0.1228\n",
      "Epoch 50/50\n",
      "571/571 [==============================] - 249s 436ms/step - loss: 0.5761 - accuracy: 0.0253 - mse: 0.0545 - mae: 0.0512 - rmse: 0.1228 - val_loss: 0.5747 - val_accuracy: 0.0212 - val_mse: 0.0544 - val_mae: 0.0512 - val_rmse: 0.1227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.25, random_state=42)\n",
    "\n",
    "model_fit8 = model1.fit(x_train,y_train,batch_size=2048,epochs=50, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c03bc9",
   "metadata": {},
   "source": [
    "# Saving Model as File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "feb6fe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model1.to_json()\n",
    "with open(\"lstm.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model1.save_weights(\"lstm.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85c18be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "[0.05459023267030716, 0.02124212495982647, 0.05459020659327507, 0.05129491165280342, 0.12296319007873535, -2923.8349609375]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open('lstm.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"lstm.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "loaded_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='mse',metrics=['accuracy','mse','mae',rmse,coeff_determination])\n",
    "print(loaded_model.evaluate(x_train, y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75d6b3",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff6190cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-65982dcd2f74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train: %.3f, Test: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# summarize history for loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "_, train_acc = model1.evaluate(x_train, y_train, verbose=0)\n",
    "_, test_acc = model1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(model_fit8.history['loss'])\n",
    "plt.plot(model_fit8.history['val_loss'])\n",
    "plt.title('Model Loss',fontweight ='bold',fontsize = 15)\n",
    "plt.ylabel('Loss',fontweight ='bold',fontsize = 15)\n",
    "plt.xlabel('Epoch',fontweight ='bold',fontsize = 15)\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(model_fit8.history['accuracy'])\n",
    "plt.plot(model_fit8.history['val_accuracy'])\n",
    "plt.title('Model accuracy',fontweight ='bold',fontsize = 15)\n",
    "plt.ylabel('Accuracy',fontweight ='bold',fontsize = 15)\n",
    "plt.xlabel('Epoch',fontweight ='bold',fontsize = 15)\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265bcbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
