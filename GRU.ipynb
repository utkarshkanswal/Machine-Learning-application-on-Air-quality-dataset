{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os.path as op\n",
    "from csv import writer\n",
    "import math\n",
    "import cmath\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model,Sequential,load_model\n",
    "from keras.layers import Input, Embedding\n",
    "from keras.layers import Dense, Bidirectional\n",
    "from keras.layers.recurrent import LSTM\n",
    "import keras.metrics as metrics\n",
    "import itertools\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from decimal import Decimal\n",
    "from keras.layers import Conv1D,MaxPooling1D,Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.50000e+02 1.90401e+05 7.25000e+02 2.75500e+01 8.03900e+01]\n",
      " [1.50000e+02 1.90401e+05 8.25000e+02 2.75600e+01 8.03300e+01]\n",
      " [1.50000e+02 1.90401e+05 9.25000e+02 2.75800e+01 8.02400e+01]\n",
      " ...\n",
      " [6.10000e+01 1.91020e+05 1.94532e+05 2.93700e+01 7.52100e+01]\n",
      " [6.10000e+01 1.91020e+05 1.94632e+05 2.93500e+01 7.52700e+01]\n",
      " [6.10000e+01 1.91020e+05 1.94732e+05 2.93400e+01 7.53000e+01]]\n",
      "[[ 28.     3.   -52.   ...  16.97  19.63  20.06]\n",
      " [ 28.    15.   -53.   ...  16.63  19.57  23.06]\n",
      " [ 31.    16.   -55.   ...  17.24  19.98  20.24]\n",
      " ...\n",
      " [ 76.    12.   -76.   ...   3.47   3.95   4.35]\n",
      " [ 75.    13.   -76.   ...   3.88   4.33   4.42]\n",
      " [ 76.    12.   -75.   ...   3.46   4.07   4.28]]\n"
     ]
    }
   ],
   "source": [
    "A1=np.empty((0,5),dtype='float32')\n",
    "U1=np.empty((0,7),dtype='float32')\n",
    "node=['150','149','147','144','142','140','136','61']\n",
    "mon=['Apr','Mar','Aug','Jun','Jul','Sep','May','Oct']\n",
    "for j in node:\n",
    "  for i in mon:\n",
    "    inp= pd.read_csv('data_gkv/AT510_Node_'+str(j)+'_'+str(i)+'19_OutputFile.csv',usecols=[1,2,3,15,16])\n",
    "    out= pd.read_csv('data_gkv/AT510_Node_'+str(j)+'_'+str(i)+'19_OutputFile.csv',usecols=[5,6,7,8,17,18,19])\n",
    "    \n",
    "    inp=np.array(inp,dtype='float32')\n",
    "    out=np.array(out,dtype='float32')\n",
    "    \n",
    "    A1=np.append(A1, inp, axis=0)\n",
    "    U1=np.append(U1, out, axis=0)\n",
    "\n",
    "print(A1)\n",
    "print(U1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "scaler_obj=MinMaxScaler()\n",
    "X1=scaler_obj.fit_transform(A1)\n",
    "Y1=scaler_obj.fit_transform(U1)\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "X1=X1[:,np.newaxis,:]\n",
    "Y1=Y1[:,np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 14)                882       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 105       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7)                 28        \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 1,015\n",
      "Trainable params: 1,001\n",
      "Non-trainable params: 14\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(keras.Input(shape=(1,5)))\n",
    "model.add(tf.keras.layers.GRU(14,activation=\"relu\",use_bias=True,kernel_initializer=\"glorot_uniform\",bias_initializer=\"zeros\", \n",
    "                                kernel_regularizer=keras.regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                                bias_regularizer=keras.regularizers.l2(1e-4),\n",
    "                                activity_regularizer=keras.regularizers.l2(1e-5)))\n",
    "model.add(keras.layers.Dropout(.1))\n",
    "model.add(Dense(7))\n",
    "model.add(keras.layers.BatchNormalization(axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,\n",
    "                                beta_initializer=\"zeros\",gamma_initializer=\"ones\",\n",
    "                                moving_mean_initializer=\"zeros\",moving_variance_initializer=\"ones\",trainable=True))\n",
    "model.add(keras.layers.ReLU())\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),loss='mse',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "571/571 [==============================] - 124s 217ms/step - loss: 1.6267e-04 - accuracy: 0.9438 - val_loss: 1.6265e-04 - val_accuracy: 0.9439\n",
      "Epoch 2/300\n",
      "571/571 [==============================] - 207s 364ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6256e-04 - val_accuracy: 0.9439\n",
      "Epoch 3/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6253e-04 - val_accuracy: 0.9439\n",
      "Epoch 4/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6262e-04 - val_accuracy: 0.9439\n",
      "Epoch 5/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6261e-04 - val_accuracy: 0.9439\n",
      "Epoch 6/300\n",
      "571/571 [==============================] - 215s 377ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 7/300\n",
      "571/571 [==============================] - 215s 377ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6262e-04 - val_accuracy: 0.9439\n",
      "Epoch 8/300\n",
      "571/571 [==============================] - 215s 376ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 9/300\n",
      "571/571 [==============================] - 215s 377ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 10/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6264e-04 - val_accuracy: 0.9439\n",
      "Epoch 11/300\n",
      "571/571 [==============================] - 215s 377ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 12/300\n",
      "571/571 [==============================] - 215s 377ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 13/300\n",
      "571/571 [==============================] - 215s 377ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6264e-04 - val_accuracy: 0.9439\n",
      "Epoch 14/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6253e-04 - val_accuracy: 0.9439\n",
      "Epoch 15/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6283e-04 - val_accuracy: 0.9439\n",
      "Epoch 16/300\n",
      "571/571 [==============================] - 215s 377ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6267e-04 - val_accuracy: 0.9439\n",
      "Epoch 17/300\n",
      "571/571 [==============================] - 215s 376ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 18/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6283e-04 - val_accuracy: 0.9439\n",
      "Epoch 19/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6312e-04 - val_accuracy: 0.9439\n",
      "Epoch 20/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6253e-04 - val_accuracy: 0.9439\n",
      "Epoch 21/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6255e-04 - val_accuracy: 0.9439\n",
      "Epoch 22/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6254e-04 - val_accuracy: 0.9439\n",
      "Epoch 23/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6258e-04 - val_accuracy: 0.9439\n",
      "Epoch 24/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6253e-04 - val_accuracy: 0.9439\n",
      "Epoch 25/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6257e-04 - val_accuracy: 0.9439\n",
      "Epoch 26/300\n",
      "571/571 [==============================] - 215s 377ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6288e-04 - val_accuracy: 0.9439\n",
      "Epoch 27/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 28/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6264e-04 - val_accuracy: 0.9439\n",
      "Epoch 29/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6260e-04 - val_accuracy: 0.9439\n",
      "Epoch 30/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 31/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6255e-04 - val_accuracy: 0.9439\n",
      "Epoch 32/300\n",
      "571/571 [==============================] - 215s 377ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 33/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6254e-04 - val_accuracy: 0.9439\n",
      "Epoch 34/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6261e-04 - val_accuracy: 0.9439\n",
      "Epoch 35/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 36/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6267e-04 - val_accuracy: 0.9439\n",
      "Epoch 37/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 38/300\n",
      "571/571 [==============================] - 215s 377ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6258e-04 - val_accuracy: 0.9439\n",
      "Epoch 39/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6257e-04 - val_accuracy: 0.9439\n",
      "Epoch 40/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 41/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 42/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6281e-04 - val_accuracy: 0.9439\n",
      "Epoch 43/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 44/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6268e-04 - val_accuracy: 0.9439\n",
      "Epoch 45/300\n",
      "571/571 [==============================] - 215s 377ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6280e-04 - val_accuracy: 0.9439\n",
      "Epoch 46/300\n",
      "571/571 [==============================] - 215s 376ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 47/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6259e-04 - val_accuracy: 0.9439\n",
      "Epoch 48/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 49/300\n",
      "571/571 [==============================] - 215s 377ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 50/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6256e-04 - val_accuracy: 0.9439\n",
      "Epoch 51/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 52/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6263e-04 - val_accuracy: 0.9439\n",
      "Epoch 53/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6268e-04 - val_accuracy: 0.9439\n",
      "Epoch 54/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6256e-04 - val_accuracy: 0.9439\n",
      "Epoch 55/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 56/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6273e-04 - val_accuracy: 0.9439\n",
      "Epoch 57/300\n",
      "571/571 [==============================] - 225s 395ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6264e-04 - val_accuracy: 0.9439\n",
      "Epoch 58/300\n",
      "571/571 [==============================] - 243s 425ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6253e-04 - val_accuracy: 0.9439\n",
      "Epoch 59/300\n",
      "571/571 [==============================] - 232s 407ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 60/300\n",
      "571/571 [==============================] - 223s 391ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 61/300\n",
      "571/571 [==============================] - 224s 392ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6271e-04 - val_accuracy: 0.9439\n",
      "Epoch 62/300\n",
      "571/571 [==============================] - 224s 392ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 63/300\n",
      "571/571 [==============================] - 222s 388ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6269e-04 - val_accuracy: 0.9439\n",
      "Epoch 64/300\n",
      "571/571 [==============================] - 224s 392ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 65/300\n",
      "571/571 [==============================] - 223s 391ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6260e-04 - val_accuracy: 0.9439\n",
      "Epoch 66/300\n",
      "571/571 [==============================] - 223s 390ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 67/300\n",
      "571/571 [==============================] - 223s 390ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6270e-04 - val_accuracy: 0.9439\n",
      "Epoch 68/300\n",
      "571/571 [==============================] - 223s 390ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6270e-04 - val_accuracy: 0.9439\n",
      "Epoch 69/300\n",
      "571/571 [==============================] - 223s 390ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6265e-04 - val_accuracy: 0.9439\n",
      "Epoch 70/300\n",
      "571/571 [==============================] - 223s 390ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6263e-04 - val_accuracy: 0.9439\n",
      "Epoch 71/300\n",
      "571/571 [==============================] - 223s 391ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6280e-04 - val_accuracy: 0.9439\n",
      "Epoch 72/300\n",
      "571/571 [==============================] - 224s 392ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6260e-04 - val_accuracy: 0.9439\n",
      "Epoch 73/300\n",
      "571/571 [==============================] - 224s 393ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6259e-04 - val_accuracy: 0.9439\n",
      "Epoch 74/300\n",
      "571/571 [==============================] - 223s 391ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6259e-04 - val_accuracy: 0.9439\n",
      "Epoch 75/300\n",
      "571/571 [==============================] - 223s 390ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6270e-04 - val_accuracy: 0.9439\n",
      "Epoch 76/300\n",
      "571/571 [==============================] - 222s 389ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 77/300\n",
      "571/571 [==============================] - 223s 390ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6257e-04 - val_accuracy: 0.9439\n",
      "Epoch 78/300\n",
      "571/571 [==============================] - 222s 390ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 79/300\n",
      "571/571 [==============================] - 222s 389ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6260e-04 - val_accuracy: 0.9439\n",
      "Epoch 80/300\n",
      "571/571 [==============================] - 223s 391ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6253e-04 - val_accuracy: 0.9439\n",
      "Epoch 81/300\n",
      "571/571 [==============================] - 223s 391ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6281e-04 - val_accuracy: 0.9439\n",
      "Epoch 82/300\n",
      "571/571 [==============================] - 223s 390ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 83/300\n",
      "571/571 [==============================] - 223s 390ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6259e-04 - val_accuracy: 0.9439\n",
      "Epoch 84/300\n",
      "571/571 [==============================] - 222s 390ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 85/300\n",
      "571/571 [==============================] - 223s 391ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6295e-04 - val_accuracy: 0.9439\n",
      "Epoch 86/300\n",
      "571/571 [==============================] - 223s 391ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 87/300\n",
      "571/571 [==============================] - 222s 390ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 88/300\n",
      "571/571 [==============================] - 222s 389ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6271e-04 - val_accuracy: 0.9439\n",
      "Epoch 89/300\n",
      "571/571 [==============================] - 223s 390ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6255e-04 - val_accuracy: 0.9439\n",
      "Epoch 90/300\n",
      "571/571 [==============================] - 224s 392ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6259e-04 - val_accuracy: 0.9439\n",
      "Epoch 91/300\n",
      "571/571 [==============================] - 222s 390ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6286e-04 - val_accuracy: 0.9439\n",
      "Epoch 92/300\n",
      "571/571 [==============================] - 223s 390ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 93/300\n",
      "571/571 [==============================] - 223s 391ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6262e-04 - val_accuracy: 0.9439\n",
      "Epoch 94/300\n",
      "571/571 [==============================] - 229s 400ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 95/300\n",
      "571/571 [==============================] - 219s 383ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6266e-04 - val_accuracy: 0.9439\n",
      "Epoch 96/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6257e-04 - val_accuracy: 0.9439\n",
      "Epoch 97/300\n",
      "571/571 [==============================] - 219s 384ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6271e-04 - val_accuracy: 0.9439\n",
      "Epoch 98/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6260e-04 - val_accuracy: 0.9439\n",
      "Epoch 99/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6253e-04 - val_accuracy: 0.9439\n",
      "Epoch 100/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6259e-04 - val_accuracy: 0.9439\n",
      "Epoch 101/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6266e-04 - val_accuracy: 0.9439\n",
      "Epoch 102/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6256e-04 - val_accuracy: 0.9439\n",
      "Epoch 103/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6253e-04 - val_accuracy: 0.9439\n",
      "Epoch 104/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 105/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 218s 383ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6256e-04 - val_accuracy: 0.9439\n",
      "Epoch 106/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6280e-04 - val_accuracy: 0.9439\n",
      "Epoch 107/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 108/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 109/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 110/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 111/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6269e-04 - val_accuracy: 0.9439\n",
      "Epoch 112/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6260e-04 - val_accuracy: 0.9439\n",
      "Epoch 113/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 114/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 115/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 116/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 117/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 118/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6263e-04 - val_accuracy: 0.9439\n",
      "Epoch 119/300\n",
      "571/571 [==============================] - 218s 382ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6253e-04 - val_accuracy: 0.9439\n",
      "Epoch 120/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 121/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6253e-04 - val_accuracy: 0.9439\n",
      "Epoch 122/300\n",
      "571/571 [==============================] - 218s 383ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6280e-04 - val_accuracy: 0.9439\n",
      "Epoch 123/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 124/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6257e-04 - val_accuracy: 0.9439\n",
      "Epoch 125/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6257e-04 - val_accuracy: 0.9439\n",
      "Epoch 126/300\n",
      "571/571 [==============================] - 218s 382ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6273e-04 - val_accuracy: 0.9439\n",
      "Epoch 127/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6259e-04 - val_accuracy: 0.9439\n",
      "Epoch 128/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 129/300\n",
      "571/571 [==============================] - 218s 382ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6258e-04 - val_accuracy: 0.9439\n",
      "Epoch 130/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 131/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6321e-04 - val_accuracy: 0.9439\n",
      "Epoch 132/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 133/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6255e-04 - val_accuracy: 0.9439\n",
      "Epoch 134/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6265e-04 - val_accuracy: 0.9439\n",
      "Epoch 135/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6276e-04 - val_accuracy: 0.9439\n",
      "Epoch 136/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6254e-04 - val_accuracy: 0.9439\n",
      "Epoch 137/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6300e-04 - val_accuracy: 0.9439\n",
      "Epoch 138/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 139/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 140/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6255e-04 - val_accuracy: 0.9439\n",
      "Epoch 141/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6263e-04 - val_accuracy: 0.9439\n",
      "Epoch 142/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 143/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6262e-04 - val_accuracy: 0.9439\n",
      "Epoch 144/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6253e-04 - val_accuracy: 0.9439\n",
      "Epoch 145/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 146/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6276e-04 - val_accuracy: 0.9439\n",
      "Epoch 147/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 148/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6257e-04 - val_accuracy: 0.9439\n",
      "Epoch 149/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6275e-04 - val_accuracy: 0.9439\n",
      "Epoch 150/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6264e-04 - val_accuracy: 0.9439\n",
      "Epoch 151/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6264e-04 - val_accuracy: 0.9439\n",
      "Epoch 152/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 153/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6270e-04 - val_accuracy: 0.9439\n",
      "Epoch 154/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 155/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 156/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6273e-04 - val_accuracy: 0.9439\n",
      "Epoch 157/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 158/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6277e-04 - val_accuracy: 0.9439\n",
      "Epoch 159/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 160/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 161/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6262e-04 - val_accuracy: 0.9439\n",
      "Epoch 162/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 163/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6254e-04 - val_accuracy: 0.9439\n",
      "Epoch 164/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 165/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6282e-04 - val_accuracy: 0.9439\n",
      "Epoch 166/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6262e-04 - val_accuracy: 0.9439\n",
      "Epoch 167/300\n",
      "571/571 [==============================] - 218s 382ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6260e-04 - val_accuracy: 0.9439\n",
      "Epoch 168/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6262e-04 - val_accuracy: 0.9439\n",
      "Epoch 169/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6253e-04 - val_accuracy: 0.9439\n",
      "Epoch 170/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6255e-04 - val_accuracy: 0.9439\n",
      "Epoch 171/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6256e-04 - val_accuracy: 0.9439\n",
      "Epoch 172/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6259e-04 - val_accuracy: 0.9439\n",
      "Epoch 173/300\n",
      "571/571 [==============================] - 218s 382ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6263e-04 - val_accuracy: 0.9439\n",
      "Epoch 174/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 175/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 176/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6282e-04 - val_accuracy: 0.9439\n",
      "Epoch 177/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6257e-04 - val_accuracy: 0.9439\n",
      "Epoch 178/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6257e-04 - val_accuracy: 0.9439\n",
      "Epoch 179/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6254e-04 - val_accuracy: 0.9439\n",
      "Epoch 180/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6290e-04 - val_accuracy: 0.9439\n",
      "Epoch 181/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 182/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6256e-04 - val_accuracy: 0.9439\n",
      "Epoch 183/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6259e-04 - val_accuracy: 0.9439\n",
      "Epoch 184/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 185/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6267e-04 - val_accuracy: 0.9439\n",
      "Epoch 186/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6255e-04 - val_accuracy: 0.9439\n",
      "Epoch 187/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6278e-04 - val_accuracy: 0.9439\n",
      "Epoch 188/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 189/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6256e-04 - val_accuracy: 0.9439\n",
      "Epoch 190/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 191/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6255e-04 - val_accuracy: 0.9439\n",
      "Epoch 192/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6255e-04 - val_accuracy: 0.9439\n",
      "Epoch 193/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6261e-04 - val_accuracy: 0.9439\n",
      "Epoch 194/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6302e-04 - val_accuracy: 0.9439\n",
      "Epoch 195/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6253e-04 - val_accuracy: 0.9439\n",
      "Epoch 196/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6279e-04 - val_accuracy: 0.9439\n",
      "Epoch 197/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6261e-04 - val_accuracy: 0.9439\n",
      "Epoch 198/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 199/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 200/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6289e-04 - val_accuracy: 0.9439\n",
      "Epoch 201/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 202/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6296e-04 - val_accuracy: 0.9439\n",
      "Epoch 203/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6255e-04 - val_accuracy: 0.9439\n",
      "Epoch 204/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 205/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 206/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6268e-04 - val_accuracy: 0.9439\n",
      "Epoch 207/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6262e-04 - val_accuracy: 0.9439\n",
      "Epoch 208/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 209/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6255e-04 - val_accuracy: 0.9439\n",
      "Epoch 210/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 211/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 212/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6259e-04 - val_accuracy: 0.9439\n",
      "Epoch 213/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 214/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6289e-04 - val_accuracy: 0.9439\n",
      "Epoch 215/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 216/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6254e-04 - val_accuracy: 0.9439\n",
      "Epoch 217/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6255e-04 - val_accuracy: 0.9439\n",
      "Epoch 218/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 219/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 220/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6267e-04 - val_accuracy: 0.9439\n",
      "Epoch 221/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 222/300\n",
      "571/571 [==============================] - 218s 383ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6260e-04 - val_accuracy: 0.9439\n",
      "Epoch 223/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6298e-04 - val_accuracy: 0.9439\n",
      "Epoch 224/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6254e-04 - val_accuracy: 0.9439\n",
      "Epoch 225/300\n",
      "571/571 [==============================] - 217s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 226/300\n",
      "571/571 [==============================] - 218s 382ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 227/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6266e-04 - val_accuracy: 0.9439\n",
      "Epoch 228/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6255e-04 - val_accuracy: 0.9439\n",
      "Epoch 229/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6253e-04 - val_accuracy: 0.9439\n",
      "Epoch 230/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 231/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6264e-04 - val_accuracy: 0.9439\n",
      "Epoch 232/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 233/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6254e-04 - val_accuracy: 0.9439\n",
      "Epoch 234/300\n",
      "571/571 [==============================] - 218s 382ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 235/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6262e-04 - val_accuracy: 0.9439\n",
      "Epoch 236/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6291e-04 - val_accuracy: 0.9439\n",
      "Epoch 237/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6278e-04 - val_accuracy: 0.9439\n",
      "Epoch 238/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6267e-04 - val_accuracy: 0.9439\n",
      "Epoch 239/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6260e-04 - val_accuracy: 0.9439\n",
      "Epoch 240/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6259e-04 - val_accuracy: 0.9439\n",
      "Epoch 241/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6263e-04 - val_accuracy: 0.9439\n",
      "Epoch 242/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6263e-04 - val_accuracy: 0.9439\n",
      "Epoch 243/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6266e-04 - val_accuracy: 0.9439\n",
      "Epoch 244/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6259e-04 - val_accuracy: 0.9439\n",
      "Epoch 245/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6290e-04 - val_accuracy: 0.9439\n",
      "Epoch 246/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6262e-04 - val_accuracy: 0.9439\n",
      "Epoch 247/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 248/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 249/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 250/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6265e-04 - val_accuracy: 0.9439\n",
      "Epoch 251/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6293e-04 - val_accuracy: 0.9439\n",
      "Epoch 252/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6261e-04 - val_accuracy: 0.9439\n",
      "Epoch 253/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6264e-04 - val_accuracy: 0.9439\n",
      "Epoch 254/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 255/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 256/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6258e-04 - val_accuracy: 0.9439\n",
      "Epoch 257/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6266e-04 - val_accuracy: 0.9439\n",
      "Epoch 258/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6253e-04 - val_accuracy: 0.9439\n",
      "Epoch 259/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6269e-04 - val_accuracy: 0.9439\n",
      "Epoch 260/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6262e-04 - val_accuracy: 0.9439\n",
      "Epoch 261/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6255e-04 - val_accuracy: 0.9439\n",
      "Epoch 262/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6280e-04 - val_accuracy: 0.9439\n",
      "Epoch 263/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6263e-04 - val_accuracy: 0.9439\n",
      "Epoch 264/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6265e-04 - val_accuracy: 0.9439\n",
      "Epoch 265/300\n",
      "571/571 [==============================] - 218s 383ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6277e-04 - val_accuracy: 0.9439\n",
      "Epoch 266/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6307e-04 - val_accuracy: 0.9439\n",
      "Epoch 267/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6253e-04 - val_accuracy: 0.9439\n",
      "Epoch 268/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6268e-04 - val_accuracy: 0.9439\n",
      "Epoch 269/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6324e-04 - val_accuracy: 0.9439\n",
      "Epoch 270/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6251e-04 - val_accuracy: 0.9439\n",
      "Epoch 271/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 272/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6268e-04 - val_accuracy: 0.9439\n",
      "Epoch 273/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6314e-04 - val_accuracy: 0.9439\n",
      "Epoch 274/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6266e-04 - val_accuracy: 0.9439\n",
      "Epoch 275/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 276/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 277/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6283e-04 - val_accuracy: 0.9439\n",
      "Epoch 278/300\n",
      "571/571 [==============================] - 216s 377ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6253e-04 - val_accuracy: 0.9439\n",
      "Epoch 279/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6278e-04 - val_accuracy: 0.9439\n",
      "Epoch 280/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6264e-04 - val_accuracy: 0.9439\n",
      "Epoch 281/300\n",
      "571/571 [==============================] - 218s 382ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6255e-04 - val_accuracy: 0.9439\n",
      "Epoch 282/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6272e-04 - val_accuracy: 0.9439\n",
      "Epoch 283/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6266e-04 - val_accuracy: 0.9439\n",
      "Epoch 284/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 285/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 286/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 287/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6257e-04 - val_accuracy: 0.9439\n",
      "Epoch 288/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6255e-04 - val_accuracy: 0.9439\n",
      "Epoch 289/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6270e-04 - val_accuracy: 0.9439\n",
      "Epoch 290/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6252e-04 - val_accuracy: 0.9439\n",
      "Epoch 291/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6316e-04 - val_accuracy: 0.9439\n",
      "Epoch 292/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6255e-04 - val_accuracy: 0.9439\n",
      "Epoch 293/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6256e-04 - val_accuracy: 0.9439\n",
      "Epoch 294/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 295/300\n",
      "571/571 [==============================] - 217s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6260e-04 - val_accuracy: 0.9439\n",
      "Epoch 296/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6305e-04 - val_accuracy: 0.9439\n",
      "Epoch 297/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6259e-04 - val_accuracy: 0.9439\n",
      "Epoch 298/300\n",
      "571/571 [==============================] - 218s 381ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n",
      "Epoch 299/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6274e-04 - val_accuracy: 0.9439\n",
      "Epoch 300/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 1.6265e-04 - accuracy: 0.9438 - val_loss: 1.6250e-04 - val_accuracy: 0.9439\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.25, random_state=42)\n",
    "\n",
    "history2 = model.fit(x_train,y_train,batch_size=2048,epochs=300, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13518/13518 [==============================] - 17s 1ms/step - loss: 1.6276e-04 - accuracy: 0.9435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00016275774396490306, 0.9434838891029358]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"gru.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"gru.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa0657bfcf8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
