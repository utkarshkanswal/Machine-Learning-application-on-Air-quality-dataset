{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96739d01",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0397420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os.path as op\n",
    "import pickle\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f9474e",
   "metadata": {},
   "source": [
    "# Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7450b0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.50000e+02 1.90401e+05 7.25000e+02 2.75500e+01 8.03900e+01]\n",
      " [1.50000e+02 1.90401e+05 8.25000e+02 2.75600e+01 8.03300e+01]\n",
      " [1.50000e+02 1.90401e+05 9.25000e+02 2.75800e+01 8.02400e+01]\n",
      " ...\n",
      " [6.10000e+01 1.91020e+05 1.94532e+05 2.93700e+01 7.52100e+01]\n",
      " [6.10000e+01 1.91020e+05 1.94632e+05 2.93500e+01 7.52700e+01]\n",
      " [6.10000e+01 1.91020e+05 1.94732e+05 2.93400e+01 7.53000e+01]]\n",
      "[[ 28.     3.   -52.   ...  16.97  19.63  20.06]\n",
      " [ 28.    15.   -53.   ...  16.63  19.57  23.06]\n",
      " [ 31.    16.   -55.   ...  17.24  19.98  20.24]\n",
      " ...\n",
      " [ 76.    12.   -76.   ...   3.47   3.95   4.35]\n",
      " [ 75.    13.   -76.   ...   3.88   4.33   4.42]\n",
      " [ 76.    12.   -75.   ...   3.46   4.07   4.28]]\n"
     ]
    }
   ],
   "source": [
    "A1=np.empty((0,5),dtype='float32')\n",
    "U1=np.empty((0,7),dtype='float32')\n",
    "node=['150','149','147','144','142','140','136','61']\n",
    "mon=['Apr','Mar','Aug','Jun','Jul','Sep','May','Oct']\n",
    "for j in node:\n",
    "  for i in mon:\n",
    "    inp= pd.read_csv('data_gkv/AT510_Node_'+str(j)+'_'+str(i)+'19_OutputFile.csv',usecols=[1,2,3,15,16],low_memory=False)\n",
    "    out= pd.read_csv('data_gkv/AT510_Node_'+str(j)+'_'+str(i)+'19_OutputFile.csv',usecols=[5,6,7,8,17,18,19],low_memory=False)\n",
    "    \n",
    "    inp=np.array(inp,dtype='float32')\n",
    "    out=np.array(out,dtype='float32')\n",
    "    \n",
    "    A1=np.append(A1, inp, axis=0)\n",
    "    U1=np.append(U1, out, axis=0)\n",
    "\n",
    "print(A1)\n",
    "print(U1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ca5e86",
   "metadata": {},
   "source": [
    "# Min Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ae9a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "scaler_obj=MinMaxScaler()\n",
    "X1=scaler_obj.fit_transform(A1)\n",
    "Y1=scaler_obj.fit_transform(U1)\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b80f424",
   "metadata": {},
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29f8c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def hyperparameterRF(x_train,y_train):\n",
    "    random_grid = {'bootstrap': [True, False],\n",
    "     'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "     'max_features': ['auto', 'sqrt'],\n",
    "     'min_samples_leaf': [1, 2, 4],\n",
    "     'min_samples_split': [2, 5, 10],\n",
    "     'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "    }\n",
    "    rf = RandomForestRegressor()\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 2, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "    grid_result = MultiOutputRegressor(rf_random).fit(x_train, y_train)\n",
    "    \n",
    "    return grid_result.estimators_[0].best_params_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9493a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X1,Y1,test_size=0.5,random_state=0)\n",
    "\n",
    "params=hyperparameterRF(x_train,y_train)\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1edf627",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05d8053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data into training and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X1,Y1,test_size=0.25,random_state=0)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "model2=MultiOutputRegressor(RandomForestRegressor(max_depth=7,n_estimators=500))\n",
    "\n",
    "#training the model\n",
    "model_fit2=model2.fit(x_train,y_train)\n",
    "print(\"Model training is Done!!\")\n",
    "\n",
    "filename2 = 'randomforest.sav'\n",
    "pickle.dump(model_fit2, open(filename2, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75d6b3",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b449c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "train_sizes=['NO2','O3','NO','CO','PM1','PM2.5','PM10']\n",
    "\n",
    "#finding out the r2 score\n",
    "y_train_pred2=model2.predict(x_train)\n",
    "r2_train2=r2_score(y_train,y_train_pred2)\n",
    "\n",
    "y_test_pred2=model2.predict(x_test)\n",
    "r2_test2=r2_score(y_test,y_test_pred2)\n",
    "\n",
    "print('r2 score on train data '+str(r2_train2))\n",
    "print('r2 score on test data '+ str(r2_test2))\n",
    "\n",
    "rf_mae=metrics.mean_absolute_error(y_test, y_test_pred2)\n",
    "rf_mse=metrics.mean_squared_error(y_test, y_test_pred2)\n",
    "rf_rmse=np.sqrt(metrics.mean_squared_error(y_test, y_test_pred2))\n",
    "print('Mean Absolute Error:',rf_mae)\n",
    "print('Mean Squared Error:',rf_mse )\n",
    "print('Root Mean Squared Error:',rf_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8492c16f",
   "metadata": {},
   "source": [
    "# y-test vs y-predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47949997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing y_test and y_test_predict\n",
    "print(\"Y_Test:\",y_test)\n",
    "print(\"Y_Test_Predict:\",y_test_pred2)\n",
    "\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('ggplot')\n",
    "for i in range(0,7):\n",
    "  plt.figure(figsize=[12,10])\n",
    "  plt.plot(y_test[:,i],linewidth=3, markersize=12)\n",
    "  plt.plot(y_test_pred2[:,i],linewidth=2, markersize=12)\n",
    "  plt.xlabel('X')\n",
    "  plt.ylabel(train_sizes[i])\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
