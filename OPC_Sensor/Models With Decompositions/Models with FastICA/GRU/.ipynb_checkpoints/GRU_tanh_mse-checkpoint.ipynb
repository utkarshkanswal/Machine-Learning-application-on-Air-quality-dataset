{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os.path as op\n",
    "from csv import writer\n",
    "import math\n",
    "import cmath\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model,Sequential,load_model\n",
    "from keras.layers import Input, Embedding\n",
    "from keras.layers import Dense, Bidirectional\n",
    "from keras.layers.recurrent import LSTM\n",
    "import keras.metrics as metrics\n",
    "import itertools\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from decimal import Decimal\n",
    "from keras.layers import Conv1D,MaxPooling1D,Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.50000e+02 1.90401e+05 7.25000e+02 2.75500e+01 8.03900e+01]\n",
      " [1.50000e+02 1.90401e+05 8.25000e+02 2.75600e+01 8.03300e+01]\n",
      " [1.50000e+02 1.90401e+05 9.25000e+02 2.75800e+01 8.02400e+01]\n",
      " ...\n",
      " [6.10000e+01 1.91020e+05 1.94532e+05 2.93700e+01 7.52100e+01]\n",
      " [6.10000e+01 1.91020e+05 1.94632e+05 2.93500e+01 7.52700e+01]\n",
      " [6.10000e+01 1.91020e+05 1.94732e+05 2.93400e+01 7.53000e+01]]\n",
      "[[ 28.     3.   -52.   ...  16.97  19.63  20.06]\n",
      " [ 28.    15.   -53.   ...  16.63  19.57  23.06]\n",
      " [ 31.    16.   -55.   ...  17.24  19.98  20.24]\n",
      " ...\n",
      " [ 76.    12.   -76.   ...   3.47   3.95   4.35]\n",
      " [ 75.    13.   -76.   ...   3.88   4.33   4.42]\n",
      " [ 76.    12.   -75.   ...   3.46   4.07   4.28]]\n"
     ]
    }
   ],
   "source": [
    "A1=np.empty((0,5),dtype='float32')\n",
    "U1=np.empty((0,7),dtype='float32')\n",
    "node=['150','149','147','144','142','140','136','61']\n",
    "mon=['Apr','Mar','Aug','Jun','Jul','Sep','May','Oct']\n",
    "for j in node:\n",
    "  for i in mon:\n",
    "    inp= pd.read_csv('../data_gkv/AT510_Node_'+str(j)+'_'+str(i)+'19_OutputFile.csv',usecols=[1,2,3,15,16])\n",
    "    out= pd.read_csv('../data_gkv/AT510_Node_'+str(j)+'_'+str(i)+'19_OutputFile.csv',usecols=[5,6,7,8,17,18,19])\n",
    "    \n",
    "    inp=np.array(inp,dtype='float32')\n",
    "    out=np.array(out,dtype='float32')\n",
    "    \n",
    "    A1=np.append(A1, inp, axis=0)\n",
    "    U1=np.append(U1, out, axis=0)\n",
    "\n",
    "print(A1)\n",
    "print(U1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "scaler_obj=MinMaxScaler()\n",
    "X1=scaler_obj.fit_transform(A1)\n",
    "Y1=scaler_obj.fit_transform(U1)\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "X1=X1[:,np.newaxis,:]\n",
    "Y1=Y1[:,np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 14)                882       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 105       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 7)                28        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 7)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,015\n",
      "Trainable params: 1,001\n",
      "Non-trainable params: 14\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(keras.Input(shape=(1,5)))\n",
    "model.add(tf.keras.layers.GRU(14,activation=\"tanh\",use_bias=True,kernel_initializer=\"glorot_uniform\",bias_initializer=\"zeros\", \n",
    "                                kernel_regularizer=keras.regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                                bias_regularizer=keras.regularizers.l2(1e-4),\n",
    "                                activity_regularizer=keras.regularizers.l2(1e-5)))\n",
    "model.add(keras.layers.Dropout(.1))\n",
    "model.add(Dense(7))\n",
    "model.add(keras.layers.BatchNormalization(axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,\n",
    "                                beta_initializer=\"zeros\",gamma_initializer=\"ones\",\n",
    "                                moving_mean_initializer=\"zeros\",moving_variance_initializer=\"ones\",trainable=True))\n",
    "model.add(keras.layers.ReLU())\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),loss='mse',metrics=['accuracy','mse','mae',rmse])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4563/4563 [==============================] - 56s 11ms/step - loss: 0.2151 - accuracy: 0.1309 - mse: 0.2140 - mae: 0.2587 - rmse: 0.3963 - val_loss: 0.0268 - val_accuracy: 0.0446 - val_mse: 0.0258 - val_mae: 0.0812 - val_rmse: 0.1321\n",
      "Epoch 2/50\n",
      "4563/4563 [==============================] - 46s 10ms/step - loss: 0.0516 - accuracy: 0.1208 - mse: 0.0506 - mae: 0.1128 - rmse: 0.1774 - val_loss: 0.0021 - val_accuracy: 0.0747 - val_mse: 0.0012 - val_mae: 0.0195 - val_rmse: 0.0337\n",
      "Epoch 3/50\n",
      "4563/4563 [==============================] - 47s 10ms/step - loss: 0.0116 - accuracy: 0.1766 - mse: 0.0109 - mae: 0.0485 - rmse: 0.0752 - val_loss: 0.0014 - val_accuracy: 0.3251 - val_mse: 6.8843e-04 - val_mae: 0.0143 - val_rmse: 0.0245\n",
      "Epoch 4/50\n",
      "4563/4563 [==============================] - 47s 10ms/step - loss: 0.0037 - accuracy: 0.2260 - mse: 0.0031 - mae: 0.0258 - rmse: 0.0410 - val_loss: 0.0012 - val_accuracy: 0.3777 - val_mse: 6.3687e-04 - val_mae: 0.0123 - val_rmse: 0.0225\n",
      "Epoch 5/50\n",
      "4563/4563 [==============================] - 48s 10ms/step - loss: 0.0017 - accuracy: 0.3372 - mse: 0.0013 - mae: 0.0165 - rmse: 0.0286 - val_loss: 0.0010 - val_accuracy: 0.4210 - val_mse: 6.1680e-04 - val_mae: 0.0118 - val_rmse: 0.0218\n",
      "Epoch 6/50\n",
      "4563/4563 [==============================] - 48s 10ms/step - loss: 0.0011 - accuracy: 0.4451 - mse: 7.7393e-04 - mae: 0.0133 - rmse: 0.0238 - val_loss: 8.8252e-04 - val_accuracy: 0.4459 - val_mse: 6.0757e-04 - val_mae: 0.0117 - val_rmse: 0.0215\n",
      "Epoch 7/50\n",
      "4563/4563 [==============================] - 49s 11ms/step - loss: 8.4894e-04 - accuracy: 0.5129 - mse: 6.2127e-04 - mae: 0.0120 - rmse: 0.0217 - val_loss: 7.8832e-04 - val_accuracy: 0.4712 - val_mse: 6.0135e-04 - val_mae: 0.0117 - val_rmse: 0.0215\n",
      "Epoch 8/50\n",
      "4563/4563 [==============================] - 50s 11ms/step - loss: 7.0498e-04 - accuracy: 0.5847 - mse: 5.4835e-04 - mae: 0.0113 - rmse: 0.0202 - val_loss: 7.6351e-04 - val_accuracy: 0.4669 - val_mse: 6.3302e-04 - val_mae: 0.0124 - val_rmse: 0.0228\n",
      "Epoch 9/50\n",
      "4563/4563 [==============================] - 50s 11ms/step - loss: 5.9604e-04 - accuracy: 0.6596 - mse: 4.8572e-04 - mae: 0.0105 - rmse: 0.0185 - val_loss: 7.9907e-04 - val_accuracy: 0.4142 - val_mse: 7.0622e-04 - val_mae: 0.0134 - val_rmse: 0.0250\n",
      "Epoch 10/50\n",
      "4563/4563 [==============================] - 51s 11ms/step - loss: 5.2599e-04 - accuracy: 0.6895 - mse: 4.4740e-04 - mae: 0.0099 - rmse: 0.0174 - val_loss: 8.0695e-04 - val_accuracy: 0.3756 - val_mse: 7.4122e-04 - val_mae: 0.0138 - val_rmse: 0.0259\n",
      "Epoch 11/50\n",
      "4563/4563 [==============================] - 50s 11ms/step - loss: 4.8219e-04 - accuracy: 0.6968 - mse: 4.2698e-04 - mae: 0.0096 - rmse: 0.0167 - val_loss: 8.0145e-04 - val_accuracy: 0.3719 - val_mse: 7.5587e-04 - val_mae: 0.0139 - val_rmse: 0.0262\n",
      "Epoch 12/50\n",
      "4563/4563 [==============================] - 50s 11ms/step - loss: 4.5217e-04 - accuracy: 0.6997 - mse: 4.1384e-04 - mae: 0.0094 - rmse: 0.0163 - val_loss: 8.2393e-04 - val_accuracy: 0.3012 - val_mse: 7.9150e-04 - val_mae: 0.0143 - val_rmse: 0.0270\n",
      "Epoch 13/50\n",
      "4563/4563 [==============================] - 51s 11ms/step - loss: 4.3220e-04 - accuracy: 0.7006 - mse: 4.0413e-04 - mae: 0.0092 - rmse: 0.0160 - val_loss: 8.2682e-04 - val_accuracy: 0.2808 - val_mse: 8.0236e-04 - val_mae: 0.0143 - val_rmse: 0.0272\n",
      "Epoch 14/50\n",
      "4563/4563 [==============================] - 51s 11ms/step - loss: 4.1748e-04 - accuracy: 0.7012 - mse: 3.9564e-04 - mae: 0.0090 - rmse: 0.0157 - val_loss: 8.1319e-04 - val_accuracy: 0.3497 - val_mse: 7.9356e-04 - val_mae: 0.0143 - val_rmse: 0.0271\n",
      "Epoch 15/50\n",
      "4563/4563 [==============================] - 50s 11ms/step - loss: 4.0799e-04 - accuracy: 0.7012 - mse: 3.9010e-04 - mae: 0.0089 - rmse: 0.0155 - val_loss: 8.1817e-04 - val_accuracy: 0.3147 - val_mse: 8.0189e-04 - val_mae: 0.0143 - val_rmse: 0.0272\n",
      "Epoch 16/50\n",
      "4563/4563 [==============================] - 52s 11ms/step - loss: 3.9942e-04 - accuracy: 0.7027 - mse: 3.8422e-04 - mae: 0.0088 - rmse: 0.0153 - val_loss: 8.2491e-04 - val_accuracy: 0.3098 - val_mse: 8.1062e-04 - val_mae: 0.0144 - val_rmse: 0.0274\n",
      "Epoch 17/50\n",
      "4563/4563 [==============================] - 50s 11ms/step - loss: 3.6622e-04 - accuracy: 0.7635 - mse: 3.5252e-04 - mae: 0.0084 - rmse: 0.0144 - val_loss: 8.4217e-04 - val_accuracy: 0.0000e+00 - val_mse: 8.2924e-04 - val_mae: 0.0146 - val_rmse: 0.0278\n",
      "Epoch 18/50\n",
      "4563/4563 [==============================] - 50s 11ms/step - loss: 3.2211e-04 - accuracy: 0.8152 - mse: 3.1028e-04 - mae: 0.0078 - rmse: 0.0132 - val_loss: 8.3209e-04 - val_accuracy: 0.3058 - val_mse: 8.2122e-04 - val_mae: 0.0145 - val_rmse: 0.0276\n",
      "Epoch 19/50\n",
      "4563/4563 [==============================] - 50s 11ms/step - loss: 3.0776e-04 - accuracy: 0.8187 - mse: 2.9750e-04 - mae: 0.0076 - rmse: 0.0127 - val_loss: 8.0505e-04 - val_accuracy: 0.6832 - val_mse: 7.9521e-04 - val_mae: 0.0143 - val_rmse: 0.0271\n",
      "Epoch 20/50\n",
      "4563/4563 [==============================] - 50s 11ms/step - loss: 3.0265e-04 - accuracy: 0.8189 - mse: 2.9309e-04 - mae: 0.0075 - rmse: 0.0126 - val_loss: 7.5213e-04 - val_accuracy: 0.9440 - val_mse: 7.4279e-04 - val_mae: 0.0139 - val_rmse: 0.0261\n",
      "Epoch 21/50\n",
      "4563/4563 [==============================] - 52s 11ms/step - loss: 2.9882e-04 - accuracy: 0.8191 - mse: 2.8971e-04 - mae: 0.0074 - rmse: 0.0124 - val_loss: 6.9597e-04 - val_accuracy: 0.9440 - val_mse: 6.8705e-04 - val_mae: 0.0134 - val_rmse: 0.0249\n",
      "Epoch 22/50\n",
      "4563/4563 [==============================] - 48s 10ms/step - loss: 2.9469e-04 - accuracy: 0.8185 - mse: 2.8599e-04 - mae: 0.0073 - rmse: 0.0123 - val_loss: 6.5742e-04 - val_accuracy: 0.9440 - val_mse: 6.4889e-04 - val_mae: 0.0131 - val_rmse: 0.0241\n",
      "Epoch 23/50\n",
      "4563/4563 [==============================] - 51s 11ms/step - loss: 2.9080e-04 - accuracy: 0.8192 - mse: 2.8248e-04 - mae: 0.0072 - rmse: 0.0122 - val_loss: 5.8829e-04 - val_accuracy: 0.9440 - val_mse: 5.8016e-04 - val_mae: 0.0124 - val_rmse: 0.0226\n",
      "Epoch 24/50\n",
      "4563/4563 [==============================] - 43s 9ms/step - loss: 2.8802e-04 - accuracy: 0.8188 - mse: 2.8009e-04 - mae: 0.0072 - rmse: 0.0121 - val_loss: 5.4930e-04 - val_accuracy: 0.9440 - val_mse: 5.4156e-04 - val_mae: 0.0120 - val_rmse: 0.0216\n",
      "Epoch 25/50\n",
      "4563/4563 [==============================] - 45s 10ms/step - loss: 2.8477e-04 - accuracy: 0.8192 - mse: 2.7723e-04 - mae: 0.0071 - rmse: 0.0120 - val_loss: 5.0032e-04 - val_accuracy: 0.9440 - val_mse: 4.9297e-04 - val_mae: 0.0115 - val_rmse: 0.0204\n",
      "Epoch 26/50\n",
      "4563/4563 [==============================] - 45s 10ms/step - loss: 2.8147e-04 - accuracy: 0.8189 - mse: 2.7433e-04 - mae: 0.0070 - rmse: 0.0119 - val_loss: 4.5132e-04 - val_accuracy: 0.9440 - val_mse: 4.4436e-04 - val_mae: 0.0109 - val_rmse: 0.0191\n",
      "Epoch 27/50\n",
      "4563/4563 [==============================] - 44s 10ms/step - loss: 2.7905e-04 - accuracy: 0.8190 - mse: 2.7230e-04 - mae: 0.0069 - rmse: 0.0118 - val_loss: 4.1814e-04 - val_accuracy: 0.9440 - val_mse: 4.1155e-04 - val_mae: 0.0105 - val_rmse: 0.0181\n",
      "Epoch 28/50\n",
      "4563/4563 [==============================] - 43s 10ms/step - loss: 2.7295e-04 - accuracy: 0.8199 - mse: 2.6649e-04 - mae: 0.0068 - rmse: 0.0117 - val_loss: 4.1405e-04 - val_accuracy: 0.9440 - val_mse: 4.0780e-04 - val_mae: 0.0104 - val_rmse: 0.0180\n",
      "Epoch 29/50\n",
      "4563/4563 [==============================] - 44s 10ms/step - loss: 2.5874e-04 - accuracy: 0.8339 - mse: 2.5278e-04 - mae: 0.0066 - rmse: 0.0112 - val_loss: 3.2181e-04 - val_accuracy: 0.9440 - val_mse: 3.1616e-04 - val_mae: 0.0090 - val_rmse: 0.0148\n",
      "Epoch 30/50\n",
      "4563/4563 [==============================] - 44s 10ms/step - loss: 2.5401e-04 - accuracy: 0.8343 - mse: 2.4876e-04 - mae: 0.0065 - rmse: 0.0111 - val_loss: 2.9707e-04 - val_accuracy: 0.9440 - val_mse: 2.9220e-04 - val_mae: 0.0085 - val_rmse: 0.0138\n",
      "Epoch 31/50\n",
      "4563/4563 [==============================] - 45s 10ms/step - loss: 2.5175e-04 - accuracy: 0.8340 - mse: 2.4728e-04 - mae: 0.0064 - rmse: 0.0111 - val_loss: 2.8481e-04 - val_accuracy: 0.9440 - val_mse: 2.8069e-04 - val_mae: 0.0082 - val_rmse: 0.0132\n",
      "Epoch 32/50\n",
      "4563/4563 [==============================] - 45s 10ms/step - loss: 2.4923e-04 - accuracy: 0.8345 - mse: 2.4547e-04 - mae: 0.0063 - rmse: 0.0110 - val_loss: 2.6089e-04 - val_accuracy: 0.9440 - val_mse: 2.5745e-04 - val_mae: 0.0076 - val_rmse: 0.0121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "4563/4563 [==============================] - 45s 10ms/step - loss: 2.4748e-04 - accuracy: 0.8342 - mse: 2.4434e-04 - mae: 0.0063 - rmse: 0.0109 - val_loss: 2.5120e-04 - val_accuracy: 0.9440 - val_mse: 2.4828e-04 - val_mae: 0.0073 - val_rmse: 0.0115\n",
      "Epoch 34/50\n",
      "4563/4563 [==============================] - 44s 10ms/step - loss: 2.3923e-04 - accuracy: 0.8482 - mse: 2.3666e-04 - mae: 0.0062 - rmse: 0.0107 - val_loss: 2.1740e-04 - val_accuracy: 0.9440 - val_mse: 2.1508e-04 - val_mae: 0.0063 - val_rmse: 0.0098\n",
      "Epoch 35/50\n",
      "4563/4563 [==============================] - 45s 10ms/step - loss: 2.3394e-04 - accuracy: 0.8501 - mse: 2.3186e-04 - mae: 0.0061 - rmse: 0.0105 - val_loss: 2.0015e-04 - val_accuracy: 0.9440 - val_mse: 1.9828e-04 - val_mae: 0.0059 - val_rmse: 0.0090\n",
      "Epoch 36/50\n",
      "4563/4563 [==============================] - 44s 10ms/step - loss: 2.1231e-04 - accuracy: 0.8891 - mse: 2.1060e-04 - mae: 0.0057 - rmse: 0.0099 - val_loss: 1.6519e-04 - val_accuracy: 0.9440 - val_mse: 1.6362e-04 - val_mae: 0.0048 - val_rmse: 0.0083\n",
      "Epoch 37/50\n",
      "4563/4563 [==============================] - 44s 10ms/step - loss: 1.6685e-04 - accuracy: 0.9438 - mse: 1.6550e-04 - mae: 0.0050 - rmse: 0.0086 - val_loss: 1.6379e-04 - val_accuracy: 0.9440 - val_mse: 1.6260e-04 - val_mae: 0.0048 - val_rmse: 0.0084\n",
      "Epoch 38/50\n",
      "4563/4563 [==============================] - 44s 10ms/step - loss: 1.6281e-04 - accuracy: 0.9438 - mse: 1.6173e-04 - mae: 0.0049 - rmse: 0.0085 - val_loss: 1.6353e-04 - val_accuracy: 0.9440 - val_mse: 1.6253e-04 - val_mae: 0.0049 - val_rmse: 0.0085\n",
      "Epoch 39/50\n",
      "4563/4563 [==============================] - 44s 10ms/step - loss: 1.6124e-04 - accuracy: 0.9438 - mse: 1.6029e-04 - mae: 0.0048 - rmse: 0.0085 - val_loss: 1.6339e-04 - val_accuracy: 0.9440 - val_mse: 1.6249e-04 - val_mae: 0.0048 - val_rmse: 0.0085\n",
      "Epoch 40/50\n",
      "4563/4563 [==============================] - 44s 10ms/step - loss: 1.6054e-04 - accuracy: 0.9438 - mse: 1.5966e-04 - mae: 0.0048 - rmse: 0.0084 - val_loss: 1.6336e-04 - val_accuracy: 0.9440 - val_mse: 1.6249e-04 - val_mae: 0.0048 - val_rmse: 0.0085\n",
      "Epoch 41/50\n",
      "4563/4563 [==============================] - 44s 10ms/step - loss: 1.6028e-04 - accuracy: 0.9438 - mse: 1.5946e-04 - mae: 0.0048 - rmse: 0.0084 - val_loss: 1.6330e-04 - val_accuracy: 0.9440 - val_mse: 1.6249e-04 - val_mae: 0.0048 - val_rmse: 0.0085\n",
      "Epoch 42/50\n",
      "4563/4563 [==============================] - 44s 10ms/step - loss: 1.6003e-04 - accuracy: 0.9438 - mse: 1.5925e-04 - mae: 0.0048 - rmse: 0.0084 - val_loss: 1.6328e-04 - val_accuracy: 0.9440 - val_mse: 1.6251e-04 - val_mae: 0.0048 - val_rmse: 0.0085\n",
      "Epoch 43/50\n",
      "4563/4563 [==============================] - 46s 10ms/step - loss: 1.5974e-04 - accuracy: 0.9438 - mse: 1.5901e-04 - mae: 0.0048 - rmse: 0.0084 - val_loss: 1.6322e-04 - val_accuracy: 0.9440 - val_mse: 1.6249e-04 - val_mae: 0.0048 - val_rmse: 0.0085\n",
      "Epoch 44/50\n",
      "4563/4563 [==============================] - 44s 10ms/step - loss: 1.5937e-04 - accuracy: 0.9438 - mse: 1.5867e-04 - mae: 0.0047 - rmse: 0.0084 - val_loss: 1.6319e-04 - val_accuracy: 0.9440 - val_mse: 1.6250e-04 - val_mae: 0.0048 - val_rmse: 0.0085\n",
      "Epoch 45/50\n",
      "4563/4563 [==============================] - 45s 10ms/step - loss: 1.5902e-04 - accuracy: 0.9438 - mse: 1.5836e-04 - mae: 0.0047 - rmse: 0.0084 - val_loss: 1.6316e-04 - val_accuracy: 0.9440 - val_mse: 1.6250e-04 - val_mae: 0.0048 - val_rmse: 0.0085\n",
      "Epoch 46/50\n",
      "4563/4563 [==============================] - 44s 10ms/step - loss: 1.5866e-04 - accuracy: 0.9438 - mse: 1.5801e-04 - mae: 0.0047 - rmse: 0.0084 - val_loss: 1.6316e-04 - val_accuracy: 0.9440 - val_mse: 1.6251e-04 - val_mae: 0.0048 - val_rmse: 0.0085\n",
      "Epoch 47/50\n",
      "4563/4563 [==============================] - 44s 10ms/step - loss: 1.5811e-04 - accuracy: 0.9438 - mse: 1.5748e-04 - mae: 0.0047 - rmse: 0.0084 - val_loss: 1.6314e-04 - val_accuracy: 0.9440 - val_mse: 1.6250e-04 - val_mae: 0.0048 - val_rmse: 0.0085\n",
      "Epoch 48/50\n",
      "4563/4563 [==============================] - 44s 10ms/step - loss: 1.5721e-04 - accuracy: 0.9438 - mse: 1.5657e-04 - mae: 0.0047 - rmse: 0.0083 - val_loss: 1.6320e-04 - val_accuracy: 0.9440 - val_mse: 1.6253e-04 - val_mae: 0.0048 - val_rmse: 0.0084\n",
      "Epoch 49/50\n",
      "4563/4563 [==============================] - 44s 10ms/step - loss: 1.5564e-04 - accuracy: 0.9438 - mse: 1.5494e-04 - mae: 0.0047 - rmse: 0.0083 - val_loss: 1.6326e-04 - val_accuracy: 0.9440 - val_mse: 1.6251e-04 - val_mae: 0.0048 - val_rmse: 0.0084\n",
      "Epoch 50/50\n",
      "4563/4563 [==============================] - 44s 10ms/step - loss: 1.5378e-04 - accuracy: 0.9438 - mse: 1.5303e-04 - mae: 0.0047 - rmse: 0.0082 - val_loss: 1.6325e-04 - val_accuracy: 0.9440 - val_mse: 1.6249e-04 - val_mae: 0.0048 - val_rmse: 0.0085\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.25, random_state=42)\n",
    "\n",
    "history2 = model.fit(x_train,y_train,batch_size=256,epochs=50, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13518/13518 [==============================] - 63s 5ms/step - loss: 1.6351e-04 - accuracy: 0.9435 - mse: 1.6276e-04 - mae: 0.0048 - rmse: 0.0085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00016351271187886596,\n",
       " 0.9434838891029358,\n",
       " 0.00016276021779049188,\n",
       " 0.004776447080075741,\n",
       " 0.008491985499858856]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40554/40554 [==============================] - 193s 5ms/step - loss: 1.6339e-04 - accuracy: 0.9438 - mse: 1.6263e-04 - mae: 0.0048 - rmse: 0.0085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0001633863284951076,\n",
       " 0.94383305311203,\n",
       " 0.0001626343437237665,\n",
       " 0.004763890523463488,\n",
       " 0.008473438210785389]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Val Accuracy</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Val MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Val MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Val RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.215101</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>0.130886</td>\n",
       "      <td>0.044628</td>\n",
       "      <td>0.214007</td>\n",
       "      <td>0.025814</td>\n",
       "      <td>0.258652</td>\n",
       "      <td>0.081176</td>\n",
       "      <td>0.396298</td>\n",
       "      <td>0.025814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.051551</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.120844</td>\n",
       "      <td>0.074664</td>\n",
       "      <td>0.050618</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.112786</td>\n",
       "      <td>0.019467</td>\n",
       "      <td>0.177375</td>\n",
       "      <td>0.001238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011623</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.176623</td>\n",
       "      <td>0.325088</td>\n",
       "      <td>0.010857</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.048535</td>\n",
       "      <td>0.014336</td>\n",
       "      <td>0.075156</td>\n",
       "      <td>0.000688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.225984</td>\n",
       "      <td>0.377728</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.025810</td>\n",
       "      <td>0.012314</td>\n",
       "      <td>0.041015</td>\n",
       "      <td>0.000637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001731</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.337160</td>\n",
       "      <td>0.421016</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.016475</td>\n",
       "      <td>0.011830</td>\n",
       "      <td>0.028593</td>\n",
       "      <td>0.000617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.445078</td>\n",
       "      <td>0.445906</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.013250</td>\n",
       "      <td>0.011716</td>\n",
       "      <td>0.023846</td>\n",
       "      <td>0.000608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.512893</td>\n",
       "      <td>0.471175</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.012026</td>\n",
       "      <td>0.011731</td>\n",
       "      <td>0.021741</td>\n",
       "      <td>0.000601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.584672</td>\n",
       "      <td>0.466906</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.011264</td>\n",
       "      <td>0.012427</td>\n",
       "      <td>0.020209</td>\n",
       "      <td>0.000633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.659607</td>\n",
       "      <td>0.414164</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>0.013413</td>\n",
       "      <td>0.018515</td>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.689539</td>\n",
       "      <td>0.375582</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>0.017382</td>\n",
       "      <td>0.000741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.696806</td>\n",
       "      <td>0.371932</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.009604</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>0.016745</td>\n",
       "      <td>0.000756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.699676</td>\n",
       "      <td>0.301158</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.009385</td>\n",
       "      <td>0.014253</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.700627</td>\n",
       "      <td>0.280803</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>0.014345</td>\n",
       "      <td>0.015970</td>\n",
       "      <td>0.000802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.701224</td>\n",
       "      <td>0.349687</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.009048</td>\n",
       "      <td>0.014272</td>\n",
       "      <td>0.015673</td>\n",
       "      <td>0.000794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.701235</td>\n",
       "      <td>0.314689</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.008938</td>\n",
       "      <td>0.014342</td>\n",
       "      <td>0.015477</td>\n",
       "      <td>0.000802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.702683</td>\n",
       "      <td>0.309759</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.008826</td>\n",
       "      <td>0.014413</td>\n",
       "      <td>0.015284</td>\n",
       "      <td>0.000811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.763497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.014560</td>\n",
       "      <td>0.014438</td>\n",
       "      <td>0.000829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.815223</td>\n",
       "      <td>0.305775</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.014497</td>\n",
       "      <td>0.013160</td>\n",
       "      <td>0.000821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.818722</td>\n",
       "      <td>0.683231</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.014293</td>\n",
       "      <td>0.012720</td>\n",
       "      <td>0.000795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.818950</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.013872</td>\n",
       "      <td>0.012560</td>\n",
       "      <td>0.000743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.819096</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.007399</td>\n",
       "      <td>0.013401</td>\n",
       "      <td>0.012448</td>\n",
       "      <td>0.000687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.818488</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.007298</td>\n",
       "      <td>0.013062</td>\n",
       "      <td>0.012302</td>\n",
       "      <td>0.000649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.819182</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.007224</td>\n",
       "      <td>0.012411</td>\n",
       "      <td>0.012192</td>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.818785</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.007157</td>\n",
       "      <td>0.012019</td>\n",
       "      <td>0.012103</td>\n",
       "      <td>0.000542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.819171</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.007080</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.011991</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.818942</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>0.010912</td>\n",
       "      <td>0.011883</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.819024</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.006935</td>\n",
       "      <td>0.010486</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>0.000412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.819906</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>0.010426</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.833948</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.006564</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>0.000316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.834282</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.006475</td>\n",
       "      <td>0.008504</td>\n",
       "      <td>0.011131</td>\n",
       "      <td>0.000292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.834038</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.006407</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>0.011052</td>\n",
       "      <td>0.000281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.834519</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.007641</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.834232</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>0.007323</td>\n",
       "      <td>0.010915</td>\n",
       "      <td>0.000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.848234</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.006217</td>\n",
       "      <td>0.006281</td>\n",
       "      <td>0.010731</td>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.850103</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.006052</td>\n",
       "      <td>0.005857</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.000198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.889147</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.005709</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.009867</td>\n",
       "      <td>0.000164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.943819</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>0.008507</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.943819</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>0.004810</td>\n",
       "      <td>0.008429</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.943819</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>0.004789</td>\n",
       "      <td>0.008426</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.943819</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.943818</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.943819</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.004794</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.943821</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.008392</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.943819</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0.004839</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.943819</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>0.008371</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.943819</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.943819</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.004770</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Loss  Val Loss  Accuracy  Val Accuracy       MSE   Val MSE       MAE  \\\n",
       "0   0.215101  0.026828  0.130886      0.044628  0.214007  0.025814  0.258652   \n",
       "1   0.051551  0.002087  0.120844      0.074664  0.050618  0.001238  0.112786   \n",
       "2   0.011623  0.001372  0.176623      0.325088  0.010857  0.000688  0.048535   \n",
       "3   0.003736  0.001163  0.225984      0.377728  0.003133  0.000637  0.025810   \n",
       "4   0.001731  0.001005  0.337160      0.421016  0.001277  0.000617  0.016475   \n",
       "5   0.001104  0.000883  0.445078      0.445906  0.000774  0.000608  0.013250   \n",
       "6   0.000849  0.000788  0.512893      0.471175  0.000621  0.000601  0.012026   \n",
       "7   0.000705  0.000764  0.584672      0.466906  0.000548  0.000633  0.011264   \n",
       "8   0.000596  0.000799  0.659607      0.414164  0.000486  0.000706  0.010460   \n",
       "9   0.000526  0.000807  0.689539      0.375582  0.000447  0.000741  0.009918   \n",
       "10  0.000482  0.000801  0.696806      0.371932  0.000427  0.000756  0.009604   \n",
       "11  0.000452  0.000824  0.699676      0.301158  0.000414  0.000792  0.009385   \n",
       "12  0.000432  0.000827  0.700627      0.280803  0.000404  0.000802  0.009208   \n",
       "13  0.000417  0.000813  0.701224      0.349687  0.000396  0.000794  0.009048   \n",
       "14  0.000408  0.000818  0.701235      0.314689  0.000390  0.000802  0.008938   \n",
       "15  0.000399  0.000825  0.702683      0.309759  0.000384  0.000811  0.008826   \n",
       "16  0.000366  0.000842  0.763497      0.000000  0.000353  0.000829  0.008403   \n",
       "17  0.000322  0.000832  0.815223      0.305775  0.000310  0.000821  0.007791   \n",
       "18  0.000308  0.000805  0.818722      0.683231  0.000297  0.000795  0.007563   \n",
       "19  0.000303  0.000752  0.818950      0.943964  0.000293  0.000743  0.007470   \n",
       "20  0.000299  0.000696  0.819096      0.943964  0.000290  0.000687  0.007399   \n",
       "21  0.000295  0.000657  0.818488      0.943964  0.000286  0.000649  0.007298   \n",
       "22  0.000291  0.000588  0.819182      0.943964  0.000282  0.000580  0.007224   \n",
       "23  0.000288  0.000549  0.818785      0.943964  0.000280  0.000542  0.007157   \n",
       "24  0.000285  0.000500  0.819171      0.943964  0.000277  0.000493  0.007080   \n",
       "25  0.000281  0.000451  0.818942      0.943964  0.000274  0.000444  0.007002   \n",
       "26  0.000279  0.000418  0.819024      0.943964  0.000272  0.000412  0.006935   \n",
       "27  0.000273  0.000414  0.819906      0.943964  0.000266  0.000408  0.006842   \n",
       "28  0.000259  0.000322  0.833948      0.943964  0.000253  0.000316  0.006564   \n",
       "29  0.000254  0.000297  0.834282      0.943964  0.000249  0.000292  0.006475   \n",
       "30  0.000252  0.000285  0.834038      0.943964  0.000247  0.000281  0.006407   \n",
       "31  0.000249  0.000261  0.834519      0.943964  0.000245  0.000257  0.006338   \n",
       "32  0.000247  0.000251  0.834232      0.943964  0.000244  0.000248  0.006282   \n",
       "33  0.000239  0.000217  0.848234      0.943964  0.000237  0.000215  0.006217   \n",
       "34  0.000234  0.000200  0.850103      0.943964  0.000232  0.000198  0.006052   \n",
       "35  0.000212  0.000165  0.889147      0.943964  0.000211  0.000164  0.005709   \n",
       "36  0.000167  0.000164  0.943819      0.943964  0.000165  0.000163  0.004992   \n",
       "37  0.000163  0.000164  0.943820      0.943964  0.000162  0.000163  0.004863   \n",
       "38  0.000161  0.000163  0.943819      0.943964  0.000160  0.000162  0.004799   \n",
       "39  0.000161  0.000163  0.943820      0.943964  0.000160  0.000162  0.004771   \n",
       "40  0.000160  0.000163  0.943819      0.943964  0.000159  0.000162  0.004761   \n",
       "41  0.000160  0.000163  0.943819      0.943964  0.000159  0.000163  0.004755   \n",
       "42  0.000160  0.000163  0.943818      0.943964  0.000159  0.000162  0.004751   \n",
       "43  0.000159  0.000163  0.943819      0.943964  0.000159  0.000162  0.004747   \n",
       "44  0.000159  0.000163  0.943821      0.943964  0.000158  0.000162  0.004744   \n",
       "45  0.000159  0.000163  0.943819      0.943964  0.000158  0.000163  0.004744   \n",
       "46  0.000158  0.000163  0.943819      0.943964  0.000157  0.000163  0.004740   \n",
       "47  0.000157  0.000163  0.943819      0.943964  0.000157  0.000163  0.004733   \n",
       "48  0.000156  0.000163  0.943819      0.943964  0.000155  0.000163  0.004721   \n",
       "49  0.000154  0.000163  0.943820      0.943964  0.000153  0.000162  0.004696   \n",
       "\n",
       "     Val MAE      RMSE  Val RMSE  \n",
       "0   0.081176  0.396298  0.025814  \n",
       "1   0.019467  0.177375  0.001238  \n",
       "2   0.014336  0.075156  0.000688  \n",
       "3   0.012314  0.041015  0.000637  \n",
       "4   0.011830  0.028593  0.000617  \n",
       "5   0.011716  0.023846  0.000608  \n",
       "6   0.011731  0.021741  0.000601  \n",
       "7   0.012427  0.020209  0.000633  \n",
       "8   0.013413  0.018515  0.000706  \n",
       "9   0.013788  0.017382  0.000741  \n",
       "10  0.013934  0.016745  0.000756  \n",
       "11  0.014253  0.016310  0.000792  \n",
       "12  0.014345  0.015970  0.000802  \n",
       "13  0.014272  0.015673  0.000794  \n",
       "14  0.014342  0.015477  0.000802  \n",
       "15  0.014413  0.015284  0.000811  \n",
       "16  0.014560  0.014438  0.000829  \n",
       "17  0.014497  0.013160  0.000821  \n",
       "18  0.014293  0.012720  0.000795  \n",
       "19  0.013872  0.012560  0.000743  \n",
       "20  0.013401  0.012448  0.000687  \n",
       "21  0.013062  0.012302  0.000649  \n",
       "22  0.012411  0.012192  0.000580  \n",
       "23  0.012019  0.012103  0.000542  \n",
       "24  0.011490  0.011991  0.000493  \n",
       "25  0.010912  0.011883  0.000444  \n",
       "26  0.010486  0.011797  0.000412  \n",
       "27  0.010426  0.011671  0.000408  \n",
       "28  0.008986  0.011220  0.000316  \n",
       "29  0.008504  0.011131  0.000292  \n",
       "30  0.008245  0.011052  0.000281  \n",
       "31  0.007641  0.010970  0.000257  \n",
       "32  0.007323  0.010915  0.000248  \n",
       "33  0.006281  0.010731  0.000215  \n",
       "34  0.005857  0.010538  0.000198  \n",
       "35  0.004766  0.009867  0.000164  \n",
       "36  0.004751  0.008632  0.000163  \n",
       "37  0.004855  0.008507  0.000163  \n",
       "38  0.004787  0.008455  0.000162  \n",
       "39  0.004810  0.008429  0.000162  \n",
       "40  0.004789  0.008426  0.000162  \n",
       "41  0.004835  0.008419  0.000163  \n",
       "42  0.004788  0.008413  0.000162  \n",
       "43  0.004794  0.008402  0.000162  \n",
       "44  0.004801  0.008392  0.000162  \n",
       "45  0.004839  0.008388  0.000163  \n",
       "46  0.004821  0.008371  0.000163  \n",
       "47  0.004751  0.008346  0.000163  \n",
       "48  0.004780  0.008296  0.000163  \n",
       "49  0.004770  0.008222  0.000162  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame(history2.history['loss'],columns=[\"Loss\"])\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"val_loss\"],columns=[\"Val Loss\"]))\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"accuracy\"],columns=['Accuracy']))\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"val_accuracy\"],columns=['Val Accuracy']))\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"mse\"],columns=['MSE']))\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"val_mse\"],columns=['Val MSE']))\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"mae\"],columns=['MAE']))\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"val_mae\"],columns=['Val MAE']))\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"rmse\"],columns=['RMSE']))\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"val_mse\"],columns=['Val RMSE']))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_excel(\"GRU_tanh_mse.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"gru_tanh_mse.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"gru_tanh_mse.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "[0.0006592384306713939, 0.22406166791915894, 0.0006567109376192093, 0.012324623763561249, 0.023422222584486008]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.25, random_state=42)\n",
    "\n",
    "from keras.models import model_from_json\n",
    "json_file = open('gru_tanh_mse.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"gru_tanh_mse.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "loaded_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),loss='mse',metrics=['accuracy','mse','mae',rmse])\n",
    "print(loaded_model.evaluate(x_train, y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13518/13518 [==============================] - 28s 2ms/step - loss: 6.5882e-04 - accuracy: 0.2249 - mse: 6.5629e-04 - mae: 0.0123 - rmse: 0.0234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0006588164833374321,\n",
       " 0.22491858899593353,\n",
       " 0.0006562928319908679,\n",
       " 0.012329255230724812,\n",
       " 0.02341914176940918]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(loaded_model.evaluate(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40554/40554 [==============================] - 86s 2ms/step - loss: 6.5924e-04 - accuracy: 0.2241 - mse: 6.5671e-04 - mae: 0.0123 - rmse: 0.0234\n",
      "[0.0006592384306713939, 0.22406166791915894, 0.0006567109376192093, 0.012324623763561249, 0.023422222584486008]\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.evaluate(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhYElEQVR4nO3de5gc1X3m8e/bPT2aGWkA3VAsCZCQJQxxiFiEDME4XIwtMAY7YMAYP8TrRPZu/NjZENaQ2HhN1lkS7zqOE2yDY218BWMIsbKWl4sBOwkGdDGJueuyAo24SEgI0GU0l/7tH1U9ao16Ri1palrqej/P009XV52qPjVq9dt1TtUpRQRmZmaDFRpdATMzOzg5IMzMrCYHhJmZ1eSAMDOzmhwQZmZWkwPCzMxqckCYjQBJfy/pv9dZdq2kdx7odsyy5oAwM7OaHBBmZlaTA8JyI23auUbSv0vaJumbkqZI+omkNyTdJ2l8VfkLJT0haYukByUdX7XsJEkr0vV+ALQNeq8LJD2WrvuQpBP3s86/L2mVpM2SFkuams6XpL+StEHS65J+Jemt6bLzJT2Z1m29pD/erz+Y5Z4DwvLmYuBcYA7wXuAnwJ8Ak0n+P3wSQNIc4FbgD9NlS4B/ktQqqRX4R+A7wATgh+l2Sdc9CVgEfAyYCNwMLJY0Zl8qKuls4H8AlwJvAp4DbksXvwt4R7ofh6dlNqXLvgl8LCI6gbcC9+/L+5pVOCAsb/4mIl6OiPXAPwOPRMQvI6IbuAs4KS13GfDjiLg3InqB/wm0A78FnAqUgC9HRG9E3AEsrXqPhcDNEfFIRPRHxLeAnel6++JDwKKIWBERO4HrgNMkzQB6gU7gLYAi4qmIeDFdrxc4QdJhEfFqRKzYx/c1AxwQlj8vV03vqPF6XDo9leQXOwARUQbWAdPSZetj95Eun6uaPga4Om1e2iJpC3BUut6+GFyHrSRHCdMi4n7gb4GbgA2SbpF0WFr0YuB84DlJP5N02j6+rxnggDAbygskX/RA0uZP8iW/HngRmJbOqzi6anod8IWIOKLq0RERtx5gHcaSNFmtB4iIr0TEycAJJE1N16Tzl0bERcCRJE1ht+/j+5oBDgizodwOvEfSOZJKwNUkzUQPAb8A+oBPSipJ+h1gftW63wA+LultaWfyWEnvkdS5j3W4FfiIpLlp/8WfkzSJrZV0Srr9ErAN6AbKaR/JhyQdnjaNvQ6UD+DvYDnmgDCrISKeAa4E/gZ4haRD+70R0RMRPcDvAL8LbCbpr/iHqnWXAb9P0gT0KrAqLbuvdbgP+CxwJ8lRyyzg8nTxYSRB9CpJM9Qm4Ivpsg8DayW9DnycpC/DbJ/JNwwyM7NafARhZmY1OSDMzKwmB4SZmdXkgDAzs5paGl2BkTJp0qSYMWNGo6thZnZIWb58+SsRMbnWsqYJiBkzZrBs2bJGV8PM7JAi6bmhlrmJyczManJAmJlZTQ4IMzOrqWn6IGrp7e2lq6uL7u7uRlclc21tbUyfPp1SqdToqphZk2jqgOjq6qKzs5MZM2aw+8CbzSUi2LRpE11dXcycObPR1TGzJtHUTUzd3d1MnDixqcMBQBITJ07MxZGSmY2epg4IoOnDoSIv+2lmo6fpA2Jv+svBS693s72nr9FVMTM7qOQ+ICKCDa93s72nP5Ptb9myha9+9av7vN7555/Pli1bRr5CZmZ1yn1AFNKmmXJG98UYKiD6+oY/YlmyZAlHHHFEJnUyM6tHU5/FVI9K0305o5syXnvttaxevZq5c+dSKpVoa2tj/PjxPP300zz77LO8733vY926dXR3d/OpT32KhQsXAruGDtm6dSvnnXceb3/723nooYeYNm0aP/rRj2hvb8+mwmZmqdwExOf/6QmefOH1msu29fRRKhRobdm3A6oTph7G597768OWufHGG3n88cd57LHHePDBB3nPe97D448/PnA66qJFi5gwYQI7duzglFNO4eKLL2bixIm7bWPlypXceuutfOMb3+DSSy/lzjvv5Morr9ynupqZ7avcBMRwhBitG6/Onz9/t2sVvvKVr3DXXXcBsG7dOlauXLlHQMycOZO5c+cCcPLJJ7N27dpRqq2Z5VluAmK4X/pPv/g6Y8e0cNSEjszrMXbs2IHpBx98kPvuu49f/OIXdHR0cOaZZ9a8lmHMmDED08VikR07dmReTzOz3HdSAxQKyqyTurOzkzfeeKPmstdee43x48fT0dHB008/zcMPP5xJHczM9kdujiCGU5AoZ9TGNHHiRE4//XTe+ta30t7ezpQpUwaWLViwgK9//escf/zxHHfccZx66qnZVMLMbD8oMvrlPNrmzZsXg28Y9NRTT3H88cfvdd3VG7dCwKwjx2VVvVFR7/6amVVIWh4R82otcxMTUFR2TUxmZocqBwTJtRBZNTGZmR2qMg0ISQskPSNplaRrayz/I0lPSvp3ST+VdEzVsqskrUwfV2VZz4KPIMzM9pBZQEgqAjcB5wEnAB+UdMKgYr8E5kXEicAdwF+m604APge8DZgPfE7S+Kzq6oAwM9tTlkcQ84FVEbEmInqA24CLqgtExAMRsT19+TAwPZ1+N3BvRGyOiFeBe4EFWVW0UADng5nZ7rIMiGnAuqrXXem8oXwU+Mm+rCtpoaRlkpZt3LhxvytaOYJoljO6zMxGwkHRSS3pSmAe8MV9WS8ibomIeRExb/Lkyfv9/oXKgH0Z5MP+DvcN8OUvf5nt27fvvaCZWQayDIj1wFFVr6en83Yj6Z3AnwIXRsTOfVl3pGQ55LcDwswOVVleSb0UmC1pJsmX++XAFdUFJJ0E3AwsiIgNVYvuBv68qmP6XcB1WVVUGQZE9XDf5557LkceeSS33347O3fu5P3vfz+f//zn2bZtG5deeildXV309/fz2c9+lpdffpkXXniBs846i0mTJvHAAw+MeN3MzIaTWUBERJ+kT5B82ReBRRHxhKQbgGURsZikSWkc8MP0S/r5iLgwIjZL+jOSkAG4ISI2H1CFfnItvPSrmosOK5c5trdMqbW46wYR9fi134Dzbhy2SPVw3/fccw933HEHjz76KBHBhRdeyM9//nM2btzI1KlT+fGPfwwkYzQdfvjhfOlLX+KBBx5g0qRJ9dfJzGyEZDoWU0QsAZYMmnd91fQ7h1l3EbAou9rVeM+Mt3/PPfdwzz33cNJJJwGwdetWVq5cyRlnnMHVV1/Npz/9aS644ALOOOOMjGtiZrZ3+Rmsb5hf+t3dfax5ZSvHThrLuLZSZlWICK677jo+9rGP7bFsxYoVLFmyhM985jOcc845XH/99TW2YGY2eg6Ks5garZD+FbI4i6l6uO93v/vdLFq0iK1btwKwfv16NmzYwAsvvEBHRwdXXnkl11xzDStWrNhjXTOz0ZafI4hhZHkWU/Vw3+eddx5XXHEFp512GgDjxo3ju9/9LqtWreKaa66hUChQKpX42te+BsDChQtZsGABU6dOdSe1mY06D/cN9PT18/RLbzB9fAcTxrZmVcXMebhvM9tXHu57L7I8zdXM7FDlgCDbJiYzs0NV0wdEPU1oWQ61MVqapanQzA4eTR0QbW1tbNq0aa9fnpIoSIfsl2xEsGnTJtra2hpdFTNrIk19FtP06dPp6uqinpFeN2zZwRutRbZ0HJqd1G1tbUyfPn3vBc3M6tTUAVEqlZg5c2ZdZX/vxvs59diJ/K9LfRaQmRk0eRPTvmhvLbKjt6/R1TAzO2g4IFLtpSLbe/obXQ0zs4OGAyLV3lpkhwPCzGyAAyLVXiqyo9cBYWZW4YBIdfgIwsxsNw6IVHur+yDMzKo5IFLtpSLdbmIyMxvggEh1+AjCzGw3DohUpZO6fCgPyGRmNoIcEKn21uSi8p195QbXxMzs4OCASLWXkj/F9h5fTW1mBg6IAR3pEYSvhTAzSzggUu2tRQBfC2FmlnJApNpLaUD4CMLMDHBADOhIjyB8qquZWcIBkWpzE5OZ2W4cEKnKEYSbmMzMEg6IVKUPwk1MZmYJB0Sq3UcQZma7cUCkBq6D8IVyZmaAA2KAm5jMzHbngEgVC6K1peAmJjOzlAOiSnvJd5UzM6twQFTxbUfNzHZxQFRpLxXZ7iYmMzPAAbGb9tYi3T6CMDMDHBC78W1Hzcx2yTQgJC2Q9IykVZKurbH8HZJWSOqTdMmgZf2SHksfi7OsZ0Wbm5jMzAa0ZLVhSUXgJuBcoAtYKmlxRDxZVex54HeBP66xiR0RMTer+tXS0Vpkw+s7R/MtzcwOWpkFBDAfWBURawAk3QZcBAwERESsTZcdFDeCTjqpfSW1mRlk28Q0DVhX9bornVevNknLJD0s6X21CkhamJZZtnHjxgOoaqK9tYUdPQdFVpmZNdzB3El9TETMA64Avixp1uACEXFLRMyLiHmTJ08+4DdMLpTzEYSZGWQbEOuBo6peT0/n1SUi1qfPa4AHgZNGsnK1dLQW2dHbT0Rk/VZmZge9LANiKTBb0kxJrcDlQF1nI0kaL2lMOj0JOJ2qvoustLcWKQfs7HMzk5lZZgEREX3AJ4C7gaeA2yPiCUk3SLoQQNIpkrqADwA3S3oiXf14YJmkfwMeAG4cdPZTJiojunq4DTOzbM9iIiKWAEsGzbu+anopSdPT4PUeAn4jy7rVUn3b0fGj/eZmZgeZg7mTetRV7irnq6nNzBwQu6k0MXX7amozMwdENR9BmJnt4oCoUt0HYWaWdw6IKu2lpM/eF8uZmTkgduMmJjOzXRwQVdzEZGa2iwOiSpsvlDMzG+CAqDJwBOGAMDNzQFQrFQu0FOS7ypmZ4YDYQ3tr0UcQZmY4IPbQ4YAwMwMcEHtIbjvqgDAzc0AMktx21AFhZuaAGKS9VGBHr6+kNjNzQAzS4SMIMzPAAbGHtlLRQ22YmeGA2ENHa9H3gzAzwwGxh45WH0GYmYEDYg9tJV8HYWYGDog9dLQWPZqrmRkOiD20l4r0lYOevnKjq2Jm1lAOiEHafU8IMzPAAbGHdg/5bWYGOCD20DFw21FfTW1m+eaAGKS91AK4icnMzAExiJuYzMwSdQWEpE9JOkyJb0paIeldWVeuETrcSW1mBtR/BPEfI+J14F3AeODDwI2Z1aqB2kuVPggHhJnlW70BofT5fOA7EfFE1bymUmli8nhMZpZ39QbEckn3kATE3ZI6gaa8ksxHEGZmiZY6y30UmAusiYjtkiYAH8msVg206zRXB4SZ5Vu9RxCnAc9ExBZJVwKfAV7LrlqN4yYmM7NEvQHxNWC7pN8ErgZWA9/OrFYN1FosUJAvlDMzqzcg+iIigIuAv42Im4DO7KrVOJLS2442ZReLmVnd6u2DeEPSdSSnt54hqQCUsqtWY7WViuzo9RGEmeVbvUcQlwE7Sa6HeAmYDnwxs1o1WEerbxpkZlZXQKSh8D3gcEkXAN0Rsdc+CEkLJD0jaZWka2ssf0d6VXafpEsGLbtK0sr0cVWd+zMi2ku+7aiZWb1DbVwKPAp8ALgUeGTwF3qNdYrATcB5wAnAByWdMKjY88DvAt8ftO4E4HPA24D5wOckja+nriOh3XeVMzOruw/iT4FTImIDgKTJwH3AHcOsMx9YFRFr0nVuI+nkfrJSICLWpssG9wi/G7g3Ijany+8FFgC31lnfA+ImJjOz+vsgCpVwSG2qY91pwLqq113pvHrUta6khZKWSVq2cePGOje9d25iMjOr/wji/0q6m12/4C8DlmRTpfpFxC3ALQDz5s2Lkdpue2vRF8qZWe7VFRARcY2ki4HT01m3RMRde1ltPXBU1evp6bx6rAfOHLTug3Wue8B8BGFmVv8RBBFxJ3DnPmx7KTBb0kySL/zLgSvqXPdu4M+rOqbfBVy3D+99QDrcSW1mNnxASHoDqNV0IyAi4rCh1o2IPkmfIPmyLwKLIuIJSTcAyyJisaRTgLtI7jHxXkmfj4hfj4jNkv6MJGQAbqh0WI+GNndSm5kNHxARcUDDaUTEEgb1VUTE9VXTS0maj2qtuwhYdCDvv786Si309Jfp6y/TUvRdWc0sn/ztV4NvO2pm5oCoqa0SEG5mMrMcc0DU0FHyEYSZmQOihnbfVc7MzAFRS7v7IMzMHBC1tJfcB2Fm5oCoocNNTGZmDohafJqrmZkDoqa2gSYm33bUzPLLAVFDR2tygbn7IMwszxwQNVQ6qbe7icnMcswBUUNbKfmz+AjCzPLMAVGDJNpLHtHVzPLNATGEjtaim5jMLNccEENoby3S7SMIM8sxB8QQfNtRM8s7B8QQfNtRM8s7B8QQ2txJbWY554AYQtJJ7SupzSy/HBBDaG/1EYSZ5ZsDYgjtpRYHhJnlmgNiCO6kNrO8c0AMob3Vp7maWb45IIbQXiqys69MuRyNroqZWUM4IIbg+1KbWd45IIbg246aWd45IIZQuatct48gzCynHBBD8BGEmeWdA2IIHe6DMLOcc0AModLEtL3Hw22YWT45IIbQ0doCuA/CzPLLATGE9pL7IMws3xwQQ3AntZnlnQNiCD7N1czyzgExBB9BmFneOSCGUOmD8JDfZpZXDoghFApiTEvB10GYWW5lGhCSFkh6RtIqSdfWWD5G0g/S5Y9ImpHOnyFph6TH0sfXs6znUDp8Vzkzy7GWrDYsqQjcBJwLdAFLJS2OiCerin0UeDUi3izpcuAvgMvSZasjYm5W9atHR2sLW3f6Qjkzy6csjyDmA6siYk1E9AC3ARcNKnMR8K10+g7gHEnKsE775JiJHax5ZVujq2Fm1hBZBsQ0YF3V6650Xs0yEdEHvAZMTJfNlPRLST+TdEatN5C0UNIyScs2btw4srUH5kzpZNXLb/imQWaWSwdrJ/WLwNERcRLwR8D3JR02uFBE3BIR8yJi3uTJk0e8ErOnjGNbTz/rt+wY8W2bmR3ssgyI9cBRVa+np/NqlpHUAhwObIqInRGxCSAilgOrgTkZ1rWm46Z0ArBywxuj/dZmZg2XZUAsBWZLmimpFbgcWDyozGLgqnT6EuD+iAhJk9NObiQdC8wG1mRY15pmpwHx7MtbR/utzcwaLrOzmCKiT9IngLuBIrAoIp6QdAOwLCIWA98EviNpFbCZJEQA3gHcIKkXKAMfj4jNWdV1KIe3l5hy2BiefclHEGaWP5kFBEBELAGWDJp3fdV0N/CBGuvdCdyZZd3qNWdKJ8+6icnMcuhg7aQ+aMyZ0smqDVt9JpOZ5Y4DYi/mTBlHd2+Zda9ub3RVzMxGlQNiLyod1c+4H8LMcsYBsRezjxwHwMoNPpPJzPLFAbEXnW0lph3RzrMv+wjCzPLFAVGH2VPGuYnJzHLHAVGH46Z0smbjNvr6y42uipnZqHFA1GH2lE56+ss8t9lnMplZfjgg6jBnStJR7SuqzSxPHBB1eHN6JpPHZDKzPHFA1KGjtYWjJ3R4yA0zyxUHRJ3mTBnHSp/qamY54oCo0+z0TKaePp/JZGb54ICo03FTOukrB2s3+R7VZpYPDoiebfCrO2DT6mGLza6cyeRmJjPLCQdEzza486PwxF3DFps1eRwF+VRXM8sPB8S4I+HXfgNWPzBssbZSkRkTx/pUVzPLDQcEwKyzYd0jsHP4o4PZU8b5VFczyw0HBCQBUe6Ftf86bLE5UzpZ+8o2unv7R6liZmaN44AAOOpUaGmHNcM3M82e0kk5YM1Gn8lkZs3PAQFQaoMZp8Pq+4ctdlx6d7mVbmYysxxwQFTMOhteeRa2rBuyyMxJY2kpyKe6mlkuOCAqZp2dPA/TzNTaUmDGpLE885LPZDKz5ueAqJj8Fuh8U13NTG5iMrM8cEBUSHDsWbDmQSgPfZbS7CnjeH7zdnb0+EwmM2tuDohqs86GHa/Ci48NWWTOlE4iYNUGNzOZWXNzQFQ79szkeZhmpjnpmUzuqDazZueAqDZuMvzaicMOuzFjYgetxYKvqDazpueAGGzW2bDu0SGH3WgpFjh28lgP2mdmTc8BMVgdw27MPeoI/nX1JpY/t3kUK2ZmNrocEIMdnQ67MUw/xKcXvIWph7fx+99ezvObto9i5czMRo8DYrCWMTDj7cMGxPixrfzvj8ynHMFH/v5RXtveO4oVNDMbHQ6IWmadDZtWwpbnhywyc9JYbr7yZJ7fvJ3/9L3lvle1mTUdB0Qts85KnvdyE6G3HTuRv7zkRB5avYk/vetXRMQoVM7MbHQ4IGqpc9gNgPefNJ1PnjObHy7v4qsPDn9fazOzQ0lLoytwUJKSZqanf5wMu1EoDlv8v7xzNs9t2sYX736GYyZ2cMGJU0epomZm2fERxFBmnQ3dW4YddqNCEn9x8YmcMmM8n/j+Lzn/r/+ZL93zDI+t20K57GYnMzs0Kct2c0kLgL8GisDfRcSNg5aPAb4NnAxsAi6LiLXpsuuAjwL9wCcj4u7h3mvevHmxbNmykav8tlfgi7OSoJh1dtLkdNjU5NH5puRsp0Fe7+7l+488z/1PbWDZc5spB0wa18pZxx3Jbx83mWMmjGVy5xgmjmulVHQ2m1njSVoeEfNqLssqICQVgWeBc4EuYCnwwYh4sqrMfwZOjIiPS7oceH9EXCbpBOBWYD4wFbgPmBMRQw6hOuIBAXDn7yXNTL01rnVo7UxCoqVt0PMYKJbopYVXdgQvbS3zwtZ+tvcV6KVIP0X6KFJsaaV1TCtjWsdQbClRKLZQLLZQbCmlzy0UikWKhQJFiUKhQLEoioVCMk1QEOkjBl5LyRFNgWS6kL5W+jp5VuXvn7wmgICItEyggR0V0u67XtkWVLazZ9gNrDP481U1PykTA4exlUWVeg7UMa3nrg1r92cVqh6DXw/1SMtVb4P0uVBM5xXT6ar1KmVUXYc63mfwvMH7UP1c64+pAhRakvoUWtK6+UeGHbjhAiLLPoj5wKqIWJNW4jbgIuDJqjIXAf8tnb4D+Fsl314XAbdFxE7g/0lalW7vFxnWd08X/13yBdf9GrzxIrz+Qvr8IuzYDH0700d3+qhM91Dq38qbopc3tfUwt9RDb89Oyv290N+Hyr0Q/RR29lHc2UcBN0PZvisPRPuuSK9MVz5Ru6J+V/DEHuW0W9nB60b6Cd21Tq33UI1tD6pXjQDUHhO2P14ZO4f/cPU/jvh2swyIaUD1/Tu7gLcNVSYi+iS9BkxM5z88aN1pg99A0kJgIcDRRx89YhUf9CbQfkTyOPL4/dsE0DpcgXIZoh/KfUmneLmPvr5eevv66SuX6e3rp78c9PT1099fpq+/n/4Q/QF9QfLcnzz3B/SXg6hMR1AuR/IfN5L55YHnMhEDxw/Jf+IQ5bTWyToQxMCBQJDOJKqmIcrlgcOG6rhL1t/zf39EpO8HISgnBzCUK+tEUE4rVo5K/ZOvxIhAEUTlayrKECDKkJYRZVQuJ3sV6esoI8oUoszA11hU7+2uMordyyuqt1X5eoyq94u0fLrN6E+n0/euLK9678rfrvprfuDvU/35iUDRj6JMgT5ULlOgn0L6HsTu8bDrqK16+7v/o9R6z93KVm1DUFXvdF713223o8SoqlNl2a7p3WpW9XpfNM3PqRHckZ7DZozcxqoc0mcxRcQtwC2QNDE1uDr7r1AAClAsDcxq4RD/xzGzQ16WjZjrgaOqXk9P59UsI6kFOJyks7qedc3MLENZBsRSYLakmZJagcuBxYPKLAauSqcvAe6PpNd8MXC5pDGSZgKzgUczrKuZmQ2SWStG2qfwCeBuktNcF0XEE5JuAJZFxGLgm8B30k7ozSQhQlrudpIO7T7gD4Y7g8nMzEZeptdBjKZMTnM1M2tyw53m6hOpzcysJgeEmZnV5IAwM7OaHBBmZlZT03RSS9oIPHcAm5gEvDJC1TmUeL/zxfudL/Xs9zERMbnWgqYJiAMladlQPfnNzPudL97vfDnQ/XYTk5mZ1eSAMDOzmhwQu9zS6Ao0iPc7X7zf+XJA++0+CDMzq8lHEGZmVpMDwszMasp9QEhaIOkZSaskXdvo+mRJ0iJJGyQ9XjVvgqR7Ja1Mn8c3so4jTdJRkh6Q9KSkJyR9Kp3f7PvdJulRSf+W7vfn0/kzJT2Sft5/kA7F33QkFSX9UtL/SV/nZb/XSvqVpMckLUvn7fdnPdcBIakI3AScB5wAfFDSCY2tVab+HlgwaN61wE8jYjbw0/R1M+kDro6IE4BTgT9I/42bfb93AmdHxG8Cc4EFkk4F/gL4q4h4M/Aq8NHGVTFTnwKeqnqdl/0GOCsi5lZd/7Dfn/VcBwQwH1gVEWsioge4DbiowXXKTET8nOS+G9UuAr6VTn8LeN9o1ilrEfFiRKxIp98g+dKYRvPvd0TE1vRlKX0EcDZwRzq/6fYbQNJ04D3A36WvRQ72exj7/VnPe0BMA9ZVve5K5+XJlIh4MZ1+CZjSyMpkSdIM4CTgEXKw32kzy2PABuBeYDWwJSL60iLN+nn/MvBfgXL6eiL52G9IfgTcI2m5pIXpvP3+rGd2Rzk79ERESGrK854ljQPuBP4wIl5PflQmmnW/07swzpV0BHAX8JbG1ih7ki4ANkTEcklnNrg6jfD2iFgv6UjgXklPVy/c18963o8g1gNHVb2ens7Lk5clvQkgfd7Q4PqMOEklknD4XkT8Qzq76fe7IiK2AA8ApwFHSKr8MGzGz/vpwIWS1pI0GZ8N/DXNv98ARMT69HkDyY+C+RzAZz3vAbEUmJ2e4dBKck/sxQ2u02hbDFyVTl8F/KiBdRlxafvzN4GnIuJLVYuafb8np0cOSGoHziXpf3kAuCQt1nT7HRHXRcT0iJhB8v/5/oj4EE2+3wCSxkrqrEwD7wIe5wA+67m/klrS+SRtlkVgUUR8obE1yo6kW4EzSYYAfhn4HPCPwO3A0STDpV8aEYM7sg9Zkt4O/DPwK3a1Sf8JST9EM+/3iSQdkkWSH4K3R8QNko4l+WU9AfglcGVE7GxcTbOTNjH9cURckIf9TvfxrvRlC/D9iPiCpIns52c99wFhZma15b2JyczMhuCAMDOzmhwQZmZWkwPCzMxqckCYmVlNDgizg4CkMysjj5odLBwQZmZWkwPCbB9IujK9z8Jjkm5OB8TbKumv0vsu/FTS5LTsXEkPS/p3SXdVxuGX9GZJ96X3alghaVa6+XGS7pD0tKTvqXrAKLMGcECY1UnS8cBlwOkRMRfoBz4EjAWWRcSvAz8juUId4NvApyPiRJIruSvzvwfclN6r4beAykibJwF/SHJvkmNJxhUyaxiP5mpWv3OAk4Gl6Y/7dpKBz8rAD9Iy3wX+QdLhwBER8bN0/reAH6Zj5UyLiLsAIqIbIN3eoxHRlb5+DJgB/Evme2U2BAeEWf0EfCsirtttpvTZQeX2d/ya6rGB+vH/T2swNzGZ1e+nwCXpWPuVe/0eQ/L/qDJS6BXAv0TEa8Crks5I538Y+Fl6V7suSe9LtzFGUsdo7oRZvfwLxaxOEfGkpM+Q3LGrAPQCfwBsA+anyzaQ9FNAMrTy19MAWAN8JJ3/YeBmSTek2/jAKO6GWd08mqvZAZK0NSLGNboeZiPNTUxmZlaTjyDMzKwmH0GYmVlNDggzM6vJAWFmZjU5IMzMrCYHhJmZ1fT/AcDy0GFETxbNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18c7c3e7400>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.06554516, 0.        , ..., 0.01927156, 0.01238301,\n",
       "        0.        ],\n",
       "       [0.        , 0.06554849, 0.        , ..., 0.01927139, 0.01237817,\n",
       "        0.        ],\n",
       "       [0.        , 0.06554811, 0.        , ..., 0.01927198, 0.01237819,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.06554803, 0.        , ..., 0.01927239, 0.01237794,\n",
       "        0.        ],\n",
       "       [0.        , 0.06554521, 0.        , ..., 0.01927139, 0.01238317,\n",
       "        0.        ],\n",
       "       [0.        , 0.06554838, 0.        , ..., 0.01927189, 0.01237781,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.25, random_state=42)\n",
    "\n",
    "y_test_pred=model.predict(x_test)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00011559, 0.06553685, 0.00011085, ..., 0.0021448 ,\n",
       "         0.0014142 , 0.00052142]],\n",
       "\n",
       "       [[0.00011088, 0.06553695, 0.00012144, ..., 0.01090628,\n",
       "         0.00639894, 0.00234271]],\n",
       "\n",
       "       [[0.0001138 , 0.06553686, 0.00011756, ..., 0.02938369,\n",
       "         0.01855402, 0.00761428]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.00011103, 0.06553663, 0.00011547, ..., 0.05674056,\n",
       "         0.03595096, 0.01243099]],\n",
       "\n",
       "       [[0.00011477, 0.06553688, 0.00010965, ..., 0.00815022,\n",
       "         0.00468672, 0.00148292]],\n",
       "\n",
       "       [[0.00010879, 0.06553657, 0.00012025, ..., 0.00375339,\n",
       "         0.00246608, 0.00081172]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "savetxt('gru_tanh_mse_y_test_pred.csv', y_test_pred[:1001], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "savetxt('gru_tanh_mse_y_test.csv', y_test[:1001], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#completed"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
