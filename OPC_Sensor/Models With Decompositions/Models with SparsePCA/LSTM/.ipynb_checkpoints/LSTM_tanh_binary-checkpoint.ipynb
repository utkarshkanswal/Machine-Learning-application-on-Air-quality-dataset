{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "877c2677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c059e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96739d01",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0397420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os.path as op\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8cc09ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model,Sequential,load_model\n",
    "from keras.layers import Input, Embedding\n",
    "from keras.layers import Dense, Bidirectional\n",
    "from keras.layers.recurrent import LSTM\n",
    "import keras.metrics as metrics\n",
    "import itertools\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from decimal import Decimal\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv1D,MaxPooling1D,Flatten,Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f9474e",
   "metadata": {},
   "source": [
    "# Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7450b0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.50000e+02 1.90401e+05 7.25000e+02 2.75500e+01 8.03900e+01]\n",
      " [1.50000e+02 1.90401e+05 8.25000e+02 2.75600e+01 8.03300e+01]\n",
      " [1.50000e+02 1.90401e+05 9.25000e+02 2.75800e+01 8.02400e+01]\n",
      " ...\n",
      " [6.10000e+01 1.91020e+05 1.94532e+05 2.93700e+01 7.52100e+01]\n",
      " [6.10000e+01 1.91020e+05 1.94632e+05 2.93500e+01 7.52700e+01]\n",
      " [6.10000e+01 1.91020e+05 1.94732e+05 2.93400e+01 7.53000e+01]]\n",
      "[[ 28.     3.   -52.   ...  16.97  19.63  20.06]\n",
      " [ 28.    15.   -53.   ...  16.63  19.57  23.06]\n",
      " [ 31.    16.   -55.   ...  17.24  19.98  20.24]\n",
      " ...\n",
      " [ 76.    12.   -76.   ...   3.47   3.95   4.35]\n",
      " [ 75.    13.   -76.   ...   3.88   4.33   4.42]\n",
      " [ 76.    12.   -75.   ...   3.46   4.07   4.28]]\n"
     ]
    }
   ],
   "source": [
    "A1=np.empty((0,5),dtype='float32')\n",
    "U1=np.empty((0,7),dtype='float32')\n",
    "node=['150','149','147','144','142','140','136','61']\n",
    "mon=['Apr','Mar','Aug','Jun','Jul','Sep','May','Oct']\n",
    "for j in node:\n",
    "  for i in mon:\n",
    "    inp= pd.read_csv('../../../data_gkv/AT510_Node_'+str(j)+'_'+str(i)+'19_OutputFile.csv',usecols=[1,2,3,15,16])\n",
    "    out= pd.read_csv('../../../data_gkv/AT510_Node_'+str(j)+'_'+str(i)+'19_OutputFile.csv',usecols=[5,6,7,8,17,18,19])\n",
    "    \n",
    "    inp=np.array(inp,dtype='float32')\n",
    "    out=np.array(out,dtype='float32')\n",
    "    \n",
    "    A1=np.append(A1, inp, axis=0)\n",
    "    U1=np.append(U1, out, axis=0)\n",
    "\n",
    "print(A1)\n",
    "print(U1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ca5e86",
   "metadata": {},
   "source": [
    "# Min Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41ae9a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "import warnings\n",
    "scaler_obj1=FastICA()\n",
    "scaler_obj2=FastICA()\n",
    "X1=scaler_obj1.fit_transform(A1)\n",
    "Y1=scaler_obj2.fit_transform(U1)\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "X1=X1[:,np.newaxis,:]\n",
    "Y1=Y1[:,np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da37491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1edf627",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d05d8053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 7)                 364       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7)                28        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 7)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 448\n",
      "Trainable params: 434\n",
      "Non-trainable params: 14\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(keras.Input(shape=(1,5)))\n",
    "model1.add(tf.keras.layers.LSTM(7,activation=\"tanh\",use_bias=True,kernel_initializer=\"glorot_uniform\",bias_initializer=\"zeros\"))\n",
    "model1.add(Dense(7))\n",
    "model1.add(keras.layers.BatchNormalization(axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,\n",
    "                                beta_initializer=\"zeros\",gamma_initializer=\"ones\",\n",
    "                                moving_mean_initializer=\"zeros\",moving_variance_initializer=\"ones\",trainable=True))\n",
    "model1.add(keras.layers.ReLU())\n",
    "model1.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5), loss='binary_crossentropy',metrics=['accuracy','mse','mae',rmse])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3393273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb37916d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4563/4563 [==============================] - 48s 10ms/step - loss: 1.2875 - accuracy: 0.0038 - mse: 0.1168 - mae: 0.1296 - rmse: 0.2079 - val_loss: 1.1173 - val_accuracy: 0.0177 - val_mse: 0.1091 - val_mae: 0.1181 - val_rmse: 0.1866\n",
      "Epoch 2/50\n",
      "4563/4563 [==============================] - 48s 10ms/step - loss: 1.0088 - accuracy: 0.1072 - mse: 0.1035 - mae: 0.1103 - rmse: 0.1718 - val_loss: 0.9560 - val_accuracy: 0.2445 - val_mse: 0.0997 - val_mae: 0.1031 - val_rmse: 0.1580\n",
      "Epoch 3/50\n",
      "4563/4563 [==============================] - 46s 10ms/step - loss: 0.9451 - accuracy: 0.3591 - mse: 0.0952 - mae: 0.0985 - rmse: 0.1514 - val_loss: 0.9276 - val_accuracy: 0.5031 - val_mse: 0.0893 - val_mae: 0.0928 - val_rmse: 0.1438\n",
      "Epoch 4/50\n",
      "4563/4563 [==============================] - 50s 11ms/step - loss: 0.9163 - accuracy: 0.5779 - mse: 0.0814 - mae: 0.0857 - rmse: 0.1364 - val_loss: 0.9021 - val_accuracy: 0.6481 - val_mse: 0.0752 - val_mae: 0.0780 - val_rmse: 0.1296\n",
      "Epoch 5/50\n",
      "4563/4563 [==============================] - 49s 11ms/step - loss: 0.8796 - accuracy: 0.7133 - mse: 0.0709 - mae: 0.0709 - rmse: 0.1254 - val_loss: 0.8926 - val_accuracy: 0.7581 - val_mse: 0.0686 - val_mae: 0.0671 - val_rmse: 0.1227\n",
      "Epoch 6/50\n",
      "4563/4563 [==============================] - 45s 10ms/step - loss: 0.7703 - accuracy: 0.7515 - mse: 0.0674 - mae: 0.0664 - rmse: 0.1217 - val_loss: 0.5708 - val_accuracy: 0.7663 - val_mse: 0.0647 - val_mae: 0.0645 - val_rmse: 0.1186\n",
      "Epoch 7/50\n",
      "4563/4563 [==============================] - 45s 10ms/step - loss: 0.5612 - accuracy: 0.7611 - mse: 0.0630 - mae: 0.0635 - rmse: 0.1174 - val_loss: 0.5417 - val_accuracy: 0.7665 - val_mse: 0.0624 - val_mae: 0.0626 - val_rmse: 0.1164\n",
      "Epoch 8/50\n",
      "4563/4563 [==============================] - 46s 10ms/step - loss: 0.5294 - accuracy: 0.7640 - mse: 0.0586 - mae: 0.0600 - rmse: 0.1131 - val_loss: 0.5150 - val_accuracy: 0.7666 - val_mse: 0.0548 - val_mae: 0.0568 - val_rmse: 0.1093\n",
      "Epoch 9/50\n",
      "4563/4563 [==============================] - 47s 10ms/step - loss: 0.5039 - accuracy: 0.7657 - mse: 0.0508 - mae: 0.0507 - rmse: 0.1054 - val_loss: 0.4924 - val_accuracy: 0.7666 - val_mse: 0.0481 - val_mae: 0.0444 - val_rmse: 0.1030\n",
      "Epoch 10/50\n",
      "4563/4563 [==============================] - 46s 10ms/step - loss: 0.4915 - accuracy: 0.7650 - mse: 0.0481 - mae: 0.0420 - rmse: 0.1032 - val_loss: 0.4897 - val_accuracy: 0.7666 - val_mse: 0.0479 - val_mae: 0.0417 - val_rmse: 0.1031\n",
      "Epoch 11/50\n",
      "4563/4563 [==============================] - 45s 10ms/step - loss: 0.4912 - accuracy: 0.7649 - mse: 0.0481 - mae: 0.0418 - rmse: 0.1035 - val_loss: 0.4896 - val_accuracy: 0.7666 - val_mse: 0.0484 - val_mae: 0.0418 - val_rmse: 0.1035\n",
      "Epoch 12/50\n",
      "4563/4563 [==============================] - 45s 10ms/step - loss: 0.4911 - accuracy: 0.7651 - mse: 0.0482 - mae: 0.0418 - rmse: 0.1037 - val_loss: 0.4896 - val_accuracy: 0.7666 - val_mse: 0.0485 - val_mae: 0.0419 - val_rmse: 0.1040\n",
      "Epoch 13/50\n",
      "4563/4563 [==============================] - 47s 10ms/step - loss: 0.4910 - accuracy: 0.7652 - mse: 0.0483 - mae: 0.0419 - rmse: 0.1039 - val_loss: 0.4895 - val_accuracy: 0.7666 - val_mse: 0.0484 - val_mae: 0.0417 - val_rmse: 0.1037\n",
      "Epoch 14/50\n",
      "4563/4563 [==============================] - 47s 10ms/step - loss: 0.4910 - accuracy: 0.7656 - mse: 0.0484 - mae: 0.0418 - rmse: 0.1039 - val_loss: 0.4895 - val_accuracy: 0.7666 - val_mse: 0.0486 - val_mae: 0.0416 - val_rmse: 0.1035\n",
      "Epoch 15/50\n",
      "4563/4563 [==============================] - 46s 10ms/step - loss: 0.4909 - accuracy: 0.7657 - mse: 0.0485 - mae: 0.0419 - rmse: 0.1041 - val_loss: 0.4894 - val_accuracy: 0.7666 - val_mse: 0.0486 - val_mae: 0.0420 - val_rmse: 0.1043\n",
      "Epoch 16/50\n",
      "4563/4563 [==============================] - 47s 10ms/step - loss: 0.4908 - accuracy: 0.7658 - mse: 0.0486 - mae: 0.0417 - rmse: 0.1039 - val_loss: 0.4893 - val_accuracy: 0.7666 - val_mse: 0.0488 - val_mae: 0.0417 - val_rmse: 0.1039\n",
      "Epoch 17/50\n",
      "4563/4563 [==============================] - 45s 10ms/step - loss: 0.4907 - accuracy: 0.7658 - mse: 0.0487 - mae: 0.0418 - rmse: 0.1040 - val_loss: 0.4892 - val_accuracy: 0.7666 - val_mse: 0.0488 - val_mae: 0.0417 - val_rmse: 0.1039\n",
      "Epoch 18/50\n",
      "4563/4563 [==============================] - 46s 10ms/step - loss: 0.4905 - accuracy: 0.7659 - mse: 0.0489 - mae: 0.0419 - rmse: 0.1043 - val_loss: 0.4890 - val_accuracy: 0.7666 - val_mse: 0.0489 - val_mae: 0.0417 - val_rmse: 0.1039\n",
      "Epoch 19/50\n",
      "4563/4563 [==============================] - 47s 10ms/step - loss: 0.4904 - accuracy: 0.7659 - mse: 0.0490 - mae: 0.0419 - rmse: 0.1044 - val_loss: 0.4888 - val_accuracy: 0.7666 - val_mse: 0.0487 - val_mae: 0.0416 - val_rmse: 0.1036\n",
      "Epoch 20/50\n",
      "4563/4563 [==============================] - 47s 10ms/step - loss: 0.4901 - accuracy: 0.7658 - mse: 0.0493 - mae: 0.0419 - rmse: 0.1044 - val_loss: 0.4886 - val_accuracy: 0.7666 - val_mse: 0.0496 - val_mae: 0.0418 - val_rmse: 0.1043\n",
      "Epoch 21/50\n",
      "4563/4563 [==============================] - 47s 10ms/step - loss: 0.4898 - accuracy: 0.7659 - mse: 0.0495 - mae: 0.0420 - rmse: 0.1045 - val_loss: 0.4880 - val_accuracy: 0.7666 - val_mse: 0.0492 - val_mae: 0.0417 - val_rmse: 0.1040\n",
      "Epoch 22/50\n",
      "4563/4563 [==============================] - 48s 10ms/step - loss: 0.4895 - accuracy: 0.7659 - mse: 0.0497 - mae: 0.0419 - rmse: 0.1045 - val_loss: 0.4877 - val_accuracy: 0.7666 - val_mse: 0.0502 - val_mae: 0.0419 - val_rmse: 0.1046\n",
      "Epoch 23/50\n",
      "4563/4563 [==============================] - 46s 10ms/step - loss: 0.4892 - accuracy: 0.7659 - mse: 0.0501 - mae: 0.0418 - rmse: 0.1045 - val_loss: 0.4874 - val_accuracy: 0.7666 - val_mse: 0.0504 - val_mae: 0.0419 - val_rmse: 0.1046\n",
      "Epoch 24/50\n",
      "4563/4563 [==============================] - 48s 11ms/step - loss: 0.4889 - accuracy: 0.7659 - mse: 0.0503 - mae: 0.0417 - rmse: 0.1044 - val_loss: 0.4872 - val_accuracy: 0.7666 - val_mse: 0.0505 - val_mae: 0.0417 - val_rmse: 0.1044\n",
      "Epoch 25/50\n",
      "4563/4563 [==============================] - 47s 10ms/step - loss: 0.4888 - accuracy: 0.7659 - mse: 0.0504 - mae: 0.0417 - rmse: 0.1044 - val_loss: 0.4872 - val_accuracy: 0.7666 - val_mse: 0.0507 - val_mae: 0.0417 - val_rmse: 0.1045\n",
      "Epoch 26/50\n",
      "4563/4563 [==============================] - 47s 10ms/step - loss: 0.4887 - accuracy: 0.7659 - mse: 0.0504 - mae: 0.0417 - rmse: 0.1044 - val_loss: 0.4873 - val_accuracy: 0.7666 - val_mse: 0.0507 - val_mae: 0.0419 - val_rmse: 0.1047\n",
      "Epoch 27/50\n",
      "4563/4563 [==============================] - 47s 10ms/step - loss: 0.4887 - accuracy: 0.7659 - mse: 0.0503 - mae: 0.0416 - rmse: 0.1043 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0506 - val_mae: 0.0415 - val_rmse: 0.1043\n",
      "Epoch 28/50\n",
      "4563/4563 [==============================] - 47s 10ms/step - loss: 0.4887 - accuracy: 0.7658 - mse: 0.0502 - mae: 0.0416 - rmse: 0.1041 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0504 - val_mae: 0.0414 - val_rmse: 0.1041\n",
      "Epoch 29/50\n",
      "4563/4563 [==============================] - 49s 11ms/step - loss: 0.4886 - accuracy: 0.7659 - mse: 0.0501 - mae: 0.0415 - rmse: 0.1040 - val_loss: 0.4873 - val_accuracy: 0.7666 - val_mse: 0.0505 - val_mae: 0.0418 - val_rmse: 0.1045\n",
      "Epoch 30/50\n",
      "4563/4563 [==============================] - 49s 11ms/step - loss: 0.4886 - accuracy: 0.7659 - mse: 0.0500 - mae: 0.0415 - rmse: 0.1040 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0496 - val_mae: 0.0412 - val_rmse: 0.1033\n",
      "Epoch 31/50\n",
      "4563/4563 [==============================] - 46s 10ms/step - loss: 0.4886 - accuracy: 0.7659 - mse: 0.0500 - mae: 0.0414 - rmse: 0.1039 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0502 - val_mae: 0.0414 - val_rmse: 0.1039\n",
      "Epoch 32/50\n",
      "4563/4563 [==============================] - 50s 11ms/step - loss: 0.4886 - accuracy: 0.7659 - mse: 0.0499 - mae: 0.0414 - rmse: 0.1038 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0495 - val_mae: 0.0412 - val_rmse: 0.1033\n",
      "Epoch 33/50\n",
      "4563/4563 [==============================] - 46s 10ms/step - loss: 0.4886 - accuracy: 0.7659 - mse: 0.0499 - mae: 0.0414 - rmse: 0.1037 - val_loss: 0.4872 - val_accuracy: 0.7666 - val_mse: 0.0503 - val_mae: 0.0415 - val_rmse: 0.1041\n",
      "Epoch 34/50\n",
      "4563/4563 [==============================] - 53s 12ms/step - loss: 0.4886 - accuracy: 0.7659 - mse: 0.0498 - mae: 0.0413 - rmse: 0.1036 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0499 - val_mae: 0.0412 - val_rmse: 0.1036\n",
      "Epoch 35/50\n",
      "4563/4563 [==============================] - 47s 10ms/step - loss: 0.4886 - accuracy: 0.7658 - mse: 0.0497 - mae: 0.0413 - rmse: 0.1036 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0498 - val_mae: 0.0412 - val_rmse: 0.1035\n",
      "Epoch 36/50\n",
      "4563/4563 [==============================] - 46s 10ms/step - loss: 0.4886 - accuracy: 0.7658 - mse: 0.0497 - mae: 0.0413 - rmse: 0.1035 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0494 - val_mae: 0.0410 - val_rmse: 0.1030\n",
      "Epoch 37/50\n",
      "4563/4563 [==============================] - 45s 10ms/step - loss: 0.4886 - accuracy: 0.7659 - mse: 0.0496 - mae: 0.0412 - rmse: 0.1034 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0498 - val_mae: 0.0413 - val_rmse: 0.1036\n",
      "Epoch 38/50\n",
      "4563/4563 [==============================] - 49s 11ms/step - loss: 0.4885 - accuracy: 0.7659 - mse: 0.0495 - mae: 0.0412 - rmse: 0.1033 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0497 - val_mae: 0.0412 - val_rmse: 0.1034\n",
      "Epoch 39/50\n",
      "4563/4563 [==============================] - 48s 10ms/step - loss: 0.4885 - accuracy: 0.7659 - mse: 0.0494 - mae: 0.0411 - rmse: 0.1032 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0495 - val_mae: 0.0411 - val_rmse: 0.1032\n",
      "Epoch 40/50\n",
      "4563/4563 [==============================] - 47s 10ms/step - loss: 0.4885 - accuracy: 0.7659 - mse: 0.0494 - mae: 0.0411 - rmse: 0.1031 - val_loss: 0.4872 - val_accuracy: 0.7666 - val_mse: 0.0495 - val_mae: 0.0413 - val_rmse: 0.1034\n",
      "Epoch 41/50\n",
      "4563/4563 [==============================] - 52s 11ms/step - loss: 0.4885 - accuracy: 0.7659 - mse: 0.0493 - mae: 0.0411 - rmse: 0.1030 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0493 - val_mae: 0.0410 - val_rmse: 0.1030\n",
      "Epoch 42/50\n",
      "4563/4563 [==============================] - 50s 11ms/step - loss: 0.4885 - accuracy: 0.7659 - mse: 0.0492 - mae: 0.0410 - rmse: 0.1030 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0492 - val_mae: 0.0409 - val_rmse: 0.1028\n",
      "Epoch 43/50\n",
      "4563/4563 [==============================] - 53s 12ms/step - loss: 0.4885 - accuracy: 0.7659 - mse: 0.0491 - mae: 0.0410 - rmse: 0.1029 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0498 - val_mae: 0.0412 - val_rmse: 0.1035\n",
      "Epoch 44/50\n",
      "4563/4563 [==============================] - 52s 11ms/step - loss: 0.4885 - accuracy: 0.7659 - mse: 0.0490 - mae: 0.0409 - rmse: 0.1028 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0491 - val_mae: 0.0409 - val_rmse: 0.10285 - accuracy: 0.7659 - mse: 0.0490 - mae: 0.040\n",
      "Epoch 45/50\n",
      "4563/4563 [==============================] - 52s 11ms/step - loss: 0.4885 - accuracy: 0.7659 - mse: 0.0489 - mae: 0.0409 - rmse: 0.1026 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0484 - val_mae: 0.0407 - val_rmse: 0.1021\n",
      "Epoch 46/50\n",
      "4563/4563 [==============================] - 49s 11ms/step - loss: 0.4885 - accuracy: 0.7659 - mse: 0.0488 - mae: 0.0408 - rmse: 0.1026 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0487 - val_mae: 0.0407 - val_rmse: 0.1023\n",
      "Epoch 47/50\n",
      "4563/4563 [==============================] - 51s 11ms/step - loss: 0.4885 - accuracy: 0.7659 - mse: 0.0487 - mae: 0.0408 - rmse: 0.1024 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0493 - val_mae: 0.0409 - val_rmse: 0.1029\n",
      "Epoch 48/50\n",
      "4563/4563 [==============================] - 49s 11ms/step - loss: 0.4885 - accuracy: 0.7659 - mse: 0.0486 - mae: 0.0407 - rmse: 0.1023 - val_loss: 0.4872 - val_accuracy: 0.7666 - val_mse: 0.0482 - val_mae: 0.0405 - val_rmse: 0.1018\n",
      "Epoch 49/50\n",
      "4563/4563 [==============================] - 45s 10ms/step - loss: 0.4885 - accuracy: 0.7659 - mse: 0.0484 - mae: 0.0407 - rmse: 0.1022 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0489 - val_mae: 0.0408 - val_rmse: 0.1025\n",
      "Epoch 50/50\n",
      "4563/4563 [==============================] - 43s 9ms/step - loss: 0.4885 - accuracy: 0.7659 - mse: 0.0484 - mae: 0.0406 - rmse: 0.1021 - val_loss: 0.4871 - val_accuracy: 0.7666 - val_mse: 0.0485 - val_mae: 0.0407 - val_rmse: 0.1022\n"
     ]
    }
   ],
   "source": [
    "model_fit8 = model1.fit(x_train,y_train,batch_size=256,epochs=50, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09110574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13518/13518 [==============================] - 64s 5ms/step - loss: 0.4902 - accuracy: 0.7646 - mse: 0.0489 - mae: 0.0410 - rmse: 0.1029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.49019181728363037,\n",
       " 0.7646472454071045,\n",
       " 0.04885462298989296,\n",
       " 0.04100942239165306,\n",
       " 0.10292555391788483]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "699c11f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40554/40554 [==============================] - 199s 5ms/step - loss: 0.4884 - accuracy: 0.7656 - mse: 0.0487 - mae: 0.0408 - rmse: 0.1025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48837408423423767,\n",
       " 0.7656370401382446,\n",
       " 0.04865056276321411,\n",
       " 0.040847476571798325,\n",
       " 0.10251941531896591]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a8eb0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Val Accuracy</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Val MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Val MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Val RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.287529</td>\n",
       "      <td>1.117320</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>0.017713</td>\n",
       "      <td>0.116800</td>\n",
       "      <td>0.109084</td>\n",
       "      <td>0.129615</td>\n",
       "      <td>0.118127</td>\n",
       "      <td>0.207851</td>\n",
       "      <td>0.109084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.008823</td>\n",
       "      <td>0.956032</td>\n",
       "      <td>0.107247</td>\n",
       "      <td>0.244531</td>\n",
       "      <td>0.103497</td>\n",
       "      <td>0.099709</td>\n",
       "      <td>0.110317</td>\n",
       "      <td>0.103074</td>\n",
       "      <td>0.171753</td>\n",
       "      <td>0.099709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.945143</td>\n",
       "      <td>0.927640</td>\n",
       "      <td>0.359127</td>\n",
       "      <td>0.503147</td>\n",
       "      <td>0.095170</td>\n",
       "      <td>0.089340</td>\n",
       "      <td>0.098454</td>\n",
       "      <td>0.092790</td>\n",
       "      <td>0.151351</td>\n",
       "      <td>0.089340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.902072</td>\n",
       "      <td>0.577906</td>\n",
       "      <td>0.648094</td>\n",
       "      <td>0.081419</td>\n",
       "      <td>0.075246</td>\n",
       "      <td>0.085736</td>\n",
       "      <td>0.077971</td>\n",
       "      <td>0.136425</td>\n",
       "      <td>0.075246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.879565</td>\n",
       "      <td>0.892580</td>\n",
       "      <td>0.713305</td>\n",
       "      <td>0.758126</td>\n",
       "      <td>0.070919</td>\n",
       "      <td>0.068620</td>\n",
       "      <td>0.070928</td>\n",
       "      <td>0.067119</td>\n",
       "      <td>0.125397</td>\n",
       "      <td>0.068620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.570845</td>\n",
       "      <td>0.751480</td>\n",
       "      <td>0.766267</td>\n",
       "      <td>0.067366</td>\n",
       "      <td>0.064675</td>\n",
       "      <td>0.066361</td>\n",
       "      <td>0.064501</td>\n",
       "      <td>0.121664</td>\n",
       "      <td>0.064675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.561151</td>\n",
       "      <td>0.541674</td>\n",
       "      <td>0.761078</td>\n",
       "      <td>0.766521</td>\n",
       "      <td>0.063042</td>\n",
       "      <td>0.062382</td>\n",
       "      <td>0.063489</td>\n",
       "      <td>0.062649</td>\n",
       "      <td>0.117402</td>\n",
       "      <td>0.062382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.529393</td>\n",
       "      <td>0.514954</td>\n",
       "      <td>0.764038</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.058617</td>\n",
       "      <td>0.054796</td>\n",
       "      <td>0.060046</td>\n",
       "      <td>0.056765</td>\n",
       "      <td>0.113138</td>\n",
       "      <td>0.054796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.503857</td>\n",
       "      <td>0.492441</td>\n",
       "      <td>0.765652</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.050751</td>\n",
       "      <td>0.048124</td>\n",
       "      <td>0.050745</td>\n",
       "      <td>0.044368</td>\n",
       "      <td>0.105425</td>\n",
       "      <td>0.048124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.491501</td>\n",
       "      <td>0.489690</td>\n",
       "      <td>0.765008</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.048081</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>0.041961</td>\n",
       "      <td>0.041657</td>\n",
       "      <td>0.103236</td>\n",
       "      <td>0.047902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.489622</td>\n",
       "      <td>0.764926</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.048146</td>\n",
       "      <td>0.048363</td>\n",
       "      <td>0.041798</td>\n",
       "      <td>0.041756</td>\n",
       "      <td>0.103521</td>\n",
       "      <td>0.048363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.491115</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.765136</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.048240</td>\n",
       "      <td>0.048512</td>\n",
       "      <td>0.041839</td>\n",
       "      <td>0.041916</td>\n",
       "      <td>0.103734</td>\n",
       "      <td>0.048512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.491038</td>\n",
       "      <td>0.489508</td>\n",
       "      <td>0.765212</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.048328</td>\n",
       "      <td>0.048377</td>\n",
       "      <td>0.041875</td>\n",
       "      <td>0.041724</td>\n",
       "      <td>0.103925</td>\n",
       "      <td>0.048377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.490966</td>\n",
       "      <td>0.489460</td>\n",
       "      <td>0.765587</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.048407</td>\n",
       "      <td>0.048650</td>\n",
       "      <td>0.041810</td>\n",
       "      <td>0.041578</td>\n",
       "      <td>0.103904</td>\n",
       "      <td>0.048650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.490874</td>\n",
       "      <td>0.489379</td>\n",
       "      <td>0.765735</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.048518</td>\n",
       "      <td>0.048594</td>\n",
       "      <td>0.041859</td>\n",
       "      <td>0.041996</td>\n",
       "      <td>0.104089</td>\n",
       "      <td>0.048594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.490790</td>\n",
       "      <td>0.489256</td>\n",
       "      <td>0.765821</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.048586</td>\n",
       "      <td>0.048779</td>\n",
       "      <td>0.041737</td>\n",
       "      <td>0.041738</td>\n",
       "      <td>0.103909</td>\n",
       "      <td>0.048779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.490669</td>\n",
       "      <td>0.489157</td>\n",
       "      <td>0.765833</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.048717</td>\n",
       "      <td>0.048796</td>\n",
       "      <td>0.041761</td>\n",
       "      <td>0.041694</td>\n",
       "      <td>0.104001</td>\n",
       "      <td>0.048796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.490526</td>\n",
       "      <td>0.489032</td>\n",
       "      <td>0.765857</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.048871</td>\n",
       "      <td>0.048861</td>\n",
       "      <td>0.041892</td>\n",
       "      <td>0.041737</td>\n",
       "      <td>0.104284</td>\n",
       "      <td>0.048861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.490360</td>\n",
       "      <td>0.488801</td>\n",
       "      <td>0.765856</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049045</td>\n",
       "      <td>0.048650</td>\n",
       "      <td>0.041915</td>\n",
       "      <td>0.041592</td>\n",
       "      <td>0.104365</td>\n",
       "      <td>0.048650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.490121</td>\n",
       "      <td>0.488630</td>\n",
       "      <td>0.765845</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049255</td>\n",
       "      <td>0.049649</td>\n",
       "      <td>0.041918</td>\n",
       "      <td>0.041820</td>\n",
       "      <td>0.104411</td>\n",
       "      <td>0.049649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.489824</td>\n",
       "      <td>0.488008</td>\n",
       "      <td>0.765865</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049509</td>\n",
       "      <td>0.049153</td>\n",
       "      <td>0.041961</td>\n",
       "      <td>0.041746</td>\n",
       "      <td>0.104545</td>\n",
       "      <td>0.049153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.489529</td>\n",
       "      <td>0.487657</td>\n",
       "      <td>0.765857</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049740</td>\n",
       "      <td>0.050192</td>\n",
       "      <td>0.041930</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>0.104545</td>\n",
       "      <td>0.050192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.489152</td>\n",
       "      <td>0.487382</td>\n",
       "      <td>0.765850</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.050051</td>\n",
       "      <td>0.050419</td>\n",
       "      <td>0.041837</td>\n",
       "      <td>0.041889</td>\n",
       "      <td>0.104479</td>\n",
       "      <td>0.050419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.488874</td>\n",
       "      <td>0.487245</td>\n",
       "      <td>0.765855</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.050281</td>\n",
       "      <td>0.050458</td>\n",
       "      <td>0.041744</td>\n",
       "      <td>0.041732</td>\n",
       "      <td>0.104421</td>\n",
       "      <td>0.050458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.488751</td>\n",
       "      <td>0.487153</td>\n",
       "      <td>0.765867</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.050397</td>\n",
       "      <td>0.050717</td>\n",
       "      <td>0.041707</td>\n",
       "      <td>0.041679</td>\n",
       "      <td>0.104416</td>\n",
       "      <td>0.050717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.488707</td>\n",
       "      <td>0.487268</td>\n",
       "      <td>0.765854</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.050386</td>\n",
       "      <td>0.050737</td>\n",
       "      <td>0.041671</td>\n",
       "      <td>0.041862</td>\n",
       "      <td>0.104362</td>\n",
       "      <td>0.050737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.488668</td>\n",
       "      <td>0.487094</td>\n",
       "      <td>0.765857</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.050343</td>\n",
       "      <td>0.050631</td>\n",
       "      <td>0.041625</td>\n",
       "      <td>0.041543</td>\n",
       "      <td>0.104284</td>\n",
       "      <td>0.050631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.488663</td>\n",
       "      <td>0.487088</td>\n",
       "      <td>0.765845</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.050202</td>\n",
       "      <td>0.050407</td>\n",
       "      <td>0.041575</td>\n",
       "      <td>0.041425</td>\n",
       "      <td>0.104146</td>\n",
       "      <td>0.050407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.488641</td>\n",
       "      <td>0.487292</td>\n",
       "      <td>0.765854</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.050128</td>\n",
       "      <td>0.050472</td>\n",
       "      <td>0.041520</td>\n",
       "      <td>0.041793</td>\n",
       "      <td>0.104041</td>\n",
       "      <td>0.050472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.488633</td>\n",
       "      <td>0.487114</td>\n",
       "      <td>0.765860</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.050044</td>\n",
       "      <td>0.049609</td>\n",
       "      <td>0.041490</td>\n",
       "      <td>0.041189</td>\n",
       "      <td>0.103960</td>\n",
       "      <td>0.049609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.488613</td>\n",
       "      <td>0.487102</td>\n",
       "      <td>0.765851</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049985</td>\n",
       "      <td>0.050158</td>\n",
       "      <td>0.041449</td>\n",
       "      <td>0.041374</td>\n",
       "      <td>0.103882</td>\n",
       "      <td>0.050158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.488600</td>\n",
       "      <td>0.487115</td>\n",
       "      <td>0.765857</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049915</td>\n",
       "      <td>0.049534</td>\n",
       "      <td>0.041404</td>\n",
       "      <td>0.041174</td>\n",
       "      <td>0.103791</td>\n",
       "      <td>0.049534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.488590</td>\n",
       "      <td>0.487158</td>\n",
       "      <td>0.765855</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049854</td>\n",
       "      <td>0.050327</td>\n",
       "      <td>0.041369</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.103719</td>\n",
       "      <td>0.050327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.488578</td>\n",
       "      <td>0.487078</td>\n",
       "      <td>0.765857</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049785</td>\n",
       "      <td>0.049943</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>0.041242</td>\n",
       "      <td>0.103635</td>\n",
       "      <td>0.049943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.488566</td>\n",
       "      <td>0.487068</td>\n",
       "      <td>0.765848</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049712</td>\n",
       "      <td>0.049847</td>\n",
       "      <td>0.041293</td>\n",
       "      <td>0.041152</td>\n",
       "      <td>0.103556</td>\n",
       "      <td>0.049847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.488557</td>\n",
       "      <td>0.487078</td>\n",
       "      <td>0.765848</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049661</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.041256</td>\n",
       "      <td>0.041021</td>\n",
       "      <td>0.103489</td>\n",
       "      <td>0.049364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.488552</td>\n",
       "      <td>0.487142</td>\n",
       "      <td>0.765854</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049574</td>\n",
       "      <td>0.049848</td>\n",
       "      <td>0.041231</td>\n",
       "      <td>0.041336</td>\n",
       "      <td>0.103405</td>\n",
       "      <td>0.049848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.488544</td>\n",
       "      <td>0.487084</td>\n",
       "      <td>0.765863</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049507</td>\n",
       "      <td>0.049676</td>\n",
       "      <td>0.041185</td>\n",
       "      <td>0.041158</td>\n",
       "      <td>0.103322</td>\n",
       "      <td>0.049676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.488537</td>\n",
       "      <td>0.487089</td>\n",
       "      <td>0.765856</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>0.049533</td>\n",
       "      <td>0.041147</td>\n",
       "      <td>0.041116</td>\n",
       "      <td>0.103240</td>\n",
       "      <td>0.049533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.488518</td>\n",
       "      <td>0.487164</td>\n",
       "      <td>0.765859</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049352</td>\n",
       "      <td>0.049520</td>\n",
       "      <td>0.041105</td>\n",
       "      <td>0.041278</td>\n",
       "      <td>0.103136</td>\n",
       "      <td>0.049520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.488517</td>\n",
       "      <td>0.487067</td>\n",
       "      <td>0.765853</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049253</td>\n",
       "      <td>0.049323</td>\n",
       "      <td>0.041063</td>\n",
       "      <td>0.040990</td>\n",
       "      <td>0.103038</td>\n",
       "      <td>0.049323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.488507</td>\n",
       "      <td>0.487066</td>\n",
       "      <td>0.765853</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049183</td>\n",
       "      <td>0.049163</td>\n",
       "      <td>0.041021</td>\n",
       "      <td>0.040901</td>\n",
       "      <td>0.102957</td>\n",
       "      <td>0.049163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.488498</td>\n",
       "      <td>0.487081</td>\n",
       "      <td>0.765852</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049097</td>\n",
       "      <td>0.049821</td>\n",
       "      <td>0.040982</td>\n",
       "      <td>0.041230</td>\n",
       "      <td>0.102864</td>\n",
       "      <td>0.049821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.488494</td>\n",
       "      <td>0.487062</td>\n",
       "      <td>0.765857</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.049010</td>\n",
       "      <td>0.049127</td>\n",
       "      <td>0.040941</td>\n",
       "      <td>0.040890</td>\n",
       "      <td>0.102773</td>\n",
       "      <td>0.049127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.488485</td>\n",
       "      <td>0.487068</td>\n",
       "      <td>0.765852</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.048894</td>\n",
       "      <td>0.048450</td>\n",
       "      <td>0.040886</td>\n",
       "      <td>0.040667</td>\n",
       "      <td>0.102644</td>\n",
       "      <td>0.048450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.488477</td>\n",
       "      <td>0.487063</td>\n",
       "      <td>0.765858</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.048818</td>\n",
       "      <td>0.048698</td>\n",
       "      <td>0.040848</td>\n",
       "      <td>0.040705</td>\n",
       "      <td>0.102561</td>\n",
       "      <td>0.048698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.488474</td>\n",
       "      <td>0.487062</td>\n",
       "      <td>0.765863</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.048676</td>\n",
       "      <td>0.049272</td>\n",
       "      <td>0.040790</td>\n",
       "      <td>0.040936</td>\n",
       "      <td>0.102414</td>\n",
       "      <td>0.049272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.488465</td>\n",
       "      <td>0.487202</td>\n",
       "      <td>0.765860</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.048561</td>\n",
       "      <td>0.048185</td>\n",
       "      <td>0.040736</td>\n",
       "      <td>0.040500</td>\n",
       "      <td>0.102293</td>\n",
       "      <td>0.048185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.488460</td>\n",
       "      <td>0.487057</td>\n",
       "      <td>0.765853</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.048436</td>\n",
       "      <td>0.048850</td>\n",
       "      <td>0.040680</td>\n",
       "      <td>0.040792</td>\n",
       "      <td>0.102161</td>\n",
       "      <td>0.048850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.488453</td>\n",
       "      <td>0.487083</td>\n",
       "      <td>0.765856</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>0.048358</td>\n",
       "      <td>0.048493</td>\n",
       "      <td>0.040641</td>\n",
       "      <td>0.040731</td>\n",
       "      <td>0.102078</td>\n",
       "      <td>0.048493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Loss  Val Loss  Accuracy  Val Accuracy       MSE   Val MSE       MAE  \\\n",
       "0   1.287529  1.117320  0.003844      0.017713  0.116800  0.109084  0.129615   \n",
       "1   1.008823  0.956032  0.107247      0.244531  0.103497  0.099709  0.110317   \n",
       "2   0.945143  0.927640  0.359127      0.503147  0.095170  0.089340  0.098454   \n",
       "3   0.916325  0.902072  0.577906      0.648094  0.081419  0.075246  0.085736   \n",
       "4   0.879565  0.892580  0.713305      0.758126  0.070919  0.068620  0.070928   \n",
       "5   0.770270  0.570845  0.751480      0.766267  0.067366  0.064675  0.066361   \n",
       "6   0.561151  0.541674  0.761078      0.766521  0.063042  0.062382  0.063489   \n",
       "7   0.529393  0.514954  0.764038      0.766608  0.058617  0.054796  0.060046   \n",
       "8   0.503857  0.492441  0.765652      0.766608  0.050751  0.048124  0.050745   \n",
       "9   0.491501  0.489690  0.765008      0.766608  0.048081  0.047902  0.041961   \n",
       "10  0.491187  0.489622  0.764926      0.766608  0.048146  0.048363  0.041798   \n",
       "11  0.491115  0.489583  0.765136      0.766608  0.048240  0.048512  0.041839   \n",
       "12  0.491038  0.489508  0.765212      0.766608  0.048328  0.048377  0.041875   \n",
       "13  0.490966  0.489460  0.765587      0.766608  0.048407  0.048650  0.041810   \n",
       "14  0.490874  0.489379  0.765735      0.766608  0.048518  0.048594  0.041859   \n",
       "15  0.490790  0.489256  0.765821      0.766608  0.048586  0.048779  0.041737   \n",
       "16  0.490669  0.489157  0.765833      0.766608  0.048717  0.048796  0.041761   \n",
       "17  0.490526  0.489032  0.765857      0.766608  0.048871  0.048861  0.041892   \n",
       "18  0.490360  0.488801  0.765856      0.766608  0.049045  0.048650  0.041915   \n",
       "19  0.490121  0.488630  0.765845      0.766608  0.049255  0.049649  0.041918   \n",
       "20  0.489824  0.488008  0.765865      0.766608  0.049509  0.049153  0.041961   \n",
       "21  0.489529  0.487657  0.765857      0.766608  0.049740  0.050192  0.041930   \n",
       "22  0.489152  0.487382  0.765850      0.766608  0.050051  0.050419  0.041837   \n",
       "23  0.488874  0.487245  0.765855      0.766608  0.050281  0.050458  0.041744   \n",
       "24  0.488751  0.487153  0.765867      0.766608  0.050397  0.050717  0.041707   \n",
       "25  0.488707  0.487268  0.765854      0.766608  0.050386  0.050737  0.041671   \n",
       "26  0.488668  0.487094  0.765857      0.766608  0.050343  0.050631  0.041625   \n",
       "27  0.488663  0.487088  0.765845      0.766608  0.050202  0.050407  0.041575   \n",
       "28  0.488641  0.487292  0.765854      0.766608  0.050128  0.050472  0.041520   \n",
       "29  0.488633  0.487114  0.765860      0.766608  0.050044  0.049609  0.041490   \n",
       "30  0.488613  0.487102  0.765851      0.766608  0.049985  0.050158  0.041449   \n",
       "31  0.488600  0.487115  0.765857      0.766608  0.049915  0.049534  0.041404   \n",
       "32  0.488590  0.487158  0.765855      0.766608  0.049854  0.050327  0.041369   \n",
       "33  0.488578  0.487078  0.765857      0.766608  0.049785  0.049943  0.041327   \n",
       "34  0.488566  0.487068  0.765848      0.766608  0.049712  0.049847  0.041293   \n",
       "35  0.488557  0.487078  0.765848      0.766608  0.049661  0.049364  0.041256   \n",
       "36  0.488552  0.487142  0.765854      0.766608  0.049574  0.049848  0.041231   \n",
       "37  0.488544  0.487084  0.765863      0.766608  0.049507  0.049676  0.041185   \n",
       "38  0.488537  0.487089  0.765856      0.766608  0.049437  0.049533  0.041147   \n",
       "39  0.488518  0.487164  0.765859      0.766608  0.049352  0.049520  0.041105   \n",
       "40  0.488517  0.487067  0.765853      0.766608  0.049253  0.049323  0.041063   \n",
       "41  0.488507  0.487066  0.765853      0.766608  0.049183  0.049163  0.041021   \n",
       "42  0.488498  0.487081  0.765852      0.766608  0.049097  0.049821  0.040982   \n",
       "43  0.488494  0.487062  0.765857      0.766608  0.049010  0.049127  0.040941   \n",
       "44  0.488485  0.487068  0.765852      0.766608  0.048894  0.048450  0.040886   \n",
       "45  0.488477  0.487063  0.765858      0.766608  0.048818  0.048698  0.040848   \n",
       "46  0.488474  0.487062  0.765863      0.766608  0.048676  0.049272  0.040790   \n",
       "47  0.488465  0.487202  0.765860      0.766608  0.048561  0.048185  0.040736   \n",
       "48  0.488460  0.487057  0.765853      0.766608  0.048436  0.048850  0.040680   \n",
       "49  0.488453  0.487083  0.765856      0.766608  0.048358  0.048493  0.040641   \n",
       "\n",
       "     Val MAE      RMSE  Val RMSE  \n",
       "0   0.118127  0.207851  0.109084  \n",
       "1   0.103074  0.171753  0.099709  \n",
       "2   0.092790  0.151351  0.089340  \n",
       "3   0.077971  0.136425  0.075246  \n",
       "4   0.067119  0.125397  0.068620  \n",
       "5   0.064501  0.121664  0.064675  \n",
       "6   0.062649  0.117402  0.062382  \n",
       "7   0.056765  0.113138  0.054796  \n",
       "8   0.044368  0.105425  0.048124  \n",
       "9   0.041657  0.103236  0.047902  \n",
       "10  0.041756  0.103521  0.048363  \n",
       "11  0.041916  0.103734  0.048512  \n",
       "12  0.041724  0.103925  0.048377  \n",
       "13  0.041578  0.103904  0.048650  \n",
       "14  0.041996  0.104089  0.048594  \n",
       "15  0.041738  0.103909  0.048779  \n",
       "16  0.041694  0.104001  0.048796  \n",
       "17  0.041737  0.104284  0.048861  \n",
       "18  0.041592  0.104365  0.048650  \n",
       "19  0.041820  0.104411  0.049649  \n",
       "20  0.041746  0.104545  0.049153  \n",
       "21  0.041900  0.104545  0.050192  \n",
       "22  0.041889  0.104479  0.050419  \n",
       "23  0.041732  0.104421  0.050458  \n",
       "24  0.041679  0.104416  0.050717  \n",
       "25  0.041862  0.104362  0.050737  \n",
       "26  0.041543  0.104284  0.050631  \n",
       "27  0.041425  0.104146  0.050407  \n",
       "28  0.041793  0.104041  0.050472  \n",
       "29  0.041189  0.103960  0.049609  \n",
       "30  0.041374  0.103882  0.050158  \n",
       "31  0.041174  0.103791  0.049534  \n",
       "32  0.041533  0.103719  0.050327  \n",
       "33  0.041242  0.103635  0.049943  \n",
       "34  0.041152  0.103556  0.049847  \n",
       "35  0.041021  0.103489  0.049364  \n",
       "36  0.041336  0.103405  0.049848  \n",
       "37  0.041158  0.103322  0.049676  \n",
       "38  0.041116  0.103240  0.049533  \n",
       "39  0.041278  0.103136  0.049520  \n",
       "40  0.040990  0.103038  0.049323  \n",
       "41  0.040901  0.102957  0.049163  \n",
       "42  0.041230  0.102864  0.049821  \n",
       "43  0.040890  0.102773  0.049127  \n",
       "44  0.040667  0.102644  0.048450  \n",
       "45  0.040705  0.102561  0.048698  \n",
       "46  0.040936  0.102414  0.049272  \n",
       "47  0.040500  0.102293  0.048185  \n",
       "48  0.040792  0.102161  0.048850  \n",
       "49  0.040731  0.102078  0.048493  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame(model_fit8.history['loss'],columns=[\"Loss\"])\n",
    "df1=df1.join(pd.DataFrame(model_fit8.history[\"val_loss\"],columns=[\"Val Loss\"]))\n",
    "df1=df1.join(pd.DataFrame(model_fit8.history[\"accuracy\"],columns=['Accuracy']))\n",
    "df1=df1.join(pd.DataFrame(model_fit8.history[\"val_accuracy\"],columns=['Val Accuracy']))\n",
    "df1=df1.join(pd.DataFrame(model_fit8.history[\"mse\"],columns=['MSE']))\n",
    "df1=df1.join(pd.DataFrame(model_fit8.history[\"val_mse\"],columns=['Val MSE']))\n",
    "df1=df1.join(pd.DataFrame(model_fit8.history[\"mae\"],columns=['MAE']))\n",
    "df1=df1.join(pd.DataFrame(model_fit8.history[\"val_mae\"],columns=['Val MAE']))\n",
    "df1=df1.join(pd.DataFrame(model_fit8.history[\"rmse\"],columns=['RMSE']))\n",
    "df1=df1.join(pd.DataFrame(model_fit8.history[\"val_mse\"],columns=['Val RMSE']))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "498c7daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_excel(\"LSTM.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c03bc9",
   "metadata": {},
   "source": [
    "# Saving Model as File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b3ceb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(432571, 1, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "feb6fe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model1.to_json()\n",
    "with open(\"lstm_tanh.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model1.save_weights(\"lstm_tanh.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85c18be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open('lstm_tanh.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"lstm_tanh.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "loaded_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy',metrics=['accuracy','mse','mae',rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dae6fe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75d6b3",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff6190cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(model_fit8.history['loss'])\n",
    "plt.plot(model_fit8.history['val_loss'])\n",
    "plt.title('Model Loss',fontweight ='bold',fontsize = 15)\n",
    "plt.ylabel('Loss',fontweight ='bold',fontsize = 15)\n",
    "plt.xlabel('Epoch',fontweight ='bold',fontsize = 15)\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(model_fit8.history['accuracy'])\n",
    "plt.plot(model_fit8.history['val_accuracy'])\n",
    "plt.title('Model accuracy',fontweight ='bold',fontsize = 15)\n",
    "plt.ylabel('Accuracy',fontweight ='bold',fontsize = 15)\n",
    "plt.xlabel('Epoch',fontweight ='bold',fontsize = 15)\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9334fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating csv file of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07217729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.06565751, 1.3418534 , ..., 0.01918538, 0.01250063,\n",
       "        0.        ],\n",
       "       [0.        , 0.06553607, 0.        , ..., 0.01918538, 0.        ,\n",
       "        0.00576578],\n",
       "       [0.        , 0.06551062, 0.        , ..., 0.01918538, 0.        ,\n",
       "        0.00539187],\n",
       "       ...,\n",
       "       [0.        , 0.06552711, 0.        , ..., 0.01918538, 0.        ,\n",
       "        0.00588094],\n",
       "       [0.        , 0.06576732, 1.3423123 , ..., 0.01918538, 0.0129696 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.06551072, 0.        , ..., 0.01918538, 0.        ,\n",
       "        0.00585441]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.25, random_state=42)\n",
    "\n",
    "y_test_pred=loaded_model.predict(x_test)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72d85cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00011559, 0.06553685, 0.00011085, ..., 0.0021448 ,\n",
       "         0.0014142 , 0.00052142]],\n",
       "\n",
       "       [[0.00011088, 0.06553695, 0.00012144, ..., 0.01090628,\n",
       "         0.00639894, 0.00234271]],\n",
       "\n",
       "       [[0.0001138 , 0.06553686, 0.00011756, ..., 0.02938369,\n",
       "         0.01855402, 0.00761428]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.00011103, 0.06553663, 0.00011547, ..., 0.05674056,\n",
       "         0.03595096, 0.01243099]],\n",
       "\n",
       "       [[0.00011477, 0.06553688, 0.00010965, ..., 0.00815022,\n",
       "         0.00468672, 0.00148292]],\n",
       "\n",
       "       [[0.00010879, 0.06553657, 0.00012025, ..., 0.00375339,\n",
       "         0.00246608, 0.00081172]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaa1df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ca1da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "savetxt('lstm_y_test_pred.csv', y_test_pred[:1001], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34d1ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "savetxt('lstm_y_test.csv', y_test[:1001], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d52b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
