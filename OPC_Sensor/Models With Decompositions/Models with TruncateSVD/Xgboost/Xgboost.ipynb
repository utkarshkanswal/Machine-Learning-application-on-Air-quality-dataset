{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5231689",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89e85a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os.path as op\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2f0d94",
   "metadata": {},
   "source": [
    "# Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f29739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.50000e+02 1.90401e+05 7.25000e+02 2.75500e+01 8.03900e+01]\n",
      " [1.50000e+02 1.90401e+05 8.25000e+02 2.75600e+01 8.03300e+01]\n",
      " [1.50000e+02 1.90401e+05 9.25000e+02 2.75800e+01 8.02400e+01]\n",
      " ...\n",
      " [6.10000e+01 1.91020e+05 1.94532e+05 2.93700e+01 7.52100e+01]\n",
      " [6.10000e+01 1.91020e+05 1.94632e+05 2.93500e+01 7.52700e+01]\n",
      " [6.10000e+01 1.91020e+05 1.94732e+05 2.93400e+01 7.53000e+01]]\n",
      "[[ 28.     3.   -52.   ...  16.97  19.63  20.06]\n",
      " [ 28.    15.   -53.   ...  16.63  19.57  23.06]\n",
      " [ 31.    16.   -55.   ...  17.24  19.98  20.24]\n",
      " ...\n",
      " [ 76.    12.   -76.   ...   3.47   3.95   4.35]\n",
      " [ 75.    13.   -76.   ...   3.88   4.33   4.42]\n",
      " [ 76.    12.   -75.   ...   3.46   4.07   4.28]]\n"
     ]
    }
   ],
   "source": [
    "A1=np.empty((0,5),dtype='float32')\n",
    "U1=np.empty((0,7),dtype='float32')\n",
    "node=['150','149','147','144','142','140','136','61']\n",
    "mon=['Apr','Mar','Aug','Jun','Jul','Sep','May','Oct']\n",
    "for j in node:\n",
    "  for i in mon:\n",
    "    inp= pd.read_csv('../../../data_gkv/AT510_Node_'+str(j)+'_'+str(i)+'19_OutputFile.csv',usecols=[1,2,3,15,16],low_memory=False)\n",
    "    out= pd.read_csv('../../../data_gkv/AT510_Node_'+str(j)+'_'+str(i)+'19_OutputFile.csv',usecols=[5,6,7,8,17,18,19],low_memory=False)\n",
    "    \n",
    "    inp=np.array(inp,dtype='float32')\n",
    "    out=np.array(out,dtype='float32')\n",
    "    \n",
    "    A1=np.append(A1, inp, axis=0)\n",
    "    U1=np.append(U1, out, axis=0)\n",
    "\n",
    "print(A1)\n",
    "print(U1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28df31d2",
   "metadata": {},
   "source": [
    "# A fast algorithm for Independent Component Analysis Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64f3edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import SparsePCA\n",
    "import warnings\n",
    "scaler_obj1=SparsePCA()\n",
    "scaler_obj2=SparsePCA()\n",
    "X1=scaler_obj1.fit_transform(A1)\n",
    "Y1=scaler_obj2.fit_transform(U1)\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aca8a3",
   "metadata": {},
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94595d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def hyperParameterTuning(X_train, y_train):\n",
    "    param_tuning = {\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [7,8,10,],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'subsample': [0.5, 0.7],\n",
    "        'n_estimators' : [80,90,100,200,400,1000],\n",
    "        'objective': ['reg:squarederror','count:poisson']\n",
    "    }\n",
    "\n",
    "    xgb_model = XGBRegressor(tree_method='gpu_hist', gpu_id=0)\n",
    "\n",
    "    gsearch = RandomizedSearchCV(estimator = xgb_model, param_distributions = param_tuning, n_iter = 5, cv = 2, verbose=2, random_state=0, n_jobs = -1)\n",
    "\n",
    "    \n",
    "    grid_result = MultiOutputRegressor(gsearch).fit(x_train, y_train)\n",
    "\n",
    "    return grid_result.estimators_[0].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f561e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X1,Y1,test_size=0.25,random_state=0)\n",
    "\n",
    "params=hyperParameterTuning(x_train,y_train)\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6bbe39",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c2c88e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:59:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"cosample_bytree\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:00:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"cosample_bytree\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:01:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"cosample_bytree\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:01:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"cosample_bytree\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:02:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"cosample_bytree\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:02:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"cosample_bytree\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:03:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"cosample_bytree\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "Model training is Done!!\n"
     ]
    }
   ],
   "source": [
    "# Splitting Data into training and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X1,Y1,test_size=0.25,random_state=42)\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#creating object of sgboostregressor\n",
    "model1=MultiOutputRegressor(XGBRegressor(tree_method='gpu_hist', gpu_id=0,max_depth=8,cosample_bytree=.5,learning_rate=.1,min_child_weight=3,\n",
    "                   n_estimators=200,subsample=.7))\n",
    "\n",
    "#training the model\n",
    "model_fit1=model1.fit(x_train, y_train)\n",
    "print(\"Model training is Done!!\")\n",
    "\n",
    "#saving as file\n",
    "filename1 = 'xgboost.sav'\n",
    "pickle.dump(model_fit1, open(filename1, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb330916",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be501d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score on train data 0.3351657659609297\n",
      "r2 score on test data -1498.28155851662\n",
      "Mean Absolute Error: 103.29054\n",
      "Mean Squared Error: 2103667800.0\n",
      "Root Mean Squared Error: 45865.758\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "train_sizes=['NO2','O3','NO','CO','PM1','PM2.5','PM10']\n",
    "\n",
    "#finding out the r2 score\n",
    "y_train_pred1=model1.predict(x_train)\n",
    "r2_train1=r2_score(y_train,y_train_pred1,multioutput='variance_weighted')\n",
    "\n",
    "y_test_pred1=model1.predict(x_test)\n",
    "r2_test1=r2_score(y_test,y_test_pred1,multioutput='variance_weighted')\n",
    "\n",
    "print('r2 score on train data '+str(r2_train1))\n",
    "print('r2 score on test data '+ str(r2_test1))\n",
    "\n",
    "xgboost_mae=metrics.mean_absolute_error(y_test, y_test_pred1)\n",
    "xgboost_mse=metrics.mean_squared_error(y_test, y_test_pred1)\n",
    "xgboost_rmse=np.sqrt(xgboost_mse)\n",
    "print('Mean Absolute Error:',xgboost_mae)\n",
    "print('Mean Squared Error:',xgboost_mse )\n",
    "print('Root Mean Squared Error:',xgboost_rmse)\n",
    "print(' \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf305f4",
   "metadata": {},
   "source": [
    "# Prediction of particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bac980c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted :\n",
      " [[-6.3266712e+01  2.6222984e+01  9.5894585e+01 ... -3.2326351e+01\n",
      "  -3.4267503e-01 -3.8126916e-01]\n",
      " [-4.2865105e+01 -4.8326118e+01  2.6734684e+01 ...  3.0773718e+01\n",
      "  -1.6355041e+00  1.5065483e+00]\n",
      " [-5.8958878e+01 -1.1239226e+01 -3.4998175e+02 ... -1.2724620e+01\n",
      "   3.1426024e-01 -2.6705676e-01]\n",
      " ...\n",
      " [-8.6125565e+01 -1.4471008e+01 -1.7130704e+02 ...  4.7370903e+01\n",
      "  -1.6055179e+00  3.3796111e-01]\n",
      " [-4.5717514e+01  3.3935410e+01  3.2849377e+02 ... -1.3256995e+01\n",
      "  -1.0992424e+00  4.0163147e-01]\n",
      " [-9.2042099e+01 -2.7857420e+01  4.1238953e+02 ... -1.8715380e+01\n",
      "   2.5518751e+00 -1.5739179e-01]]\n",
      "\n",
      "\n",
      "R2 Score :  -1498.28155851662\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X1,Y1,test_size=0.25,random_state=42)\n",
    "loaded_model_fit7 = pickle.load(open(\"xgboost.sav\", 'rb'))\n",
    "y_test_pred=loaded_model_fit7.predict(x_test)\n",
    "print(\"Predicted :\\n\",y_test_pred)\n",
    "print(\"\\n\")\n",
    "r2_test=r2_score(y_test,y_test_pred,multioutput='variance_weighted')\n",
    "print(\"R2 Score : \",r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4e8edd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparsePCA' object has no attribute 'inverse_transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10336/226534693.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaler_obj1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaler_obj2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaler_obj2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SparsePCA' object has no attribute 'inverse_transform'"
     ]
    }
   ],
   "source": [
    "x_test=scaler_obj1.inverse_transform(x_test)\n",
    "y_test_pred=scaler_obj2.inverse_transform(y_test_pred)\n",
    "y_test=scaler_obj2.inverse_transform(y_test)\n",
    "pd.DataFrame(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f1f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import datetime\n",
    "temp_arr=x_test[0:,1]\n",
    "dates=list()\n",
    "for i in range(0,len(temp_arr)):\n",
    "    datetime_str=str(int(temp_arr[i]))\n",
    "    datetime_str=datetime_str[0:6]\n",
    "    if(datetime_str[4:6]==\"00\"):\n",
    "        datetime_str=datetime_str[0:4]+'1'\n",
    "    datetime_obj = datetime.strptime(datetime_str,\"%y%m%d\")\n",
    "    dates.append(str(datetime_obj.date()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4559cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1=pd.DataFrame(y_test,index=dates,columns=['NO2','O3','NO','CO','PM1','PM2.5','PM10'])\n",
    "df1.index.name=\"DATE\"\n",
    "print(\"Actual Values:\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4bd5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=[\"Y_Actual\"]*25\n",
    "temp_df1=df1.head(25)\n",
    "temp_df1['Data']=arr\n",
    "temp_df1.to_excel(\"xgboost_y_test.xlsx\")\n",
    "temp_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64fa8ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2=pd.DataFrame(y_test_pred,index=dates,columns=['NO2','O3','NO','CO','PM1','PM2.5','PM10'])\n",
    "df2.index.name=\"DATE\"\n",
    "print(\"Predicted Values:\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a5a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=[\"Y_Predicted\"]*25\n",
    "temp_df2=df2.head(25)\n",
    "temp_df2['Data']=arr\n",
    "temp_df2.to_excel(\"xgboost_y_test_pred.xlsx\")\n",
    "temp_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "372d161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Completed"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
