{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os.path as op\n",
    "from csv import writer\n",
    "import math\n",
    "import cmath\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model,Sequential,load_model\n",
    "from keras.layers import Input, Embedding\n",
    "from keras.layers import Dense, Bidirectional\n",
    "from keras.layers.recurrent import LSTM\n",
    "import keras.metrics as metrics\n",
    "import itertools\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from decimal import Decimal\n",
    "from keras.layers import Conv1D,MaxPooling1D,Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.50000e+02 1.90401e+05 7.25000e+02 2.75500e+01 8.03900e+01]\n",
      " [1.50000e+02 1.90401e+05 8.25000e+02 2.75600e+01 8.03300e+01]\n",
      " [1.50000e+02 1.90401e+05 9.25000e+02 2.75800e+01 8.02400e+01]\n",
      " ...\n",
      " [6.10000e+01 1.91020e+05 1.94532e+05 2.93700e+01 7.52100e+01]\n",
      " [6.10000e+01 1.91020e+05 1.94632e+05 2.93500e+01 7.52700e+01]\n",
      " [6.10000e+01 1.91020e+05 1.94732e+05 2.93400e+01 7.53000e+01]]\n",
      "[[ 28.     3.   -52.   ...  16.97  19.63  20.06]\n",
      " [ 28.    15.   -53.   ...  16.63  19.57  23.06]\n",
      " [ 31.    16.   -55.   ...  17.24  19.98  20.24]\n",
      " ...\n",
      " [ 76.    12.   -76.   ...   3.47   3.95   4.35]\n",
      " [ 75.    13.   -76.   ...   3.88   4.33   4.42]\n",
      " [ 76.    12.   -75.   ...   3.46   4.07   4.28]]\n"
     ]
    }
   ],
   "source": [
    "A1=np.empty((0,5),dtype='float32')\n",
    "U1=np.empty((0,7),dtype='float32')\n",
    "node=['150','149','147','144','142','140','136','61']\n",
    "mon=['Apr','Mar','Aug','Jun','Jul','Sep','May','Oct']\n",
    "for j in node:\n",
    "  for i in mon:\n",
    "    inp= pd.read_csv('../../../data_gkv/AT510_Node_'+str(j)+'_'+str(i)+'19_OutputFile.csv',usecols=[1,2,3,15,16])\n",
    "    out= pd.read_csv('../../../data_gkv/AT510_Node_'+str(j)+'_'+str(i)+'19_OutputFile.csv',usecols=[5,6,7,8,17,18,19])\n",
    "    \n",
    "    inp=np.array(inp,dtype='float32')\n",
    "    out=np.array(out,dtype='float32')\n",
    "    \n",
    "    A1=np.append(A1, inp, axis=0)\n",
    "    U1=np.append(U1, out, axis=0)\n",
    "\n",
    "print(A1)\n",
    "print(U1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "scaler_obj1=PCA(svd_solver='full')\n",
    "scaler_obj2=PCA(svd_solver='full')\n",
    "X1=scaler_obj1.fit_transform(A1)\n",
    "Y1=scaler_obj2.fit_transform(U1)\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "X1=X1[:,np.newaxis,:]\n",
    "Y1=Y1[:,np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_1 (GRU)                 (None, 14)                882       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 105       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 7)                28        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 7)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,015\n",
      "Trainable params: 1,001\n",
      "Non-trainable params: 14\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(keras.Input(shape=(1,5)))\n",
    "model.add(tf.keras.layers.GRU(14,activation=\"tanh\",use_bias=True,kernel_initializer=\"glorot_uniform\",bias_initializer=\"zeros\", \n",
    "                                kernel_regularizer=keras.regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                                bias_regularizer=keras.regularizers.l2(1e-4),\n",
    "                                activity_regularizer=keras.regularizers.l2(1e-5)))\n",
    "model.add(keras.layers.Dropout(.1))\n",
    "model.add(Dense(7))\n",
    "model.add(keras.layers.BatchNormalization(axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,\n",
    "                                beta_initializer=\"zeros\",gamma_initializer=\"ones\",\n",
    "                                moving_mean_initializer=\"zeros\",moving_variance_initializer=\"ones\",trainable=True))\n",
    "model.add(keras.layers.ReLU())\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),loss='mse',metrics=['accuracy','mse','mae',rmse])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4563/4563 [==============================] - 55s 12ms/step - loss: 2296374272.0000 - accuracy: 0.1494 - mse: 2296471552.0000 - mae: 96.6970 - rmse: 197.0939 - val_loss: 30779.7090 - val_accuracy: 0.1411 - val_mse: 30779.7461 - val_mae: 72.9065 - val_rmse: 137.4894\n",
      "Epoch 2/50\n",
      "4563/4563 [==============================] - 53s 12ms/step - loss: 2296356864.0000 - accuracy: 0.1428 - mse: 2296454144.0000 - mae: 96.6854 - rmse: 197.0893 - val_loss: 30778.8359 - val_accuracy: 0.1396 - val_mse: 30778.8770 - val_mae: 72.8932 - val_rmse: 137.4845\n",
      "Epoch 3/50\n",
      "4563/4563 [==============================] - 54s 12ms/step - loss: 2296363264.0000 - accuracy: 0.1472 - mse: 2296460544.0000 - mae: 96.6758 - rmse: 197.0874 - val_loss: 30778.1562 - val_accuracy: 0.1602 - val_mse: 30778.1973 - val_mae: 72.8822 - val_rmse: 137.4800\n",
      "Epoch 4/50\n",
      "4563/4563 [==============================] - 53s 12ms/step - loss: 2296357632.0000 - accuracy: 0.1589 - mse: 2296455168.0000 - mae: 96.6666 - rmse: 197.0860 - val_loss: 30778.1875 - val_accuracy: 0.1587 - val_mse: 30778.2285 - val_mae: 72.8726 - val_rmse: 137.4800\n",
      "Epoch 5/50\n",
      "4563/4563 [==============================] - 54s 12ms/step - loss: 2296364544.0000 - accuracy: 0.1646 - mse: 2296462080.0000 - mae: 96.6570 - rmse: 197.0849 - val_loss: 30778.2773 - val_accuracy: 0.1586 - val_mse: 30778.3184 - val_mae: 72.8626 - val_rmse: 137.4805\n",
      "Epoch 6/50\n",
      "4563/4563 [==============================] - 56s 12ms/step - loss: 2296347136.0000 - accuracy: 0.1699 - mse: 2296444416.0000 - mae: 96.6494 - rmse: 197.0851 - val_loss: 30778.2539 - val_accuracy: 0.1586 - val_mse: 30778.2949 - val_mae: 72.8571 - val_rmse: 137.4803\n",
      "Epoch 7/50\n",
      "4563/4563 [==============================] - 54s 12ms/step - loss: 2296355840.0000 - accuracy: 0.1743 - mse: 2296453120.0000 - mae: 96.6436 - rmse: 197.0843 - val_loss: 30778.1777 - val_accuracy: 0.1607 - val_mse: 30778.2188 - val_mae: 72.8541 - val_rmse: 137.4794\n",
      "Epoch 8/50\n",
      "4563/4563 [==============================] - 55s 12ms/step - loss: 2296357888.0000 - accuracy: 0.1764 - mse: 2296455168.0000 - mae: 96.6373 - rmse: 197.0824 - val_loss: 30777.5371 - val_accuracy: 0.1624 - val_mse: 30777.5801 - val_mae: 72.8476 - val_rmse: 137.4761\n",
      "Epoch 9/50\n",
      "4563/4563 [==============================] - 54s 12ms/step - loss: 2296348416.0000 - accuracy: 0.1773 - mse: 2296445952.0000 - mae: 96.6397 - rmse: 197.0809 - val_loss: 30777.6504 - val_accuracy: 0.1622 - val_mse: 30777.6934 - val_mae: 72.8595 - val_rmse: 137.4770\n",
      "Epoch 10/50\n",
      "4563/4563 [==============================] - 55s 12ms/step - loss: 2296367360.0000 - accuracy: 0.1778 - mse: 2296464640.0000 - mae: 96.6369 - rmse: 197.0815 - val_loss: 30777.4766 - val_accuracy: 0.1625 - val_mse: 30777.5176 - val_mae: 72.8565 - val_rmse: 137.4759\n",
      "Epoch 11/50\n",
      "4563/4563 [==============================] - 55s 12ms/step - loss: 2296355840.0000 - accuracy: 0.1774 - mse: 2296453120.0000 - mae: 96.6334 - rmse: 197.0804 - val_loss: 30777.4512 - val_accuracy: 0.1626 - val_mse: 30777.4922 - val_mae: 72.8543 - val_rmse: 137.4756\n",
      "Epoch 12/50\n",
      "4563/4563 [==============================] - 54s 12ms/step - loss: 2296354816.0000 - accuracy: 0.1775 - mse: 2296452096.0000 - mae: 96.6304 - rmse: 197.0798 - val_loss: 30777.3828 - val_accuracy: 0.1632 - val_mse: 30777.4238 - val_mae: 72.8518 - val_rmse: 137.4749\n",
      "Epoch 13/50\n",
      "4563/4563 [==============================] - 53s 12ms/step - loss: 2296346112.0000 - accuracy: 0.1771 - mse: 2296443392.0000 - mae: 96.6283 - rmse: 197.0801 - val_loss: 30777.2734 - val_accuracy: 0.1636 - val_mse: 30777.3145 - val_mae: 72.8491 - val_rmse: 137.4742\n",
      "Epoch 14/50\n",
      "4563/4563 [==============================] - 55s 12ms/step - loss: 2296365056.0000 - accuracy: 0.1755 - mse: 2296462336.0000 - mae: 96.6256 - rmse: 197.0788 - val_loss: 30777.2520 - val_accuracy: 0.1636 - val_mse: 30777.2930 - val_mae: 72.8472 - val_rmse: 137.4740\n",
      "Epoch 15/50\n",
      "4563/4563 [==============================] - 53s 12ms/step - loss: 2296351232.0000 - accuracy: 0.1766 - mse: 2296448512.0000 - mae: 96.6236 - rmse: 197.0783 - val_loss: 30777.8223 - val_accuracy: 0.1498 - val_mse: 30777.8613 - val_mae: 72.8494 - val_rmse: 137.4773\n",
      "Epoch 16/50\n",
      "4563/4563 [==============================] - 55s 12ms/step - loss: 2296355072.0000 - accuracy: 0.1829 - mse: 2296452352.0000 - mae: 96.6208 - rmse: 197.0771 - val_loss: 30777.3516 - val_accuracy: 0.1603 - val_mse: 30777.3926 - val_mae: 72.8448 - val_rmse: 137.4738\n",
      "Epoch 17/50\n",
      "4563/4563 [==============================] - 55s 12ms/step - loss: 2296349184.0000 - accuracy: 0.1805 - mse: 2296446464.0000 - mae: 96.6187 - rmse: 197.0762 - val_loss: 30777.5449 - val_accuracy: 0.1513 - val_mse: 30777.5859 - val_mae: 72.8450 - val_rmse: 137.4747\n",
      "Epoch 18/50\n",
      "4563/4563 [==============================] - 53s 12ms/step - loss: 2296367872.0000 - accuracy: 0.1785 - mse: 2296465152.0000 - mae: 96.6174 - rmse: 197.0754 - val_loss: 30777.3516 - val_accuracy: 0.1492 - val_mse: 30777.3926 - val_mae: 72.8426 - val_rmse: 137.4731\n",
      "Epoch 19/50\n",
      "4563/4563 [==============================] - 54s 12ms/step - loss: 2296351232.0000 - accuracy: 0.1780 - mse: 2296448512.0000 - mae: 96.6169 - rmse: 197.0760 - val_loss: 30777.5039 - val_accuracy: 0.1490 - val_mse: 30777.5469 - val_mae: 72.8428 - val_rmse: 137.4739\n",
      "Epoch 20/50\n",
      "4563/4563 [==============================] - 54s 12ms/step - loss: 2296364544.0000 - accuracy: 0.1775 - mse: 2296462080.0000 - mae: 96.6153 - rmse: 197.0747 - val_loss: 30777.3320 - val_accuracy: 0.1498 - val_mse: 30777.3730 - val_mae: 72.8407 - val_rmse: 137.4728\n",
      "Epoch 21/50\n",
      "4563/4563 [==============================] - 54s 12ms/step - loss: 2296374784.0000 - accuracy: 0.1765 - mse: 2296472064.0000 - mae: 96.6143 - rmse: 197.0748 - val_loss: 30777.1602 - val_accuracy: 0.1509 - val_mse: 30777.2012 - val_mae: 72.8393 - val_rmse: 137.4720\n",
      "Epoch 22/50\n",
      "4563/4563 [==============================] - 55s 12ms/step - loss: 2296363008.0000 - accuracy: 0.1764 - mse: 2296460288.0000 - mae: 96.6136 - rmse: 197.0742 - val_loss: 30777.2227 - val_accuracy: 0.1505 - val_mse: 30777.2637 - val_mae: 72.8387 - val_rmse: 137.4719\n",
      "Epoch 23/50\n",
      "4563/4563 [==============================] - 53s 12ms/step - loss: 2296371456.0000 - accuracy: 0.1771 - mse: 2296468736.0000 - mae: 96.6118 - rmse: 197.0728 - val_loss: 30777.1641 - val_accuracy: 0.1511 - val_mse: 30777.2070 - val_mae: 72.8375 - val_rmse: 137.4713\n",
      "Epoch 24/50\n",
      "4563/4563 [==============================] - 55s 12ms/step - loss: 2296353024.0000 - accuracy: 0.1760 - mse: 2296450560.0000 - mae: 96.6116 - rmse: 197.0732 - val_loss: 30777.3203 - val_accuracy: 0.1515 - val_mse: 30777.3613 - val_mae: 72.8378 - val_rmse: 137.4720\n",
      "Epoch 25/50\n",
      "4563/4563 [==============================] - 53s 12ms/step - loss: 2296347648.0000 - accuracy: 0.1766 - mse: 2296444928.0000 - mae: 96.6106 - rmse: 197.0730 - val_loss: 30777.1562 - val_accuracy: 0.1597 - val_mse: 30777.1992 - val_mae: 72.8358 - val_rmse: 137.4708\n",
      "Epoch 26/50\n",
      "4563/4563 [==============================] - 55s 12ms/step - loss: 2296350208.0000 - accuracy: 0.1765 - mse: 2296447488.0000 - mae: 96.6097 - rmse: 197.0730 - val_loss: 30777.2969 - val_accuracy: 0.1516 - val_mse: 30777.3379 - val_mae: 72.8364 - val_rmse: 137.4713\n",
      "Epoch 27/50\n",
      "4563/4563 [==============================] - 55s 12ms/step - loss: 2296343808.0000 - accuracy: 0.1741 - mse: 2296441088.0000 - mae: 96.6091 - rmse: 197.0732 - val_loss: 30777.1797 - val_accuracy: 0.1477 - val_mse: 30777.2207 - val_mae: 72.8345 - val_rmse: 137.4705\n",
      "Epoch 28/50\n",
      "4563/4563 [==============================] - 54s 12ms/step - loss: 2296367872.0000 - accuracy: 0.1742 - mse: 2296465152.0000 - mae: 96.6079 - rmse: 197.0724 - val_loss: 30777.1406 - val_accuracy: 0.1472 - val_mse: 30777.1816 - val_mae: 72.8335 - val_rmse: 137.4699\n",
      "Epoch 29/50\n",
      "4563/4563 [==============================] - 55s 12ms/step - loss: 2296355328.0000 - accuracy: 0.1741 - mse: 2296452864.0000 - mae: 96.6075 - rmse: 197.0720 - val_loss: 30777.1562 - val_accuracy: 0.1472 - val_mse: 30777.1973 - val_mae: 72.8328 - val_rmse: 137.4700\n",
      "Epoch 30/50\n",
      "4563/4563 [==============================] - 54s 12ms/step - loss: 2296365568.0000 - accuracy: 0.1709 - mse: 2296462848.0000 - mae: 96.6066 - rmse: 197.0714 - val_loss: 30777.1211 - val_accuracy: 0.1470 - val_mse: 30777.1641 - val_mae: 72.8319 - val_rmse: 137.4694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "4563/4563 [==============================] - 53s 12ms/step - loss: 2296374528.0000 - accuracy: 0.1705 - mse: 2296471808.0000 - mae: 96.6057 - rmse: 197.0713 - val_loss: 30776.9941 - val_accuracy: 0.1473 - val_mse: 30777.0371 - val_mae: 72.8306 - val_rmse: 137.4686\n",
      "Epoch 32/50\n",
      "4563/4563 [==============================] - 53s 12ms/step - loss: 2296372480.0000 - accuracy: 0.1707 - mse: 2296469760.0000 - mae: 96.6051 - rmse: 197.0704 - val_loss: 30777.0137 - val_accuracy: 0.1469 - val_mse: 30777.0527 - val_mae: 72.8308 - val_rmse: 137.4686\n",
      "Epoch 33/50\n",
      "4563/4563 [==============================] - 53s 12ms/step - loss: 2296357120.0000 - accuracy: 0.1717 - mse: 2296454400.0000 - mae: 96.6035 - rmse: 197.0668 - val_loss: 30776.9824 - val_accuracy: 0.1472 - val_mse: 30777.0254 - val_mae: 72.8304 - val_rmse: 137.4683\n",
      "Epoch 34/50\n",
      "4563/4563 [==============================] - 54s 12ms/step - loss: 2296357376.0000 - accuracy: 0.1719 - mse: 2296454656.0000 - mae: 96.6044 - rmse: 197.0705 - val_loss: 30777.0312 - val_accuracy: 0.1469 - val_mse: 30777.0723 - val_mae: 72.8308 - val_rmse: 137.4686\n",
      "Epoch 35/50\n",
      "4563/4563 [==============================] - 55s 12ms/step - loss: 2296367360.0000 - accuracy: 0.1708 - mse: 2296464640.0000 - mae: 96.6041 - rmse: 197.0707 - val_loss: 30777.0215 - val_accuracy: 0.1490 - val_mse: 30777.0605 - val_mae: 72.8308 - val_rmse: 137.4681\n",
      "Epoch 36/50\n",
      "4563/4563 [==============================] - 53s 12ms/step - loss: 2296371968.0000 - accuracy: 0.1705 - mse: 2296469248.0000 - mae: 96.6020 - rmse: 197.0672 - val_loss: 30777.0410 - val_accuracy: 0.1476 - val_mse: 30777.0801 - val_mae: 72.8309 - val_rmse: 137.4685\n",
      "Epoch 37/50\n",
      "4563/4563 [==============================] - 54s 12ms/step - loss: 2296364032.0000 - accuracy: 0.1722 - mse: 2296461312.0000 - mae: 96.6045 - rmse: 197.0719 - val_loss: 30777.1895 - val_accuracy: 0.1471 - val_mse: 30777.2305 - val_mae: 72.8318 - val_rmse: 137.4693\n",
      "Epoch 38/50\n",
      "4563/4563 [==============================] - 52s 11ms/step - loss: 2296345344.0000 - accuracy: 0.1713 - mse: 2296442624.0000 - mae: 96.6032 - rmse: 197.0698 - val_loss: 30777.0723 - val_accuracy: 0.1476 - val_mse: 30777.1133 - val_mae: 72.8308 - val_rmse: 137.4684\n",
      "Epoch 39/50\n",
      "4563/4563 [==============================] - 54s 12ms/step - loss: 2296360704.0000 - accuracy: 0.1715 - mse: 2296457984.0000 - mae: 96.6032 - rmse: 197.0699 - val_loss: 30777.0566 - val_accuracy: 0.1472 - val_mse: 30777.0977 - val_mae: 72.8308 - val_rmse: 137.4682\n",
      "Epoch 40/50\n",
      "4563/4563 [==============================] - 53s 12ms/step - loss: 2296346624.0000 - accuracy: 0.1708 - mse: 2296443904.0000 - mae: 96.6027 - rmse: 197.0695 - val_loss: 30776.9297 - val_accuracy: 0.1468 - val_mse: 30776.9727 - val_mae: 72.8300 - val_rmse: 137.4677\n",
      "Epoch 41/50\n",
      "4563/4563 [==============================] - 54s 12ms/step - loss: 2296367360.0000 - accuracy: 0.1720 - mse: 2296464640.0000 - mae: 96.6022 - rmse: 197.0693 - val_loss: 30776.9277 - val_accuracy: 0.1478 - val_mse: 30776.9707 - val_mae: 72.8300 - val_rmse: 137.4675\n",
      "Epoch 42/50\n",
      "4563/4563 [==============================] - 58s 13ms/step - loss: 2296348928.0000 - accuracy: 0.1725 - mse: 2296446208.0000 - mae: 96.6018 - rmse: 197.0687 - val_loss: 30776.9980 - val_accuracy: 0.1487 - val_mse: 30777.0391 - val_mae: 72.8306 - val_rmse: 137.4678\n",
      "Epoch 43/50\n",
      "4563/4563 [==============================] - 56s 12ms/step - loss: 2296366336.0000 - accuracy: 0.1720 - mse: 2296463616.0000 - mae: 96.6018 - rmse: 197.0698 - val_loss: 30776.8203 - val_accuracy: 0.1486 - val_mse: 30776.8613 - val_mae: 72.8293 - val_rmse: 137.4667\n",
      "Epoch 44/50\n",
      "4563/4563 [==============================] - 96s 21ms/step - loss: 2296367872.0000 - accuracy: 0.1702 - mse: 2296465152.0000 - mae: 96.6012 - rmse: 197.0689 - val_loss: 30776.9844 - val_accuracy: 0.1475 - val_mse: 30777.0254 - val_mae: 72.8304 - val_rmse: 137.4675\n",
      "Epoch 45/50\n",
      "4563/4563 [==============================] - 137s 30ms/step - loss: 2296357632.0000 - accuracy: 0.1707 - mse: 2296455168.0000 - mae: 96.6009 - rmse: 197.0690 - val_loss: 30776.9180 - val_accuracy: 0.1508 - val_mse: 30776.9609 - val_mae: 72.8299 - val_rmse: 137.4671\n",
      "Epoch 46/50\n",
      "4563/4563 [==============================] - 134s 29ms/step - loss: 2296364032.0000 - accuracy: 0.1710 - mse: 2296461312.0000 - mae: 96.6006 - rmse: 197.0686 - val_loss: 30776.8535 - val_accuracy: 0.1517 - val_mse: 30776.8945 - val_mae: 72.8294 - val_rmse: 137.4669\n",
      "Epoch 47/50\n",
      "4563/4563 [==============================] - 133s 29ms/step - loss: 2296355584.0000 - accuracy: 0.1718 - mse: 2296452864.0000 - mae: 96.6004 - rmse: 197.0693 - val_loss: 30776.8555 - val_accuracy: 0.1507 - val_mse: 30776.8984 - val_mae: 72.8296 - val_rmse: 137.4666\n",
      "Epoch 48/50\n",
      "4563/4563 [==============================] - 134s 29ms/step - loss: 2296348672.0000 - accuracy: 0.1707 - mse: 2296446208.0000 - mae: 96.6002 - rmse: 197.0685 - val_loss: 30776.7422 - val_accuracy: 0.1492 - val_mse: 30776.7832 - val_mae: 72.8286 - val_rmse: 137.4661\n",
      "Epoch 49/50\n",
      "4563/4563 [==============================] - 135s 30ms/step - loss: 2296356352.0000 - accuracy: 0.1703 - mse: 2296453632.0000 - mae: 96.5998 - rmse: 197.0682 - val_loss: 30776.8027 - val_accuracy: 0.1494 - val_mse: 30776.8457 - val_mae: 72.8291 - val_rmse: 137.4663\n",
      "Epoch 50/50\n",
      "4563/4563 [==============================] - 131s 29ms/step - loss: 2296354048.0000 - accuracy: 0.1695 - mse: 2296451328.0000 - mae: 96.5995 - rmse: 197.0676 - val_loss: 30776.8809 - val_accuracy: 0.1492 - val_mse: 30776.9238 - val_mae: 72.8296 - val_rmse: 137.4666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.25, random_state=42)\n",
    "\n",
    "history2 = model.fit(x_train,y_train,batch_size=256,epochs=50, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13518/13518 [==============================] - 180s 13ms/step - loss: 1432071.7500 - accuracy: 0.1475 - mse: 1432085.3750 - mae: 74.2265 - rmse: 141.0122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1432071.75,\n",
       " 0.1475204974412918,\n",
       " 1432085.375,\n",
       " 74.22654724121094,\n",
       " 141.01223754882812]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40554/40554 [==============================] - 537s 13ms/step - loss: 2066725120.0000 - accuracy: 0.1478 - mse: 2066737920.0000 - mae: 94.2109 - rmse: 191.0949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2066725120.0,\n",
       " 0.14784526824951172,\n",
       " 2066737920.0,\n",
       " 94.21088409423828,\n",
       " 191.09494018554688]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Val Accuracy</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Val MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Val MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Val RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.296374e+09</td>\n",
       "      <td>30779.708984</td>\n",
       "      <td>0.149436</td>\n",
       "      <td>0.141140</td>\n",
       "      <td>2.296472e+09</td>\n",
       "      <td>30779.746094</td>\n",
       "      <td>96.697021</td>\n",
       "      <td>72.906517</td>\n",
       "      <td>197.093933</td>\n",
       "      <td>30779.746094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.296357e+09</td>\n",
       "      <td>30778.835938</td>\n",
       "      <td>0.142781</td>\n",
       "      <td>0.139645</td>\n",
       "      <td>2.296454e+09</td>\n",
       "      <td>30778.876953</td>\n",
       "      <td>96.685364</td>\n",
       "      <td>72.893196</td>\n",
       "      <td>197.089279</td>\n",
       "      <td>30778.876953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.296363e+09</td>\n",
       "      <td>30778.156250</td>\n",
       "      <td>0.147191</td>\n",
       "      <td>0.160157</td>\n",
       "      <td>2.296461e+09</td>\n",
       "      <td>30778.197266</td>\n",
       "      <td>96.675766</td>\n",
       "      <td>72.882217</td>\n",
       "      <td>197.087402</td>\n",
       "      <td>30778.197266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.296358e+09</td>\n",
       "      <td>30778.187500</td>\n",
       "      <td>0.158868</td>\n",
       "      <td>0.158688</td>\n",
       "      <td>2.296455e+09</td>\n",
       "      <td>30778.228516</td>\n",
       "      <td>96.666580</td>\n",
       "      <td>72.872559</td>\n",
       "      <td>197.086044</td>\n",
       "      <td>30778.228516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.296365e+09</td>\n",
       "      <td>30778.277344</td>\n",
       "      <td>0.164639</td>\n",
       "      <td>0.158617</td>\n",
       "      <td>2.296462e+09</td>\n",
       "      <td>30778.318359</td>\n",
       "      <td>96.656998</td>\n",
       "      <td>72.862648</td>\n",
       "      <td>197.084885</td>\n",
       "      <td>30778.318359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.296347e+09</td>\n",
       "      <td>30778.253906</td>\n",
       "      <td>0.169908</td>\n",
       "      <td>0.158565</td>\n",
       "      <td>2.296444e+09</td>\n",
       "      <td>30778.294922</td>\n",
       "      <td>96.649445</td>\n",
       "      <td>72.857109</td>\n",
       "      <td>197.085129</td>\n",
       "      <td>30778.294922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.296356e+09</td>\n",
       "      <td>30778.177734</td>\n",
       "      <td>0.174336</td>\n",
       "      <td>0.160683</td>\n",
       "      <td>2.296453e+09</td>\n",
       "      <td>30778.218750</td>\n",
       "      <td>96.643623</td>\n",
       "      <td>72.854111</td>\n",
       "      <td>197.084274</td>\n",
       "      <td>30778.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.296358e+09</td>\n",
       "      <td>30777.537109</td>\n",
       "      <td>0.176364</td>\n",
       "      <td>0.162410</td>\n",
       "      <td>2.296455e+09</td>\n",
       "      <td>30777.580078</td>\n",
       "      <td>96.637306</td>\n",
       "      <td>72.847641</td>\n",
       "      <td>197.082428</td>\n",
       "      <td>30777.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.296348e+09</td>\n",
       "      <td>30777.650391</td>\n",
       "      <td>0.177316</td>\n",
       "      <td>0.162228</td>\n",
       "      <td>2.296446e+09</td>\n",
       "      <td>30777.693359</td>\n",
       "      <td>96.639694</td>\n",
       "      <td>72.859528</td>\n",
       "      <td>197.080902</td>\n",
       "      <td>30777.693359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.296367e+09</td>\n",
       "      <td>30777.476562</td>\n",
       "      <td>0.177832</td>\n",
       "      <td>0.162489</td>\n",
       "      <td>2.296465e+09</td>\n",
       "      <td>30777.517578</td>\n",
       "      <td>96.636879</td>\n",
       "      <td>72.856461</td>\n",
       "      <td>197.081451</td>\n",
       "      <td>30777.517578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.296356e+09</td>\n",
       "      <td>30777.451172</td>\n",
       "      <td>0.177356</td>\n",
       "      <td>0.162633</td>\n",
       "      <td>2.296453e+09</td>\n",
       "      <td>30777.492188</td>\n",
       "      <td>96.633354</td>\n",
       "      <td>72.854286</td>\n",
       "      <td>197.080444</td>\n",
       "      <td>30777.492188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.296355e+09</td>\n",
       "      <td>30777.382812</td>\n",
       "      <td>0.177461</td>\n",
       "      <td>0.163204</td>\n",
       "      <td>2.296452e+09</td>\n",
       "      <td>30777.423828</td>\n",
       "      <td>96.630417</td>\n",
       "      <td>72.851799</td>\n",
       "      <td>197.079803</td>\n",
       "      <td>30777.423828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.296346e+09</td>\n",
       "      <td>30777.273438</td>\n",
       "      <td>0.177128</td>\n",
       "      <td>0.163596</td>\n",
       "      <td>2.296443e+09</td>\n",
       "      <td>30777.314453</td>\n",
       "      <td>96.628326</td>\n",
       "      <td>72.849129</td>\n",
       "      <td>197.080093</td>\n",
       "      <td>30777.314453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.296365e+09</td>\n",
       "      <td>30777.251953</td>\n",
       "      <td>0.175482</td>\n",
       "      <td>0.163562</td>\n",
       "      <td>2.296462e+09</td>\n",
       "      <td>30777.292969</td>\n",
       "      <td>96.625618</td>\n",
       "      <td>72.847229</td>\n",
       "      <td>197.078766</td>\n",
       "      <td>30777.292969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.296351e+09</td>\n",
       "      <td>30777.822266</td>\n",
       "      <td>0.176612</td>\n",
       "      <td>0.149809</td>\n",
       "      <td>2.296449e+09</td>\n",
       "      <td>30777.861328</td>\n",
       "      <td>96.623589</td>\n",
       "      <td>72.849373</td>\n",
       "      <td>197.078308</td>\n",
       "      <td>30777.861328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.296355e+09</td>\n",
       "      <td>30777.351562</td>\n",
       "      <td>0.182871</td>\n",
       "      <td>0.160271</td>\n",
       "      <td>2.296452e+09</td>\n",
       "      <td>30777.392578</td>\n",
       "      <td>96.620850</td>\n",
       "      <td>72.844841</td>\n",
       "      <td>197.077057</td>\n",
       "      <td>30777.392578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.296349e+09</td>\n",
       "      <td>30777.544922</td>\n",
       "      <td>0.180499</td>\n",
       "      <td>0.151274</td>\n",
       "      <td>2.296446e+09</td>\n",
       "      <td>30777.585938</td>\n",
       "      <td>96.618652</td>\n",
       "      <td>72.845016</td>\n",
       "      <td>197.076187</td>\n",
       "      <td>30777.585938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.296368e+09</td>\n",
       "      <td>30777.351562</td>\n",
       "      <td>0.178547</td>\n",
       "      <td>0.149228</td>\n",
       "      <td>2.296465e+09</td>\n",
       "      <td>30777.392578</td>\n",
       "      <td>96.617416</td>\n",
       "      <td>72.842575</td>\n",
       "      <td>197.075424</td>\n",
       "      <td>30777.392578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.296351e+09</td>\n",
       "      <td>30777.503906</td>\n",
       "      <td>0.177987</td>\n",
       "      <td>0.149017</td>\n",
       "      <td>2.296449e+09</td>\n",
       "      <td>30777.546875</td>\n",
       "      <td>96.616890</td>\n",
       "      <td>72.842751</td>\n",
       "      <td>197.076004</td>\n",
       "      <td>30777.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.296365e+09</td>\n",
       "      <td>30777.332031</td>\n",
       "      <td>0.177478</td>\n",
       "      <td>0.149847</td>\n",
       "      <td>2.296462e+09</td>\n",
       "      <td>30777.373047</td>\n",
       "      <td>96.615303</td>\n",
       "      <td>72.840744</td>\n",
       "      <td>197.074722</td>\n",
       "      <td>30777.373047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.296375e+09</td>\n",
       "      <td>30777.160156</td>\n",
       "      <td>0.176519</td>\n",
       "      <td>0.150933</td>\n",
       "      <td>2.296472e+09</td>\n",
       "      <td>30777.201172</td>\n",
       "      <td>96.614342</td>\n",
       "      <td>72.839340</td>\n",
       "      <td>197.074753</td>\n",
       "      <td>30777.201172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.296363e+09</td>\n",
       "      <td>30777.222656</td>\n",
       "      <td>0.176403</td>\n",
       "      <td>0.150471</td>\n",
       "      <td>2.296460e+09</td>\n",
       "      <td>30777.263672</td>\n",
       "      <td>96.613556</td>\n",
       "      <td>72.838737</td>\n",
       "      <td>197.074219</td>\n",
       "      <td>30777.263672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.296371e+09</td>\n",
       "      <td>30777.164062</td>\n",
       "      <td>0.177125</td>\n",
       "      <td>0.151148</td>\n",
       "      <td>2.296469e+09</td>\n",
       "      <td>30777.207031</td>\n",
       "      <td>96.611801</td>\n",
       "      <td>72.837502</td>\n",
       "      <td>197.072800</td>\n",
       "      <td>30777.207031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.296353e+09</td>\n",
       "      <td>30777.320312</td>\n",
       "      <td>0.176034</td>\n",
       "      <td>0.151460</td>\n",
       "      <td>2.296451e+09</td>\n",
       "      <td>30777.361328</td>\n",
       "      <td>96.611572</td>\n",
       "      <td>72.837799</td>\n",
       "      <td>197.073242</td>\n",
       "      <td>30777.361328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.296348e+09</td>\n",
       "      <td>30777.156250</td>\n",
       "      <td>0.176557</td>\n",
       "      <td>0.159734</td>\n",
       "      <td>2.296445e+09</td>\n",
       "      <td>30777.199219</td>\n",
       "      <td>96.610626</td>\n",
       "      <td>72.835754</td>\n",
       "      <td>197.073044</td>\n",
       "      <td>30777.199219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.296350e+09</td>\n",
       "      <td>30777.296875</td>\n",
       "      <td>0.176528</td>\n",
       "      <td>0.151636</td>\n",
       "      <td>2.296447e+09</td>\n",
       "      <td>30777.337891</td>\n",
       "      <td>96.609657</td>\n",
       "      <td>72.836380</td>\n",
       "      <td>197.072983</td>\n",
       "      <td>30777.337891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.296344e+09</td>\n",
       "      <td>30777.179688</td>\n",
       "      <td>0.174128</td>\n",
       "      <td>0.147673</td>\n",
       "      <td>2.296441e+09</td>\n",
       "      <td>30777.220703</td>\n",
       "      <td>96.609116</td>\n",
       "      <td>72.834488</td>\n",
       "      <td>197.073196</td>\n",
       "      <td>30777.220703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.296368e+09</td>\n",
       "      <td>30777.140625</td>\n",
       "      <td>0.174199</td>\n",
       "      <td>0.147219</td>\n",
       "      <td>2.296465e+09</td>\n",
       "      <td>30777.181641</td>\n",
       "      <td>96.607948</td>\n",
       "      <td>72.833458</td>\n",
       "      <td>197.072449</td>\n",
       "      <td>30777.181641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.296355e+09</td>\n",
       "      <td>30777.156250</td>\n",
       "      <td>0.174125</td>\n",
       "      <td>0.147155</td>\n",
       "      <td>2.296453e+09</td>\n",
       "      <td>30777.197266</td>\n",
       "      <td>96.607521</td>\n",
       "      <td>72.832848</td>\n",
       "      <td>197.072021</td>\n",
       "      <td>30777.197266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.296366e+09</td>\n",
       "      <td>30777.121094</td>\n",
       "      <td>0.170882</td>\n",
       "      <td>0.147025</td>\n",
       "      <td>2.296463e+09</td>\n",
       "      <td>30777.164062</td>\n",
       "      <td>96.606560</td>\n",
       "      <td>72.831879</td>\n",
       "      <td>197.071365</td>\n",
       "      <td>30777.164062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.296375e+09</td>\n",
       "      <td>30776.994141</td>\n",
       "      <td>0.170495</td>\n",
       "      <td>0.147326</td>\n",
       "      <td>2.296472e+09</td>\n",
       "      <td>30777.037109</td>\n",
       "      <td>96.605667</td>\n",
       "      <td>72.830643</td>\n",
       "      <td>197.071335</td>\n",
       "      <td>30777.037109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.296372e+09</td>\n",
       "      <td>30777.013672</td>\n",
       "      <td>0.170666</td>\n",
       "      <td>0.146924</td>\n",
       "      <td>2.296470e+09</td>\n",
       "      <td>30777.052734</td>\n",
       "      <td>96.605072</td>\n",
       "      <td>72.830757</td>\n",
       "      <td>197.070358</td>\n",
       "      <td>30777.052734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.296357e+09</td>\n",
       "      <td>30776.982422</td>\n",
       "      <td>0.171694</td>\n",
       "      <td>0.147210</td>\n",
       "      <td>2.296454e+09</td>\n",
       "      <td>30777.025391</td>\n",
       "      <td>96.603470</td>\n",
       "      <td>72.830368</td>\n",
       "      <td>197.066803</td>\n",
       "      <td>30777.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2.296357e+09</td>\n",
       "      <td>30777.031250</td>\n",
       "      <td>0.171921</td>\n",
       "      <td>0.146855</td>\n",
       "      <td>2.296455e+09</td>\n",
       "      <td>30777.072266</td>\n",
       "      <td>96.604370</td>\n",
       "      <td>72.830757</td>\n",
       "      <td>197.070465</td>\n",
       "      <td>30777.072266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.296367e+09</td>\n",
       "      <td>30777.021484</td>\n",
       "      <td>0.170757</td>\n",
       "      <td>0.148988</td>\n",
       "      <td>2.296465e+09</td>\n",
       "      <td>30777.060547</td>\n",
       "      <td>96.604088</td>\n",
       "      <td>72.830803</td>\n",
       "      <td>197.070679</td>\n",
       "      <td>30777.060547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.296372e+09</td>\n",
       "      <td>30777.041016</td>\n",
       "      <td>0.170506</td>\n",
       "      <td>0.147579</td>\n",
       "      <td>2.296469e+09</td>\n",
       "      <td>30777.080078</td>\n",
       "      <td>96.601959</td>\n",
       "      <td>72.830864</td>\n",
       "      <td>197.067245</td>\n",
       "      <td>30777.080078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.296364e+09</td>\n",
       "      <td>30777.189453</td>\n",
       "      <td>0.172195</td>\n",
       "      <td>0.147131</td>\n",
       "      <td>2.296461e+09</td>\n",
       "      <td>30777.230469</td>\n",
       "      <td>96.604515</td>\n",
       "      <td>72.831779</td>\n",
       "      <td>197.071930</td>\n",
       "      <td>30777.230469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.296345e+09</td>\n",
       "      <td>30777.072266</td>\n",
       "      <td>0.171271</td>\n",
       "      <td>0.147568</td>\n",
       "      <td>2.296443e+09</td>\n",
       "      <td>30777.113281</td>\n",
       "      <td>96.603218</td>\n",
       "      <td>72.830818</td>\n",
       "      <td>197.069794</td>\n",
       "      <td>30777.113281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2.296361e+09</td>\n",
       "      <td>30777.056641</td>\n",
       "      <td>0.171495</td>\n",
       "      <td>0.147182</td>\n",
       "      <td>2.296458e+09</td>\n",
       "      <td>30777.097656</td>\n",
       "      <td>96.603180</td>\n",
       "      <td>72.830849</td>\n",
       "      <td>197.069916</td>\n",
       "      <td>30777.097656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.296347e+09</td>\n",
       "      <td>30776.929688</td>\n",
       "      <td>0.170825</td>\n",
       "      <td>0.146758</td>\n",
       "      <td>2.296444e+09</td>\n",
       "      <td>30776.972656</td>\n",
       "      <td>96.602669</td>\n",
       "      <td>72.830048</td>\n",
       "      <td>197.069473</td>\n",
       "      <td>30776.972656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2.296367e+09</td>\n",
       "      <td>30776.927734</td>\n",
       "      <td>0.171991</td>\n",
       "      <td>0.147796</td>\n",
       "      <td>2.296465e+09</td>\n",
       "      <td>30776.970703</td>\n",
       "      <td>96.602211</td>\n",
       "      <td>72.830032</td>\n",
       "      <td>197.069336</td>\n",
       "      <td>30776.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2.296349e+09</td>\n",
       "      <td>30776.998047</td>\n",
       "      <td>0.172483</td>\n",
       "      <td>0.148744</td>\n",
       "      <td>2.296446e+09</td>\n",
       "      <td>30777.039062</td>\n",
       "      <td>96.601799</td>\n",
       "      <td>72.830582</td>\n",
       "      <td>197.068680</td>\n",
       "      <td>30777.039062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2.296366e+09</td>\n",
       "      <td>30776.820312</td>\n",
       "      <td>0.172047</td>\n",
       "      <td>0.148636</td>\n",
       "      <td>2.296464e+09</td>\n",
       "      <td>30776.861328</td>\n",
       "      <td>96.601776</td>\n",
       "      <td>72.829254</td>\n",
       "      <td>197.069794</td>\n",
       "      <td>30776.861328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2.296368e+09</td>\n",
       "      <td>30776.984375</td>\n",
       "      <td>0.170218</td>\n",
       "      <td>0.147452</td>\n",
       "      <td>2.296465e+09</td>\n",
       "      <td>30777.025391</td>\n",
       "      <td>96.601219</td>\n",
       "      <td>72.830383</td>\n",
       "      <td>197.068863</td>\n",
       "      <td>30777.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2.296358e+09</td>\n",
       "      <td>30776.917969</td>\n",
       "      <td>0.170678</td>\n",
       "      <td>0.150845</td>\n",
       "      <td>2.296455e+09</td>\n",
       "      <td>30776.960938</td>\n",
       "      <td>96.600914</td>\n",
       "      <td>72.829918</td>\n",
       "      <td>197.068954</td>\n",
       "      <td>30776.960938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2.296364e+09</td>\n",
       "      <td>30776.853516</td>\n",
       "      <td>0.171039</td>\n",
       "      <td>0.151724</td>\n",
       "      <td>2.296461e+09</td>\n",
       "      <td>30776.894531</td>\n",
       "      <td>96.600639</td>\n",
       "      <td>72.829430</td>\n",
       "      <td>197.068588</td>\n",
       "      <td>30776.894531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2.296356e+09</td>\n",
       "      <td>30776.855469</td>\n",
       "      <td>0.171806</td>\n",
       "      <td>0.150664</td>\n",
       "      <td>2.296453e+09</td>\n",
       "      <td>30776.898438</td>\n",
       "      <td>96.600441</td>\n",
       "      <td>72.829597</td>\n",
       "      <td>197.069260</td>\n",
       "      <td>30776.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2.296349e+09</td>\n",
       "      <td>30776.742188</td>\n",
       "      <td>0.170671</td>\n",
       "      <td>0.149169</td>\n",
       "      <td>2.296446e+09</td>\n",
       "      <td>30776.783203</td>\n",
       "      <td>96.600235</td>\n",
       "      <td>72.828575</td>\n",
       "      <td>197.068527</td>\n",
       "      <td>30776.783203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2.296356e+09</td>\n",
       "      <td>30776.802734</td>\n",
       "      <td>0.170320</td>\n",
       "      <td>0.149390</td>\n",
       "      <td>2.296454e+09</td>\n",
       "      <td>30776.845703</td>\n",
       "      <td>96.599815</td>\n",
       "      <td>72.829063</td>\n",
       "      <td>197.068176</td>\n",
       "      <td>30776.845703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2.296354e+09</td>\n",
       "      <td>30776.880859</td>\n",
       "      <td>0.169480</td>\n",
       "      <td>0.149210</td>\n",
       "      <td>2.296451e+09</td>\n",
       "      <td>30776.923828</td>\n",
       "      <td>96.599533</td>\n",
       "      <td>72.829552</td>\n",
       "      <td>197.067612</td>\n",
       "      <td>30776.923828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Loss      Val Loss  Accuracy  Val Accuracy           MSE  \\\n",
       "0   2.296374e+09  30779.708984  0.149436      0.141140  2.296472e+09   \n",
       "1   2.296357e+09  30778.835938  0.142781      0.139645  2.296454e+09   \n",
       "2   2.296363e+09  30778.156250  0.147191      0.160157  2.296461e+09   \n",
       "3   2.296358e+09  30778.187500  0.158868      0.158688  2.296455e+09   \n",
       "4   2.296365e+09  30778.277344  0.164639      0.158617  2.296462e+09   \n",
       "5   2.296347e+09  30778.253906  0.169908      0.158565  2.296444e+09   \n",
       "6   2.296356e+09  30778.177734  0.174336      0.160683  2.296453e+09   \n",
       "7   2.296358e+09  30777.537109  0.176364      0.162410  2.296455e+09   \n",
       "8   2.296348e+09  30777.650391  0.177316      0.162228  2.296446e+09   \n",
       "9   2.296367e+09  30777.476562  0.177832      0.162489  2.296465e+09   \n",
       "10  2.296356e+09  30777.451172  0.177356      0.162633  2.296453e+09   \n",
       "11  2.296355e+09  30777.382812  0.177461      0.163204  2.296452e+09   \n",
       "12  2.296346e+09  30777.273438  0.177128      0.163596  2.296443e+09   \n",
       "13  2.296365e+09  30777.251953  0.175482      0.163562  2.296462e+09   \n",
       "14  2.296351e+09  30777.822266  0.176612      0.149809  2.296449e+09   \n",
       "15  2.296355e+09  30777.351562  0.182871      0.160271  2.296452e+09   \n",
       "16  2.296349e+09  30777.544922  0.180499      0.151274  2.296446e+09   \n",
       "17  2.296368e+09  30777.351562  0.178547      0.149228  2.296465e+09   \n",
       "18  2.296351e+09  30777.503906  0.177987      0.149017  2.296449e+09   \n",
       "19  2.296365e+09  30777.332031  0.177478      0.149847  2.296462e+09   \n",
       "20  2.296375e+09  30777.160156  0.176519      0.150933  2.296472e+09   \n",
       "21  2.296363e+09  30777.222656  0.176403      0.150471  2.296460e+09   \n",
       "22  2.296371e+09  30777.164062  0.177125      0.151148  2.296469e+09   \n",
       "23  2.296353e+09  30777.320312  0.176034      0.151460  2.296451e+09   \n",
       "24  2.296348e+09  30777.156250  0.176557      0.159734  2.296445e+09   \n",
       "25  2.296350e+09  30777.296875  0.176528      0.151636  2.296447e+09   \n",
       "26  2.296344e+09  30777.179688  0.174128      0.147673  2.296441e+09   \n",
       "27  2.296368e+09  30777.140625  0.174199      0.147219  2.296465e+09   \n",
       "28  2.296355e+09  30777.156250  0.174125      0.147155  2.296453e+09   \n",
       "29  2.296366e+09  30777.121094  0.170882      0.147025  2.296463e+09   \n",
       "30  2.296375e+09  30776.994141  0.170495      0.147326  2.296472e+09   \n",
       "31  2.296372e+09  30777.013672  0.170666      0.146924  2.296470e+09   \n",
       "32  2.296357e+09  30776.982422  0.171694      0.147210  2.296454e+09   \n",
       "33  2.296357e+09  30777.031250  0.171921      0.146855  2.296455e+09   \n",
       "34  2.296367e+09  30777.021484  0.170757      0.148988  2.296465e+09   \n",
       "35  2.296372e+09  30777.041016  0.170506      0.147579  2.296469e+09   \n",
       "36  2.296364e+09  30777.189453  0.172195      0.147131  2.296461e+09   \n",
       "37  2.296345e+09  30777.072266  0.171271      0.147568  2.296443e+09   \n",
       "38  2.296361e+09  30777.056641  0.171495      0.147182  2.296458e+09   \n",
       "39  2.296347e+09  30776.929688  0.170825      0.146758  2.296444e+09   \n",
       "40  2.296367e+09  30776.927734  0.171991      0.147796  2.296465e+09   \n",
       "41  2.296349e+09  30776.998047  0.172483      0.148744  2.296446e+09   \n",
       "42  2.296366e+09  30776.820312  0.172047      0.148636  2.296464e+09   \n",
       "43  2.296368e+09  30776.984375  0.170218      0.147452  2.296465e+09   \n",
       "44  2.296358e+09  30776.917969  0.170678      0.150845  2.296455e+09   \n",
       "45  2.296364e+09  30776.853516  0.171039      0.151724  2.296461e+09   \n",
       "46  2.296356e+09  30776.855469  0.171806      0.150664  2.296453e+09   \n",
       "47  2.296349e+09  30776.742188  0.170671      0.149169  2.296446e+09   \n",
       "48  2.296356e+09  30776.802734  0.170320      0.149390  2.296454e+09   \n",
       "49  2.296354e+09  30776.880859  0.169480      0.149210  2.296451e+09   \n",
       "\n",
       "         Val MSE        MAE    Val MAE        RMSE      Val RMSE  \n",
       "0   30779.746094  96.697021  72.906517  197.093933  30779.746094  \n",
       "1   30778.876953  96.685364  72.893196  197.089279  30778.876953  \n",
       "2   30778.197266  96.675766  72.882217  197.087402  30778.197266  \n",
       "3   30778.228516  96.666580  72.872559  197.086044  30778.228516  \n",
       "4   30778.318359  96.656998  72.862648  197.084885  30778.318359  \n",
       "5   30778.294922  96.649445  72.857109  197.085129  30778.294922  \n",
       "6   30778.218750  96.643623  72.854111  197.084274  30778.218750  \n",
       "7   30777.580078  96.637306  72.847641  197.082428  30777.580078  \n",
       "8   30777.693359  96.639694  72.859528  197.080902  30777.693359  \n",
       "9   30777.517578  96.636879  72.856461  197.081451  30777.517578  \n",
       "10  30777.492188  96.633354  72.854286  197.080444  30777.492188  \n",
       "11  30777.423828  96.630417  72.851799  197.079803  30777.423828  \n",
       "12  30777.314453  96.628326  72.849129  197.080093  30777.314453  \n",
       "13  30777.292969  96.625618  72.847229  197.078766  30777.292969  \n",
       "14  30777.861328  96.623589  72.849373  197.078308  30777.861328  \n",
       "15  30777.392578  96.620850  72.844841  197.077057  30777.392578  \n",
       "16  30777.585938  96.618652  72.845016  197.076187  30777.585938  \n",
       "17  30777.392578  96.617416  72.842575  197.075424  30777.392578  \n",
       "18  30777.546875  96.616890  72.842751  197.076004  30777.546875  \n",
       "19  30777.373047  96.615303  72.840744  197.074722  30777.373047  \n",
       "20  30777.201172  96.614342  72.839340  197.074753  30777.201172  \n",
       "21  30777.263672  96.613556  72.838737  197.074219  30777.263672  \n",
       "22  30777.207031  96.611801  72.837502  197.072800  30777.207031  \n",
       "23  30777.361328  96.611572  72.837799  197.073242  30777.361328  \n",
       "24  30777.199219  96.610626  72.835754  197.073044  30777.199219  \n",
       "25  30777.337891  96.609657  72.836380  197.072983  30777.337891  \n",
       "26  30777.220703  96.609116  72.834488  197.073196  30777.220703  \n",
       "27  30777.181641  96.607948  72.833458  197.072449  30777.181641  \n",
       "28  30777.197266  96.607521  72.832848  197.072021  30777.197266  \n",
       "29  30777.164062  96.606560  72.831879  197.071365  30777.164062  \n",
       "30  30777.037109  96.605667  72.830643  197.071335  30777.037109  \n",
       "31  30777.052734  96.605072  72.830757  197.070358  30777.052734  \n",
       "32  30777.025391  96.603470  72.830368  197.066803  30777.025391  \n",
       "33  30777.072266  96.604370  72.830757  197.070465  30777.072266  \n",
       "34  30777.060547  96.604088  72.830803  197.070679  30777.060547  \n",
       "35  30777.080078  96.601959  72.830864  197.067245  30777.080078  \n",
       "36  30777.230469  96.604515  72.831779  197.071930  30777.230469  \n",
       "37  30777.113281  96.603218  72.830818  197.069794  30777.113281  \n",
       "38  30777.097656  96.603180  72.830849  197.069916  30777.097656  \n",
       "39  30776.972656  96.602669  72.830048  197.069473  30776.972656  \n",
       "40  30776.970703  96.602211  72.830032  197.069336  30776.970703  \n",
       "41  30777.039062  96.601799  72.830582  197.068680  30777.039062  \n",
       "42  30776.861328  96.601776  72.829254  197.069794  30776.861328  \n",
       "43  30777.025391  96.601219  72.830383  197.068863  30777.025391  \n",
       "44  30776.960938  96.600914  72.829918  197.068954  30776.960938  \n",
       "45  30776.894531  96.600639  72.829430  197.068588  30776.894531  \n",
       "46  30776.898438  96.600441  72.829597  197.069260  30776.898438  \n",
       "47  30776.783203  96.600235  72.828575  197.068527  30776.783203  \n",
       "48  30776.845703  96.599815  72.829063  197.068176  30776.845703  \n",
       "49  30776.923828  96.599533  72.829552  197.067612  30776.923828  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame(history2.history['loss'],columns=[\"Loss\"])\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"val_loss\"],columns=[\"Val Loss\"]))\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"accuracy\"],columns=['Accuracy']))\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"val_accuracy\"],columns=['Val Accuracy']))\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"mse\"],columns=['MSE']))\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"val_mse\"],columns=['Val MSE']))\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"mae\"],columns=['MAE']))\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"val_mae\"],columns=['Val MAE']))\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"rmse\"],columns=['RMSE']))\n",
    "df1=df1.join(pd.DataFrame(history2.history[\"val_mse\"],columns=['Val RMSE']))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_excel(\"GRU_tanh_mse.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"gru_tanh_mse.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"gru_tanh_mse.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "[2066725120.0, 0.14784526824951172, 2066737920.0, 94.21088409423828, 191.09494018554688]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.25, random_state=42)\n",
    "\n",
    "from keras.models import model_from_json\n",
    "json_file = open('gru_tanh_mse.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"gru_tanh_mse.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "loaded_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),loss='mse',metrics=['accuracy','mse','mae',rmse])\n",
    "print(loaded_model.evaluate(x_train, y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13518/13518 [==============================] - 100s 7ms/step - loss: 1432071.7500 - accuracy: 0.1475 - mse: 1432085.3750 - mae: 74.2265 - rmse: 141.0122\n",
      "[1432071.75, 0.1475204974412918, 1432085.375, 74.22654724121094, 141.01223754882812]\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.evaluate(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40554/40554 [==============================] - 299s 7ms/step - loss: 2066725120.0000 - accuracy: 0.1478 - mse: 2066737920.0000 - mae: 94.2109 - rmse: 191.0949\n",
      "[2066725120.0, 0.14784526824951172, 2066737920.0, 94.21088409423828, 191.09494018554688]\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.evaluate(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.25, random_state=42)\n",
    "\n",
    "y_test_pred=model.predict(x_test)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "savetxt('gru_tanh_mse_y_test_pred.csv', y_test_pred[:1001], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "savetxt('gru_tanh_mse_y_test.csv', y_test[:1001], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#completed"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
