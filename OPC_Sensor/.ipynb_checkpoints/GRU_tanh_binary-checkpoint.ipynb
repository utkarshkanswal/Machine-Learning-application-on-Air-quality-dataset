{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os.path as op\n",
    "from csv import writer\n",
    "import math\n",
    "import cmath\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wrapt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_584/2782615379.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m# Bring in subpackages.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m# from tensorflow.python import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mservice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_ragged_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_sparse_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfrom_dataset_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompression_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_server_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_experimental_dataset_ops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mged_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mwrapt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wrapt'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model,Sequential,load_model\n",
    "from keras.layers import Input, Embedding\n",
    "from keras.layers import Dense, Bidirectional\n",
    "from keras.layers.recurrent import LSTM\n",
    "import keras.metrics as metrics\n",
    "import itertools\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from decimal import Decimal\n",
    "from keras.layers import Conv1D,MaxPooling1D,Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.50000e+02 1.90401e+05 7.25000e+02 2.75500e+01 8.03900e+01]\n",
      " [1.50000e+02 1.90401e+05 8.25000e+02 2.75600e+01 8.03300e+01]\n",
      " [1.50000e+02 1.90401e+05 9.25000e+02 2.75800e+01 8.02400e+01]\n",
      " ...\n",
      " [6.10000e+01 1.91020e+05 1.94532e+05 2.93700e+01 7.52100e+01]\n",
      " [6.10000e+01 1.91020e+05 1.94632e+05 2.93500e+01 7.52700e+01]\n",
      " [6.10000e+01 1.91020e+05 1.94732e+05 2.93400e+01 7.53000e+01]]\n",
      "[[ 28.     3.   -52.   ...  16.97  19.63  20.06]\n",
      " [ 28.    15.   -53.   ...  16.63  19.57  23.06]\n",
      " [ 31.    16.   -55.   ...  17.24  19.98  20.24]\n",
      " ...\n",
      " [ 76.    12.   -76.   ...   3.47   3.95   4.35]\n",
      " [ 75.    13.   -76.   ...   3.88   4.33   4.42]\n",
      " [ 76.    12.   -75.   ...   3.46   4.07   4.28]]\n"
     ]
    }
   ],
   "source": [
    "A1=np.empty((0,5),dtype='float32')\n",
    "U1=np.empty((0,7),dtype='float32')\n",
    "node=['150','149','147','144','142','140','136','61']\n",
    "mon=['Apr','Mar','Aug','Jun','Jul','Sep','May','Oct']\n",
    "for j in node:\n",
    "  for i in mon:\n",
    "    inp= pd.read_csv('data_gkv/AT510_Node_'+str(j)+'_'+str(i)+'19_OutputFile.csv',usecols=[1,2,3,15,16])\n",
    "    out= pd.read_csv('data_gkv/AT510_Node_'+str(j)+'_'+str(i)+'19_OutputFile.csv',usecols=[5,6,7,8,17,18,19])\n",
    "    \n",
    "    inp=np.array(inp,dtype='float32')\n",
    "    out=np.array(out,dtype='float32')\n",
    "    \n",
    "    A1=np.append(A1, inp, axis=0)\n",
    "    U1=np.append(U1, out, axis=0)\n",
    "\n",
    "print(A1)\n",
    "print(U1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "scaler_obj=MinMaxScaler()\n",
    "X1=scaler_obj.fit_transform(A1)\n",
    "Y1=scaler_obj.fit_transform(U1)\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "X1=X1[:,np.newaxis,:]\n",
    "Y1=Y1[:,np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 14)                882       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 105       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 7)                 28        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 1,015\n",
      "Trainable params: 1,001\n",
      "Non-trainable params: 14\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(keras.Input(shape=(1,5)))\n",
    "model.add(tf.keras.layers.GRU(14,activation=\"tanh\",use_bias=True,kernel_initializer=\"glorot_uniform\",bias_initializer=\"zeros\", \n",
    "                                kernel_regularizer=keras.regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                                bias_regularizer=keras.regularizers.l2(1e-4),\n",
    "                                activity_regularizer=keras.regularizers.l2(1e-5)))\n",
    "model.add(keras.layers.Dropout(.1))\n",
    "model.add(Dense(7))\n",
    "model.add(keras.layers.BatchNormalization(axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,\n",
    "                                beta_initializer=\"zeros\",gamma_initializer=\"ones\",\n",
    "                                moving_mean_initializer=\"zeros\",moving_variance_initializer=\"ones\",trainable=True))\n",
    "model.add(keras.layers.ReLU())\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),loss='binary_crossentropy',metrics=['accuracy','mse','mae',rmse])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "571/571 [==============================] - 220s 383ms/step - loss: 0.2043 - accuracy: 0.0595 - mse: 0.2030 - mae: 0.2740 - rmse: 0.4118 - val_loss: 0.0422 - val_accuracy: 0.0047 - val_mse: 0.0410 - val_mae: 0.1142 - val_rmse: 0.1729\n",
      "Epoch 2/300\n",
      "571/571 [==============================] - 220s 385ms/step - loss: 0.1678 - accuracy: 0.0584 - mse: 0.1665 - mae: 0.2466 - rmse: 0.3784 - val_loss: 0.0720 - val_accuracy: 0.0105 - val_mse: 0.0708 - val_mae: 0.1447 - val_rmse: 0.2229\n",
      "Epoch 3/300\n",
      "571/571 [==============================] - 224s 392ms/step - loss: 0.1370 - accuracy: 0.0527 - mse: 0.1358 - mae: 0.2212 - rmse: 0.3434 - val_loss: 0.0488 - val_accuracy: 0.0091 - val_mse: 0.0477 - val_mae: 0.1205 - val_rmse: 0.1886\n",
      "Epoch 4/300\n",
      "571/571 [==============================] - 217s 380ms/step - loss: 0.1110 - accuracy: 0.0614 - mse: 0.1099 - mae: 0.1975 - rmse: 0.3072 - val_loss: 0.0315 - val_accuracy: 0.0070 - val_mse: 0.0304 - val_mae: 0.0989 - val_rmse: 0.1558\n",
      "Epoch 5/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 0.0898 - accuracy: 0.0623 - mse: 0.0887 - mae: 0.1753 - rmse: 0.2711 - val_loss: 0.0201 - val_accuracy: 0.0062 - val_mse: 0.0190 - val_mae: 0.0808 - val_rmse: 0.1259\n",
      "Epoch 6/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 0.0721 - accuracy: 0.0932 - mse: 0.0710 - mae: 0.1544 - rmse: 0.2364 - val_loss: 0.0132 - val_accuracy: 0.1232 - val_mse: 0.0121 - val_mae: 0.0661 - val_rmse: 0.1008\n",
      "Epoch 7/300\n",
      "571/571 [==============================] - 216s 379ms/step - loss: 0.0569 - accuracy: 0.1573 - mse: 0.0558 - mae: 0.1339 - rmse: 0.2033 - val_loss: 0.0087 - val_accuracy: 0.1795 - val_mse: 0.0076 - val_mae: 0.0534 - val_rmse: 0.0800\n",
      "Epoch 8/300\n",
      "571/571 [==============================] - 215s 377ms/step - loss: 0.0439 - accuracy: 0.1632 - mse: 0.0429 - mae: 0.1141 - rmse: 0.1726 - val_loss: 0.0057 - val_accuracy: 0.1764 - val_mse: 0.0047 - val_mae: 0.0419 - val_rmse: 0.0627\n",
      "Epoch 9/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 0.0334 - accuracy: 0.1554 - mse: 0.0324 - mae: 0.0965 - rmse: 0.1463 - val_loss: 0.0040 - val_accuracy: 0.1730 - val_mse: 0.0030 - val_mae: 0.0335 - val_rmse: 0.0508\n",
      "Epoch 10/300\n",
      "571/571 [==============================] - 215s 377ms/step - loss: 0.0253 - accuracy: 0.1590 - mse: 0.0243 - mae: 0.0817 - rmse: 0.1241 - val_loss: 0.0031 - val_accuracy: 0.1735 - val_mse: 0.0021 - val_mae: 0.0282 - val_rmse: 0.0434\n",
      "Epoch 11/300\n",
      "571/571 [==============================] - 215s 376ms/step - loss: 0.0189 - accuracy: 0.1674 - mse: 0.0180 - mae: 0.0691 - rmse: 0.1049 - val_loss: 0.0025 - val_accuracy: 0.1756 - val_mse: 0.0016 - val_mae: 0.0242 - val_rmse: 0.0376\n",
      "Epoch 12/300\n",
      "571/571 [==============================] - 216s 378ms/step - loss: 0.0141 - accuracy: 0.1785 - mse: 0.0132 - mae: 0.0585 - rmse: 0.0889 - val_loss: 0.0022 - val_accuracy: 0.1768 - val_mse: 0.0012 - val_mae: 0.0211 - val_rmse: 0.0333\n",
      "Epoch 13/300\n",
      "571/571 [==============================] - 214s 375ms/step - loss: 0.0106 - accuracy: 0.1774 - mse: 0.0097 - mae: 0.0503 - rmse: 0.0764 - val_loss: 0.0019 - val_accuracy: 0.1774 - val_mse: 0.0010 - val_mae: 0.0188 - val_rmse: 0.0303\n",
      "Epoch 14/300\n",
      "571/571 [==============================] - 214s 376ms/step - loss: 0.0081 - accuracy: 0.1576 - mse: 0.0072 - mae: 0.0439 - rmse: 0.0667 - val_loss: 0.0018 - val_accuracy: 0.1784 - val_mse: 9.0912e-04 - val_mae: 0.0171 - val_rmse: 0.0283\n",
      "Epoch 15/300\n",
      "571/571 [==============================] - 215s 377ms/step - loss: 0.0062 - accuracy: 0.1606 - mse: 0.0053 - mae: 0.0382 - rmse: 0.0584 - val_loss: 0.0017 - val_accuracy: 0.1783 - val_mse: 8.4242e-04 - val_mae: 0.0160 - val_rmse: 0.0272\n",
      "Epoch 16/300\n",
      "571/571 [==============================] - 215s 377ms/step - loss: 0.0047 - accuracy: 0.1721 - mse: 0.0039 - mae: 0.0333 - rmse: 0.0513 - val_loss: 0.0016 - val_accuracy: 0.1784 - val_mse: 8.0657e-04 - val_mae: 0.0154 - val_rmse: 0.0266\n",
      "Epoch 17/300\n",
      "571/571 [==============================] - 214s 375ms/step - loss: 0.0037 - accuracy: 0.1809 - mse: 0.0029 - mae: 0.0291 - rmse: 0.0453 - val_loss: 0.0016 - val_accuracy: 0.1782 - val_mse: 7.7768e-04 - val_mae: 0.0148 - val_rmse: 0.0261\n",
      "Epoch 18/300\n",
      "571/571 [==============================] - 215s 376ms/step - loss: 0.0029 - accuracy: 0.1885 - mse: 0.0021 - mae: 0.0255 - rmse: 0.0400 - val_loss: 0.0015 - val_accuracy: 0.1802 - val_mse: 7.5165e-04 - val_mae: 0.0142 - val_rmse: 0.0256\n",
      "Epoch 19/300\n",
      "571/571 [==============================] - 215s 376ms/step - loss: 0.0023 - accuracy: 0.2112 - mse: 0.0016 - mae: 0.0220 - rmse: 0.0352 - val_loss: 0.0014 - val_accuracy: 0.1803 - val_mse: 7.2632e-04 - val_mae: 0.0135 - val_rmse: 0.0246\n",
      "Epoch 20/300\n",
      "571/571 [==============================] - 215s 376ms/step - loss: 0.0019 - accuracy: 0.2237 - mse: 0.0012 - mae: 0.0193 - rmse: 0.0315 - val_loss: 0.0014 - val_accuracy: 0.1806 - val_mse: 7.1520e-04 - val_mae: 0.0131 - val_rmse: 0.0242\n",
      "Epoch 21/300\n",
      "571/571 [==============================] - 212s 371ms/step - loss: 0.0017 - accuracy: 0.2267 - mse: 9.8816e-04 - mae: 0.0170 - rmse: 0.0285 - val_loss: 0.0014 - val_accuracy: 0.1801 - val_mse: 7.1020e-04 - val_mae: 0.0128 - val_rmse: 0.0241\n",
      "Epoch 22/300\n",
      "571/571 [==============================] - 212s 371ms/step - loss: 0.0015 - accuracy: 0.2297 - mse: 8.5011e-04 - mae: 0.0154 - rmse: 0.0265 - val_loss: 0.0014 - val_accuracy: 0.1798 - val_mse: 7.0995e-04 - val_mae: 0.0127 - val_rmse: 0.0241\n",
      "Epoch 23/300\n",
      "571/571 [==============================] - 211s 370ms/step - loss: 0.0014 - accuracy: 0.2336 - mse: 7.6978e-04 - mae: 0.0142 - rmse: 0.0252 - val_loss: 0.0013 - val_accuracy: 0.1792 - val_mse: 7.1036e-04 - val_mae: 0.0128 - val_rmse: 0.0241\n",
      "Epoch 24/300\n",
      "571/571 [==============================] - 212s 372ms/step - loss: 0.0013 - accuracy: 0.2370 - mse: 7.2597e-04 - mae: 0.0135 - rmse: 0.0244 - val_loss: 0.0013 - val_accuracy: 0.1779 - val_mse: 7.1066e-04 - val_mae: 0.0128 - val_rmse: 0.0242\n",
      "Epoch 25/300\n",
      "571/571 [==============================] - 213s 372ms/step - loss: 0.0013 - accuracy: 0.2407 - mse: 6.9999e-04 - mae: 0.0130 - rmse: 0.0239 - val_loss: 0.0013 - val_accuracy: 0.1774 - val_mse: 7.1061e-04 - val_mae: 0.0128 - val_rmse: 0.0242\n",
      "Epoch 26/300\n",
      "571/571 [==============================] - 212s 372ms/step - loss: 0.0012 - accuracy: 0.2452 - mse: 6.8372e-04 - mae: 0.0127 - rmse: 0.0235 - val_loss: 0.0012 - val_accuracy: 0.1774 - val_mse: 7.1067e-04 - val_mae: 0.0128 - val_rmse: 0.0242\n",
      "Epoch 27/300\n",
      "571/571 [==============================] - 212s 372ms/step - loss: 0.0012 - accuracy: 0.2492 - mse: 6.7505e-04 - mae: 0.0125 - rmse: 0.0233 - val_loss: 0.0012 - val_accuracy: 0.1774 - val_mse: 7.1069e-04 - val_mae: 0.0128 - val_rmse: 0.0241\n",
      "Epoch 28/300\n",
      "571/571 [==============================] - 211s 370ms/step - loss: 0.0012 - accuracy: 0.2525 - mse: 6.6756e-04 - mae: 0.0124 - rmse: 0.0231 - val_loss: 0.0012 - val_accuracy: 0.1774 - val_mse: 7.1071e-04 - val_mae: 0.0128 - val_rmse: 0.0241\n",
      "Epoch 29/300\n",
      "571/571 [==============================] - 211s 370ms/step - loss: 0.0011 - accuracy: 0.2552 - mse: 6.6300e-04 - mae: 0.0123 - rmse: 0.0229 - val_loss: 0.0012 - val_accuracy: 0.1774 - val_mse: 7.1073e-04 - val_mae: 0.0127 - val_rmse: 0.0241\n",
      "Epoch 30/300\n",
      "571/571 [==============================] - 212s 371ms/step - loss: 0.0011 - accuracy: 0.2573 - mse: 6.5953e-04 - mae: 0.0122 - rmse: 0.0228 - val_loss: 0.0011 - val_accuracy: 0.1774 - val_mse: 7.1073e-04 - val_mae: 0.0127 - val_rmse: 0.0241\n",
      "Epoch 31/300\n",
      "571/571 [==============================] - 211s 370ms/step - loss: 0.0011 - accuracy: 0.2585 - mse: 6.5649e-04 - mae: 0.0122 - rmse: 0.0227 - val_loss: 0.0011 - val_accuracy: 0.1782 - val_mse: 7.1067e-04 - val_mae: 0.0127 - val_rmse: 0.0241\n",
      "Epoch 32/300\n",
      "571/571 [==============================] - 212s 372ms/step - loss: 0.0011 - accuracy: 0.2596 - mse: 6.5470e-04 - mae: 0.0121 - rmse: 0.0227 - val_loss: 0.0011 - val_accuracy: 0.1797 - val_mse: 7.1012e-04 - val_mae: 0.0127 - val_rmse: 0.0241\n",
      "Epoch 33/300\n",
      "571/571 [==============================] - 212s 371ms/step - loss: 0.0010 - accuracy: 0.2596 - mse: 6.5354e-04 - mae: 0.0121 - rmse: 0.0226 - val_loss: 0.0011 - val_accuracy: 0.1801 - val_mse: 7.0968e-04 - val_mae: 0.0127 - val_rmse: 0.0241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/300\n",
      "571/571 [==============================] - 210s 368ms/step - loss: 0.0010 - accuracy: 0.2606 - mse: 6.5158e-04 - mae: 0.0121 - rmse: 0.0226 - val_loss: 0.0011 - val_accuracy: 0.1806 - val_mse: 7.0916e-04 - val_mae: 0.0127 - val_rmse: 0.0241\n",
      "Epoch 35/300\n",
      "571/571 [==============================] - 210s 368ms/step - loss: 9.9049e-04 - accuracy: 0.2611 - mse: 6.5114e-04 - mae: 0.0121 - rmse: 0.0226 - val_loss: 0.0010 - val_accuracy: 0.1810 - val_mse: 7.0878e-04 - val_mae: 0.0127 - val_rmse: 0.0241\n",
      "Epoch 36/300\n",
      "571/571 [==============================] - 210s 368ms/step - loss: 9.6942e-04 - accuracy: 0.2617 - mse: 6.4976e-04 - mae: 0.0120 - rmse: 0.0226 - val_loss: 0.0010 - val_accuracy: 0.1814 - val_mse: 7.0857e-04 - val_mae: 0.0127 - val_rmse: 0.0241\n",
      "Epoch 37/300\n",
      "571/571 [==============================] - 210s 367ms/step - loss: 9.5085e-04 - accuracy: 0.2614 - mse: 6.5018e-04 - mae: 0.0120 - rmse: 0.0226 - val_loss: 9.9979e-04 - val_accuracy: 0.1817 - val_mse: 7.0830e-04 - val_mae: 0.0127 - val_rmse: 0.0241\n",
      "Epoch 38/300\n",
      "571/571 [==============================] - 209s 367ms/step - loss: 9.3182e-04 - accuracy: 0.2616 - mse: 6.4923e-04 - mae: 0.0120 - rmse: 0.0225 - val_loss: 9.8131e-04 - val_accuracy: 0.1826 - val_mse: 7.0754e-04 - val_mae: 0.0127 - val_rmse: 0.0241\n",
      "Epoch 39/300\n",
      "571/571 [==============================] - 209s 367ms/step - loss: 9.1448e-04 - accuracy: 0.2620 - mse: 6.4923e-04 - mae: 0.0120 - rmse: 0.0225 - val_loss: 9.6394e-04 - val_accuracy: 0.1830 - val_mse: 7.0711e-04 - val_mae: 0.0127 - val_rmse: 0.0241\n",
      "Epoch 40/300\n",
      "571/571 [==============================] - 209s 367ms/step - loss: 8.9799e-04 - accuracy: 0.2620 - mse: 6.4931e-04 - mae: 0.0120 - rmse: 0.0225 - val_loss: 9.4743e-04 - val_accuracy: 0.1832 - val_mse: 7.0678e-04 - val_mae: 0.0127 - val_rmse: 0.0241\n",
      "Epoch 41/300\n",
      "571/571 [==============================] - 211s 369ms/step - loss: 8.8214e-04 - accuracy: 0.2619 - mse: 6.4920e-04 - mae: 0.0120 - rmse: 0.0225 - val_loss: 9.3172e-04 - val_accuracy: 0.1834 - val_mse: 7.0636e-04 - val_mae: 0.0127 - val_rmse: 0.0241\n",
      "Epoch 42/300\n",
      "571/571 [==============================] - 210s 368ms/step - loss: 8.6628e-04 - accuracy: 0.2623 - mse: 6.4819e-04 - mae: 0.0120 - rmse: 0.0225 - val_loss: 9.1696e-04 - val_accuracy: 0.1835 - val_mse: 7.0601e-04 - val_mae: 0.0126 - val_rmse: 0.0240\n",
      "Epoch 43/300\n",
      "571/571 [==============================] - 211s 369ms/step - loss: 8.5254e-04 - accuracy: 0.2622 - mse: 6.4845e-04 - mae: 0.0120 - rmse: 0.0225 - val_loss: 9.0334e-04 - val_accuracy: 0.1833 - val_mse: 7.0605e-04 - val_mae: 0.0126 - val_rmse: 0.0240\n",
      "Epoch 44/300\n",
      "571/571 [==============================] - 210s 368ms/step - loss: 8.3811e-04 - accuracy: 0.2625 - mse: 6.4734e-04 - mae: 0.0120 - rmse: 0.0225 - val_loss: 8.8984e-04 - val_accuracy: 0.1834 - val_mse: 7.0550e-04 - val_mae: 0.0126 - val_rmse: 0.0240\n",
      "Epoch 45/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 8.2562e-04 - accuracy: 0.2626 - mse: 6.4743e-04 - mae: 0.0120 - rmse: 0.0225 - val_loss: 8.7753e-04 - val_accuracy: 0.1834 - val_mse: 7.0540e-04 - val_mae: 0.0126 - val_rmse: 0.0240\n",
      "Epoch 46/300\n",
      "571/571 [==============================] - 210s 367ms/step - loss: 8.1403e-04 - accuracy: 0.2624 - mse: 6.4770e-04 - mae: 0.0120 - rmse: 0.0225 - val_loss: 8.6523e-04 - val_accuracy: 0.1835 - val_mse: 7.0458e-04 - val_mae: 0.0126 - val_rmse: 0.0240\n",
      "Epoch 47/300\n",
      "571/571 [==============================] - 214s 374ms/step - loss: 8.0233e-04 - accuracy: 0.2624 - mse: 6.4716e-04 - mae: 0.0120 - rmse: 0.0225 - val_loss: 8.5484e-04 - val_accuracy: 0.1834 - val_mse: 7.0506e-04 - val_mae: 0.0126 - val_rmse: 0.0240\n",
      "Epoch 48/300\n",
      "571/571 [==============================] - 210s 368ms/step - loss: 7.9111e-04 - accuracy: 0.2629 - mse: 6.4648e-04 - mae: 0.0120 - rmse: 0.0225 - val_loss: 8.4424e-04 - val_accuracy: 0.1835 - val_mse: 7.0464e-04 - val_mae: 0.0126 - val_rmse: 0.0240\n",
      "Epoch 49/300\n",
      "571/571 [==============================] - 211s 370ms/step - loss: 7.8155e-04 - accuracy: 0.2628 - mse: 6.4676e-04 - mae: 0.0120 - rmse: 0.0225 - val_loss: 8.3459e-04 - val_accuracy: 0.1835 - val_mse: 7.0459e-04 - val_mae: 0.0126 - val_rmse: 0.0240\n",
      "Epoch 50/300\n",
      "571/571 [==============================] - 210s 368ms/step - loss: 7.7186e-04 - accuracy: 0.2626 - mse: 6.4641e-04 - mae: 0.0120 - rmse: 0.0225 - val_loss: 8.2467e-04 - val_accuracy: 0.1839 - val_mse: 7.0365e-04 - val_mae: 0.0126 - val_rmse: 0.0240\n",
      "Epoch 51/300\n",
      "571/571 [==============================] - 209s 367ms/step - loss: 7.6278e-04 - accuracy: 0.2628 - mse: 6.4602e-04 - mae: 0.0120 - rmse: 0.0224 - val_loss: 8.1699e-04 - val_accuracy: 0.1837 - val_mse: 7.0436e-04 - val_mae: 0.0126 - val_rmse: 0.0240\n",
      "Epoch 52/300\n",
      "571/571 [==============================] - 209s 367ms/step - loss: 7.5515e-04 - accuracy: 0.2623 - mse: 6.4649e-04 - mae: 0.0120 - rmse: 0.0225 - val_loss: 8.0832e-04 - val_accuracy: 0.1841 - val_mse: 7.0353e-04 - val_mae: 0.0126 - val_rmse: 0.0239\n",
      "Epoch 53/300\n",
      "571/571 [==============================] - 210s 368ms/step - loss: 7.4694e-04 - accuracy: 0.2624 - mse: 6.4587e-04 - mae: 0.0120 - rmse: 0.0224 - val_loss: 8.0101e-04 - val_accuracy: 0.1844 - val_mse: 7.0353e-04 - val_mae: 0.0126 - val_rmse: 0.0240\n",
      "Epoch 54/300\n",
      "571/571 [==============================] - 210s 368ms/step - loss: 7.3933e-04 - accuracy: 0.2630 - mse: 6.4528e-04 - mae: 0.0120 - rmse: 0.0224 - val_loss: 7.9410e-04 - val_accuracy: 0.1845 - val_mse: 7.0332e-04 - val_mae: 0.0126 - val_rmse: 0.0239\n",
      "Epoch 55/300\n",
      "571/571 [==============================] - 211s 369ms/step - loss: 7.3330e-04 - accuracy: 0.2627 - mse: 6.4567e-04 - mae: 0.0120 - rmse: 0.0224 - val_loss: 7.8827e-04 - val_accuracy: 0.1845 - val_mse: 7.0366e-04 - val_mae: 0.0126 - val_rmse: 0.0240\n",
      "Epoch 56/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 7.2697e-04 - accuracy: 0.2630 - mse: 6.4530e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.8227e-04 - val_accuracy: 0.1848 - val_mse: 7.0338e-04 - val_mae: 0.0126 - val_rmse: 0.0239\n",
      "Epoch 57/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 7.2108e-04 - accuracy: 0.2635 - mse: 6.4486e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.7674e-04 - val_accuracy: 0.1849 - val_mse: 7.0307e-04 - val_mae: 0.0126 - val_rmse: 0.0239\n",
      "Epoch 58/300\n",
      "571/571 [==============================] - 209s 367ms/step - loss: 7.1663e-04 - accuracy: 0.2625 - mse: 6.4542e-04 - mae: 0.0120 - rmse: 0.0224 - val_loss: 7.7157e-04 - val_accuracy: 0.1852 - val_mse: 7.0271e-04 - val_mae: 0.0126 - val_rmse: 0.0239\n",
      "Epoch 59/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 7.1162e-04 - accuracy: 0.2628 - mse: 6.4503e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.6664e-04 - val_accuracy: 0.1854 - val_mse: 7.0228e-04 - val_mae: 0.0126 - val_rmse: 0.0239\n",
      "Epoch 60/300\n",
      "571/571 [==============================] - 209s 365ms/step - loss: 7.0728e-04 - accuracy: 0.2626 - mse: 6.4499e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.6271e-04 - val_accuracy: 0.1856 - val_mse: 7.0238e-04 - val_mae: 0.0126 - val_rmse: 0.0239\n",
      "Epoch 61/300\n",
      "571/571 [==============================] - 208s 365ms/step - loss: 7.0319e-04 - accuracy: 0.2630 - mse: 6.4469e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.5875e-04 - val_accuracy: 0.1861 - val_mse: 7.0200e-04 - val_mae: 0.0126 - val_rmse: 0.0239\n",
      "Epoch 62/300\n",
      "571/571 [==============================] - 209s 367ms/step - loss: 6.9917e-04 - accuracy: 0.2634 - mse: 6.4409e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.5500e-04 - val_accuracy: 0.1862 - val_mse: 7.0152e-04 - val_mae: 0.0125 - val_rmse: 0.0239\n",
      "Epoch 63/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.9649e-04 - accuracy: 0.2628 - mse: 6.4452e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.5195e-04 - val_accuracy: 0.1864 - val_mse: 7.0144e-04 - val_mae: 0.0125 - val_rmse: 0.0239\n",
      "Epoch 64/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.9323e-04 - accuracy: 0.2632 - mse: 6.4410e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.4918e-04 - val_accuracy: 0.1863 - val_mse: 7.0137e-04 - val_mae: 0.0125 - val_rmse: 0.0239\n",
      "Epoch 65/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.9075e-04 - accuracy: 0.2632 - mse: 6.4420e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.4643e-04 - val_accuracy: 0.1866 - val_mse: 7.0105e-04 - val_mae: 0.0125 - val_rmse: 0.0239\n",
      "Epoch 66/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.8801e-04 - accuracy: 0.2636 - mse: 6.4379e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.4396e-04 - val_accuracy: 0.1867 - val_mse: 7.0082e-04 - val_mae: 0.0125 - val_rmse: 0.0239\n",
      "Epoch 67/300\n",
      "571/571 [==============================] - 208s 365ms/step - loss: 6.8515e-04 - accuracy: 0.2641 - mse: 6.4312e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.4161e-04 - val_accuracy: 0.1869 - val_mse: 7.0059e-04 - val_mae: 0.0125 - val_rmse: 0.0238\n",
      "Epoch 68/300\n",
      "571/571 [==============================] - 209s 365ms/step - loss: 6.8293e-04 - accuracy: 0.2640 - mse: 6.4293e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.3933e-04 - val_accuracy: 0.1870 - val_mse: 7.0029e-04 - val_mae: 0.0125 - val_rmse: 0.0238\n",
      "Epoch 69/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.8056e-04 - accuracy: 0.2644 - mse: 6.4246e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.3345e-04 - val_accuracy: 0.1901 - val_mse: 6.9624e-04 - val_mae: 0.0125 - val_rmse: 0.0238\n",
      "Epoch 70/300\n",
      "571/571 [==============================] - 209s 365ms/step - loss: 6.7745e-04 - accuracy: 0.2673 - mse: 6.4110e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.3418e-04 - val_accuracy: 0.1901 - val_mse: 6.9862e-04 - val_mae: 0.0125 - val_rmse: 0.0238\n",
      "Epoch 71/300\n",
      "571/571 [==============================] - 209s 367ms/step - loss: 6.7481e-04 - accuracy: 0.2680 - mse: 6.4006e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.3265e-04 - val_accuracy: 0.1901 - val_mse: 6.9866e-04 - val_mae: 0.0125 - val_rmse: 0.0238\n",
      "Epoch 72/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.7302e-04 - accuracy: 0.2678 - mse: 6.3984e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.3116e-04 - val_accuracy: 0.1902 - val_mse: 6.9871e-04 - val_mae: 0.0125 - val_rmse: 0.0238\n",
      "Epoch 73/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.7117e-04 - accuracy: 0.2676 - mse: 6.3948e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.2902e-04 - val_accuracy: 0.1908 - val_mse: 6.9802e-04 - val_mae: 0.0125 - val_rmse: 0.0238\n",
      "Epoch 74/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.6920e-04 - accuracy: 0.2681 - mse: 6.3890e-04 - mae: 0.0119 - rmse: 0.0224 - val_loss: 7.2746e-04 - val_accuracy: 0.1913 - val_mse: 6.9779e-04 - val_mae: 0.0125 - val_rmse: 0.0238\n",
      "Epoch 75/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.6751e-04 - accuracy: 0.2683 - mse: 6.3852e-04 - mae: 0.0119 - rmse: 0.0223 - val_loss: 7.2576e-04 - val_accuracy: 0.1917 - val_mse: 6.9739e-04 - val_mae: 0.0124 - val_rmse: 0.0238\n",
      "Epoch 76/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.6625e-04 - accuracy: 0.2679 - mse: 6.3854e-04 - mae: 0.0119 - rmse: 0.0223 - val_loss: 7.2419e-04 - val_accuracy: 0.1921 - val_mse: 6.9707e-04 - val_mae: 0.0124 - val_rmse: 0.0238\n",
      "Epoch 77/300\n",
      "571/571 [==============================] - 208s 365ms/step - loss: 6.6493e-04 - accuracy: 0.2677 - mse: 6.3842e-04 - mae: 0.0119 - rmse: 0.0223 - val_loss: 7.2259e-04 - val_accuracy: 0.1925 - val_mse: 6.9662e-04 - val_mae: 0.0124 - val_rmse: 0.0237\n",
      "Epoch 78/300\n",
      "571/571 [==============================] - 209s 367ms/step - loss: 6.6311e-04 - accuracy: 0.2684 - mse: 6.3772e-04 - mae: 0.0119 - rmse: 0.0223 - val_loss: 7.2081e-04 - val_accuracy: 0.1930 - val_mse: 6.9593e-04 - val_mae: 0.0124 - val_rmse: 0.0237\n",
      "Epoch 79/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.6216e-04 - accuracy: 0.2681 - mse: 6.3784e-04 - mae: 0.0119 - rmse: 0.0223 - val_loss: 7.1949e-04 - val_accuracy: 0.1937 - val_mse: 6.9563e-04 - val_mae: 0.0124 - val_rmse: 0.0237\n",
      "Epoch 80/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.6086e-04 - accuracy: 0.2688 - mse: 6.3750e-04 - mae: 0.0119 - rmse: 0.0223 - val_loss: 7.1668e-04 - val_accuracy: 0.1958 - val_mse: 6.9377e-04 - val_mae: 0.0124 - val_rmse: 0.0237\n",
      "Epoch 81/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.5901e-04 - accuracy: 0.2695 - mse: 6.3658e-04 - mae: 0.0119 - rmse: 0.0223 - val_loss: 7.1424e-04 - val_accuracy: 0.1958 - val_mse: 6.9225e-04 - val_mae: 0.0124 - val_rmse: 0.0237\n",
      "Epoch 82/300\n",
      "571/571 [==============================] - 208s 365ms/step - loss: 6.5778e-04 - accuracy: 0.2696 - mse: 6.3627e-04 - mae: 0.0119 - rmse: 0.0223 - val_loss: 7.1259e-04 - val_accuracy: 0.1958 - val_mse: 6.9146e-04 - val_mae: 0.0124 - val_rmse: 0.0237\n",
      "Epoch 83/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.5665e-04 - accuracy: 0.2696 - mse: 6.3594e-04 - mae: 0.0118 - rmse: 0.0223 - val_loss: 7.1146e-04 - val_accuracy: 0.1958 - val_mse: 6.9112e-04 - val_mae: 0.0124 - val_rmse: 0.0236\n",
      "Epoch 84/300\n",
      "571/571 [==============================] - 210s 367ms/step - loss: 6.5101e-04 - accuracy: 0.2775 - mse: 6.3103e-04 - mae: 0.0118 - rmse: 0.0222 - val_loss: 6.9882e-04 - val_accuracy: 0.2143 - val_mse: 6.7913e-04 - val_mae: 0.0122 - val_rmse: 0.0235\n",
      "Epoch 85/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.4445e-04 - accuracy: 0.2840 - mse: 6.2513e-04 - mae: 0.0118 - rmse: 0.0222 - val_loss: 7.0231e-04 - val_accuracy: 0.2143 - val_mse: 6.8332e-04 - val_mae: 0.0122 - val_rmse: 0.0235\n",
      "Epoch 86/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.4268e-04 - accuracy: 0.2843 - mse: 6.2408e-04 - mae: 0.0118 - rmse: 0.0222 - val_loss: 7.0131e-04 - val_accuracy: 0.2143 - val_mse: 6.8305e-04 - val_mae: 0.0122 - val_rmse: 0.0235\n",
      "Epoch 87/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.4126e-04 - accuracy: 0.2844 - mse: 6.2336e-04 - mae: 0.0118 - rmse: 0.0222 - val_loss: 6.9892e-04 - val_accuracy: 0.2143 - val_mse: 6.8133e-04 - val_mae: 0.0122 - val_rmse: 0.0235\n",
      "Epoch 88/300\n",
      "571/571 [==============================] - 209s 365ms/step - loss: 6.4021e-04 - accuracy: 0.2842 - mse: 6.2299e-04 - mae: 0.0118 - rmse: 0.0222 - val_loss: 6.9787e-04 - val_accuracy: 0.2143 - val_mse: 6.8095e-04 - val_mae: 0.0122 - val_rmse: 0.0235\n",
      "Epoch 89/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.3773e-04 - accuracy: 0.2873 - mse: 6.2112e-04 - mae: 0.0117 - rmse: 0.0221 - val_loss: 6.9107e-04 - val_accuracy: 0.2228 - val_mse: 6.7473e-04 - val_mae: 0.0121 - val_rmse: 0.0234\n",
      "Epoch 90/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.3471e-04 - accuracy: 0.2906 - mse: 6.1865e-04 - mae: 0.0117 - rmse: 0.0221 - val_loss: 6.9211e-04 - val_accuracy: 0.2228 - val_mse: 6.7631e-04 - val_mae: 0.0121 - val_rmse: 0.0234\n",
      "Epoch 91/300\n",
      "571/571 [==============================] - 209s 366ms/step - loss: 6.3335e-04 - accuracy: 0.2906 - mse: 6.1786e-04 - mae: 0.0117 - rmse: 0.0221 - val_loss: 6.9052e-04 - val_accuracy: 0.2228 - val_mse: 6.7528e-04 - val_mae: 0.0121 - val_rmse: 0.0234\n",
      "Epoch 92/300\n",
      "571/571 [==============================] - 201s 353ms/step - loss: 6.3165e-04 - accuracy: 0.2917 - mse: 6.1671e-04 - mae: 0.0117 - rmse: 0.0221 - val_loss: 6.8825e-04 - val_accuracy: 0.2228 - val_mse: 6.7358e-04 - val_mae: 0.0120 - val_rmse: 0.0234\n",
      "Epoch 93/300\n",
      "571/571 [==============================] - 178s 313ms/step - loss: 6.3068e-04 - accuracy: 0.2912 - mse: 6.1632e-04 - mae: 0.0117 - rmse: 0.0221 - val_loss: 6.8675e-04 - val_accuracy: 0.2228 - val_mse: 6.7262e-04 - val_mae: 0.0120 - val_rmse: 0.0234\n",
      "Epoch 94/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.2968e-04 - accuracy: 0.2911 - mse: 6.1587e-04 - mae: 0.0117 - rmse: 0.0221 - val_loss: 6.8523e-04 - val_accuracy: 0.2228 - val_mse: 6.7165e-04 - val_mae: 0.0120 - val_rmse: 0.0234\n",
      "Epoch 95/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.2841e-04 - accuracy: 0.2914 - mse: 6.1511e-04 - mae: 0.0117 - rmse: 0.0221 - val_loss: 6.8302e-04 - val_accuracy: 0.2228 - val_mse: 6.6997e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 96/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 179s 313ms/step - loss: 6.2717e-04 - accuracy: 0.2917 - mse: 6.1439e-04 - mae: 0.0117 - rmse: 0.0220 - val_loss: 6.8300e-04 - val_accuracy: 0.2228 - val_mse: 6.7043e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 97/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.2675e-04 - accuracy: 0.2909 - mse: 6.1445e-04 - mae: 0.0117 - rmse: 0.0221 - val_loss: 6.8146e-04 - val_accuracy: 0.2228 - val_mse: 6.6934e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 98/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.2559e-04 - accuracy: 0.2915 - mse: 6.1370e-04 - mae: 0.0117 - rmse: 0.0220 - val_loss: 6.8124e-04 - val_accuracy: 0.2228 - val_mse: 6.6951e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 99/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.2500e-04 - accuracy: 0.2911 - mse: 6.1347e-04 - mae: 0.0117 - rmse: 0.0220 - val_loss: 6.7922e-04 - val_accuracy: 0.2228 - val_mse: 6.6781e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 100/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.2428e-04 - accuracy: 0.2913 - mse: 6.1301e-04 - mae: 0.0117 - rmse: 0.0220 - val_loss: 6.7815e-04 - val_accuracy: 0.2228 - val_mse: 6.6703e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 101/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.2312e-04 - accuracy: 0.2920 - mse: 6.1215e-04 - mae: 0.0117 - rmse: 0.0220 - val_loss: 6.7825e-04 - val_accuracy: 0.2228 - val_mse: 6.6738e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 102/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.2292e-04 - accuracy: 0.2915 - mse: 6.1222e-04 - mae: 0.0117 - rmse: 0.0220 - val_loss: 6.7731e-04 - val_accuracy: 0.2228 - val_mse: 6.6670e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 103/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.2232e-04 - accuracy: 0.2917 - mse: 6.1186e-04 - mae: 0.0116 - rmse: 0.0220 - val_loss: 6.7714e-04 - val_accuracy: 0.2228 - val_mse: 6.6678e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 104/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.2213e-04 - accuracy: 0.2915 - mse: 6.1193e-04 - mae: 0.0116 - rmse: 0.0220 - val_loss: 6.7626e-04 - val_accuracy: 0.2228 - val_mse: 6.6615e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 105/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.2171e-04 - accuracy: 0.2915 - mse: 6.1176e-04 - mae: 0.0116 - rmse: 0.0220 - val_loss: 6.7549e-04 - val_accuracy: 0.2228 - val_mse: 6.6562e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 106/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.2134e-04 - accuracy: 0.2916 - mse: 6.1160e-04 - mae: 0.0116 - rmse: 0.0220 - val_loss: 6.7453e-04 - val_accuracy: 0.2228 - val_mse: 6.6488e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 107/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.2110e-04 - accuracy: 0.2915 - mse: 6.1159e-04 - mae: 0.0116 - rmse: 0.0220 - val_loss: 6.7312e-04 - val_accuracy: 0.2228 - val_mse: 6.6369e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 108/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.2074e-04 - accuracy: 0.2916 - mse: 6.1145e-04 - mae: 0.0116 - rmse: 0.0220 - val_loss: 6.7285e-04 - val_accuracy: 0.2228 - val_mse: 6.6363e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 109/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.2046e-04 - accuracy: 0.2915 - mse: 6.1138e-04 - mae: 0.0116 - rmse: 0.0220 - val_loss: 6.7227e-04 - val_accuracy: 0.2228 - val_mse: 6.6326e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 110/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.2014e-04 - accuracy: 0.2917 - mse: 6.1126e-04 - mae: 0.0116 - rmse: 0.0220 - val_loss: 6.7117e-04 - val_accuracy: 0.2228 - val_mse: 6.6235e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 111/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.2000e-04 - accuracy: 0.2915 - mse: 6.1128e-04 - mae: 0.0116 - rmse: 0.0220 - val_loss: 6.7079e-04 - val_accuracy: 0.2228 - val_mse: 6.6216e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 112/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.1972e-04 - accuracy: 0.2916 - mse: 6.1119e-04 - mae: 0.0116 - rmse: 0.0220 - val_loss: 6.7068e-04 - val_accuracy: 0.2228 - val_mse: 6.6222e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 113/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1947e-04 - accuracy: 0.2917 - mse: 6.1114e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6983e-04 - val_accuracy: 0.2228 - val_mse: 6.6154e-04 - val_mae: 0.0121 - val_rmse: 0.0233\n",
      "Epoch 114/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1953e-04 - accuracy: 0.2913 - mse: 6.1134e-04 - mae: 0.0116 - rmse: 0.0220 - val_loss: 6.6957e-04 - val_accuracy: 0.2228 - val_mse: 6.6142e-04 - val_mae: 0.0121 - val_rmse: 0.0233\n",
      "Epoch 115/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.1973e-04 - accuracy: 0.2908 - mse: 6.1165e-04 - mae: 0.0116 - rmse: 0.0220 - val_loss: 6.6870e-04 - val_accuracy: 0.2228 - val_mse: 6.6066e-04 - val_mae: 0.0121 - val_rmse: 0.0233\n",
      "Epoch 116/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1903e-04 - accuracy: 0.2916 - mse: 6.1106e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6816e-04 - val_accuracy: 0.2228 - val_mse: 6.6022e-04 - val_mae: 0.0121 - val_rmse: 0.0233\n",
      "Epoch 117/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1942e-04 - accuracy: 0.2908 - mse: 6.1154e-04 - mae: 0.0116 - rmse: 0.0220 - val_loss: 6.6810e-04 - val_accuracy: 0.2228 - val_mse: 6.6027e-04 - val_mae: 0.0121 - val_rmse: 0.0233\n",
      "Epoch 118/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.1909e-04 - accuracy: 0.2912 - mse: 6.1135e-04 - mae: 0.0116 - rmse: 0.0220 - val_loss: 6.6748e-04 - val_accuracy: 0.2228 - val_mse: 6.5976e-04 - val_mae: 0.0121 - val_rmse: 0.0233\n",
      "Epoch 119/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1867e-04 - accuracy: 0.2916 - mse: 6.1101e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6702e-04 - val_accuracy: 0.2228 - val_mse: 6.5940e-04 - val_mae: 0.0121 - val_rmse: 0.0233\n",
      "Epoch 120/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1850e-04 - accuracy: 0.2917 - mse: 6.1094e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6707e-04 - val_accuracy: 0.2228 - val_mse: 6.5955e-04 - val_mae: 0.0121 - val_rmse: 0.0233\n",
      "Epoch 121/300\n",
      "571/571 [==============================] - 178s 313ms/step - loss: 6.1873e-04 - accuracy: 0.2911 - mse: 6.1127e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6663e-04 - val_accuracy: 0.2228 - val_mse: 6.5921e-04 - val_mae: 0.0121 - val_rmse: 0.0233\n",
      "Epoch 122/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.1853e-04 - accuracy: 0.2913 - mse: 6.1117e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6612e-04 - val_accuracy: 0.2228 - val_mse: 6.5879e-04 - val_mae: 0.0121 - val_rmse: 0.0233\n",
      "Epoch 123/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1842e-04 - accuracy: 0.2912 - mse: 6.1115e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6581e-04 - val_accuracy: 0.2228 - val_mse: 6.5857e-04 - val_mae: 0.0121 - val_rmse: 0.0233\n",
      "Epoch 124/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.1803e-04 - accuracy: 0.2917 - mse: 6.1088e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6553e-04 - val_accuracy: 0.2228 - val_mse: 6.5839e-04 - val_mae: 0.0121 - val_rmse: 0.0233\n",
      "Epoch 125/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1792e-04 - accuracy: 0.2917 - mse: 6.1086e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6511e-04 - val_accuracy: 0.2228 - val_mse: 6.5806e-04 - val_mae: 0.0122 - val_rmse: 0.0233\n",
      "Epoch 126/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.1802e-04 - accuracy: 0.2913 - mse: 6.1105e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6513e-04 - val_accuracy: 0.2228 - val_mse: 6.5817e-04 - val_mae: 0.0121 - val_rmse: 0.0233\n",
      "Epoch 127/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1804e-04 - accuracy: 0.2912 - mse: 6.1114e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6471e-04 - val_accuracy: 0.2228 - val_mse: 6.5784e-04 - val_mae: 0.0122 - val_rmse: 0.0233\n",
      "Epoch 128/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1783e-04 - accuracy: 0.2914 - mse: 6.1102e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6436e-04 - val_accuracy: 0.2228 - val_mse: 6.5757e-04 - val_mae: 0.0122 - val_rmse: 0.0233\n",
      "Epoch 129/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1692e-04 - accuracy: 0.2923 - mse: 6.1021e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.7498e-04 - val_accuracy: 0.2228 - val_mse: 6.6832e-04 - val_mae: 0.0120 - val_rmse: 0.0233\n",
      "Epoch 130/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1190e-04 - accuracy: 0.2953 - mse: 6.0533e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6329e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 131/300\n",
      "571/571 [==============================] - 178s 313ms/step - loss: 6.1194e-04 - accuracy: 0.2950 - mse: 6.0547e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6327e-04 - val_accuracy: 0.2228 - val_mse: 6.5682e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 132/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.1146e-04 - accuracy: 0.2956 - mse: 6.0508e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6307e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 133/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.1116e-04 - accuracy: 0.2959 - mse: 6.0490e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6303e-04 - val_accuracy: 0.2228 - val_mse: 6.5678e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 134/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1114e-04 - accuracy: 0.2958 - mse: 6.0495e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6292e-04 - val_accuracy: 0.2228 - val_mse: 6.5678e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 135/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1108e-04 - accuracy: 0.2957 - mse: 6.0502e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6277e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 136/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.1098e-04 - accuracy: 0.2957 - mse: 6.0501e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6264e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 137/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.1109e-04 - accuracy: 0.2954 - mse: 6.0524e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6257e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0124 - val_rmse: 0.0234\n",
      "Epoch 138/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.1080e-04 - accuracy: 0.2956 - mse: 6.0505e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6248e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 139/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.1056e-04 - accuracy: 0.2959 - mse: 6.0491e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6237e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 140/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1060e-04 - accuracy: 0.2957 - mse: 6.0502e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6228e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 141/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1090e-04 - accuracy: 0.2952 - mse: 6.0538e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6230e-04 - val_accuracy: 0.2228 - val_mse: 6.5676e-04 - val_mae: 0.0124 - val_rmse: 0.0234\n",
      "Epoch 142/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.1076e-04 - accuracy: 0.2953 - mse: 6.0527e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6225e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 143/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1080e-04 - accuracy: 0.2953 - mse: 6.0532e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6221e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 144/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1055e-04 - accuracy: 0.2955 - mse: 6.0511e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6218e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 145/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1045e-04 - accuracy: 0.2957 - mse: 6.0504e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6217e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 146/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1042e-04 - accuracy: 0.2957 - mse: 6.0501e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6215e-04 - val_accuracy: 0.2228 - val_mse: 6.5675e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 147/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1063e-04 - accuracy: 0.2953 - mse: 6.0528e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6210e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 148/300\n",
      "571/571 [==============================] - 178s 313ms/step - loss: 6.1051e-04 - accuracy: 0.2955 - mse: 6.0517e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6207e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 149/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1067e-04 - accuracy: 0.2952 - mse: 6.0536e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6216e-04 - val_accuracy: 0.2228 - val_mse: 6.5683e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 150/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1028e-04 - accuracy: 0.2957 - mse: 6.0500e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6205e-04 - val_accuracy: 0.2228 - val_mse: 6.5675e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 151/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.1055e-04 - accuracy: 0.2953 - mse: 6.0530e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6202e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 152/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1040e-04 - accuracy: 0.2955 - mse: 6.0517e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6197e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 153/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.1019e-04 - accuracy: 0.2957 - mse: 6.0498e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6196e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 154/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1020e-04 - accuracy: 0.2957 - mse: 6.0501e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6192e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 155/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1023e-04 - accuracy: 0.2956 - mse: 6.0506e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6191e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 156/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1045e-04 - accuracy: 0.2952 - mse: 6.0531e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6187e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 157/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1018e-04 - accuracy: 0.2956 - mse: 6.0506e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6200e-04 - val_accuracy: 0.2228 - val_mse: 6.5686e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 158/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1038e-04 - accuracy: 0.2953 - mse: 6.0528e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6183e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 159/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.1000e-04 - accuracy: 0.2958 - mse: 6.0492e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6184e-04 - val_accuracy: 0.2228 - val_mse: 6.5675e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 160/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1000e-04 - accuracy: 0.2958 - mse: 6.0493e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6179e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 161/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0995e-04 - accuracy: 0.2958 - mse: 6.0491e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6176e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 162/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1014e-04 - accuracy: 0.2955 - mse: 6.0510e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6176e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0124 - val_rmse: 0.0234\n",
      "Epoch 163/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1053e-04 - accuracy: 0.2949 - mse: 6.0555e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6182e-04 - val_accuracy: 0.2228 - val_mse: 6.5682e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 164/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1035e-04 - accuracy: 0.2951 - mse: 6.0539e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6176e-04 - val_accuracy: 0.2228 - val_mse: 6.5679e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 165/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1028e-04 - accuracy: 0.2952 - mse: 6.0536e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6168e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 166/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.1006e-04 - accuracy: 0.2955 - mse: 6.0516e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6171e-04 - val_accuracy: 0.2228 - val_mse: 6.5678e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 167/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.0972e-04 - accuracy: 0.2959 - mse: 6.0483e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6163e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 168/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0981e-04 - accuracy: 0.2958 - mse: 6.0494e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6160e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 169/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0987e-04 - accuracy: 0.2956 - mse: 6.0504e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6158e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 170/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.0994e-04 - accuracy: 0.2955 - mse: 6.0512e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6157e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 171/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0997e-04 - accuracy: 0.2955 - mse: 6.0519e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6153e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 172/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0990e-04 - accuracy: 0.2955 - mse: 6.0505e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6151e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 173/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.0966e-04 - accuracy: 0.2958 - mse: 6.0490e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6148e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 174/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0986e-04 - accuracy: 0.2955 - mse: 6.0513e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6151e-04 - val_accuracy: 0.2228 - val_mse: 6.5676e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 175/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.0984e-04 - accuracy: 0.2955 - mse: 6.0514e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6144e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 176/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.1010e-04 - accuracy: 0.2951 - mse: 6.0542e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6142e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 177/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0984e-04 - accuracy: 0.2954 - mse: 6.0517e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6142e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 178/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.0993e-04 - accuracy: 0.2952 - mse: 6.0528e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6140e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 179/300\n",
      "571/571 [==============================] - 180s 315ms/step - loss: 6.0977e-04 - accuracy: 0.2955 - mse: 6.0514e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6136e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 180/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.0979e-04 - accuracy: 0.2954 - mse: 6.0520e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6133e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 181/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0959e-04 - accuracy: 0.2957 - mse: 6.0501e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6135e-04 - val_accuracy: 0.2228 - val_mse: 6.5675e-04 - val_mae: 0.0124 - val_rmse: 0.0234\n",
      "Epoch 182/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0954e-04 - accuracy: 0.2957 - mse: 6.0499e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6129e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 183/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.0964e-04 - accuracy: 0.2955 - mse: 6.0511e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6128e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 184/300\n",
      "571/571 [==============================] - 181s 317ms/step - loss: 6.0967e-04 - accuracy: 0.2955 - mse: 6.0517e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6127e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 185/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0959e-04 - accuracy: 0.2955 - mse: 6.0511e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6124e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 186/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0972e-04 - accuracy: 0.2953 - mse: 6.0524e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6125e-04 - val_accuracy: 0.2228 - val_mse: 6.5676e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 187/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0966e-04 - accuracy: 0.2954 - mse: 6.0520e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6120e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 188/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0971e-04 - accuracy: 0.2953 - mse: 6.0528e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6118e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 189/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0969e-04 - accuracy: 0.2953 - mse: 6.0520e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6116e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 190/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0960e-04 - accuracy: 0.2953 - mse: 6.0519e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6112e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 191/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0970e-04 - accuracy: 0.2952 - mse: 6.0532e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6113e-04 - val_accuracy: 0.2228 - val_mse: 6.5675e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 192/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0958e-04 - accuracy: 0.2953 - mse: 6.0525e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6108e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 193/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0946e-04 - accuracy: 0.2955 - mse: 6.0513e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6106e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 194/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0909e-04 - accuracy: 0.2960 - mse: 6.0479e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6104e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 195/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0948e-04 - accuracy: 0.2954 - mse: 6.0520e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6102e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 196/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0947e-04 - accuracy: 0.2954 - mse: 6.0520e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6102e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 197/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0952e-04 - accuracy: 0.2953 - mse: 6.0527e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6100e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 198/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0920e-04 - accuracy: 0.2957 - mse: 6.0497e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6116e-04 - val_accuracy: 0.2228 - val_mse: 6.5693e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 199/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0927e-04 - accuracy: 0.2956 - mse: 6.0507e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6095e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0124 - val_rmse: 0.0234\n",
      "Epoch 200/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0903e-04 - accuracy: 0.2959 - mse: 6.0484e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6094e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 201/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0944e-04 - accuracy: 0.2953 - mse: 6.0526e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6090e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 202/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0937e-04 - accuracy: 0.2954 - mse: 6.0520e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6088e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 203/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0907e-04 - accuracy: 0.2958 - mse: 6.0494e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6086e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 204/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0933e-04 - accuracy: 0.2953 - mse: 6.0523e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6083e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 205/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0939e-04 - accuracy: 0.2952 - mse: 6.0532e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6088e-04 - val_accuracy: 0.2228 - val_mse: 6.5678e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 206/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0916e-04 - accuracy: 0.2955 - mse: 6.0510e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6081e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 207/300\n",
      "571/571 [==============================] - 177s 310ms/step - loss: 6.0914e-04 - accuracy: 0.2955 - mse: 6.0510e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6078e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 208/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0910e-04 - accuracy: 0.2955 - mse: 6.0506e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6083e-04 - val_accuracy: 0.2228 - val_mse: 6.5679e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 209/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0955e-04 - accuracy: 0.2949 - mse: 6.0554e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6075e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 210/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0927e-04 - accuracy: 0.2953 - mse: 6.0528e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6082e-04 - val_accuracy: 0.2228 - val_mse: 6.5682e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 211/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0890e-04 - accuracy: 0.2957 - mse: 6.0493e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6076e-04 - val_accuracy: 0.2228 - val_mse: 6.5677e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 212/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0922e-04 - accuracy: 0.2953 - mse: 6.0527e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6074e-04 - val_accuracy: 0.2228 - val_mse: 6.5677e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 213/300\n",
      "571/571 [==============================] - 178s 313ms/step - loss: 6.0904e-04 - accuracy: 0.2955 - mse: 6.0512e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6083e-04 - val_accuracy: 0.2228 - val_mse: 6.5688e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 214/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0916e-04 - accuracy: 0.2953 - mse: 6.0525e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6068e-04 - val_accuracy: 0.2228 - val_mse: 6.5676e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 215/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0877e-04 - accuracy: 0.2958 - mse: 6.0490e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6064e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 216/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0915e-04 - accuracy: 0.2953 - mse: 6.0527e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6061e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 217/300\n",
      "571/571 [==============================] - 177s 311ms/step - loss: 6.0908e-04 - accuracy: 0.2953 - mse: 6.0525e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6073e-04 - val_accuracy: 0.2228 - val_mse: 6.5686e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 218/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0933e-04 - accuracy: 0.2950 - mse: 6.0548e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6059e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 219/300\n",
      "571/571 [==============================] - 177s 311ms/step - loss: 6.0868e-04 - accuracy: 0.2958 - mse: 6.0487e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6060e-04 - val_accuracy: 0.2228 - val_mse: 6.5677e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 220/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0901e-04 - accuracy: 0.2953 - mse: 6.0523e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6054e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 221/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0871e-04 - accuracy: 0.2957 - mse: 6.0492e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6052e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 222/300\n",
      "571/571 [==============================] - 177s 310ms/step - loss: 6.0903e-04 - accuracy: 0.2953 - mse: 6.0529e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6054e-04 - val_accuracy: 0.2228 - val_mse: 6.5676e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 223/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0889e-04 - accuracy: 0.2954 - mse: 6.0515e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6047e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 224/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0896e-04 - accuracy: 0.2953 - mse: 6.0524e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6047e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 225/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0912e-04 - accuracy: 0.2951 - mse: 6.0539e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6044e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 226/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0886e-04 - accuracy: 0.2954 - mse: 6.0518e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6042e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 227/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0886e-04 - accuracy: 0.2954 - mse: 6.0519e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6040e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 228/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0880e-04 - accuracy: 0.2955 - mse: 6.0515e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6040e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 229/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0840e-04 - accuracy: 0.2960 - mse: 6.0477e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6038e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 230/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0893e-04 - accuracy: 0.2952 - mse: 6.0531e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6034e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 231/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0867e-04 - accuracy: 0.2956 - mse: 6.0509e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6033e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 232/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0846e-04 - accuracy: 0.2958 - mse: 6.0488e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6040e-04 - val_accuracy: 0.2228 - val_mse: 6.5680e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 233/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0847e-04 - accuracy: 0.2958 - mse: 6.0491e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6029e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 234/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0860e-04 - accuracy: 0.2956 - mse: 6.0507e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6041e-04 - val_accuracy: 0.2228 - val_mse: 6.5685e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 235/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0869e-04 - accuracy: 0.2954 - mse: 6.0518e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6026e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 236/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0847e-04 - accuracy: 0.2957 - mse: 6.0495e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6028e-04 - val_accuracy: 0.2228 - val_mse: 6.5675e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 237/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0841e-04 - accuracy: 0.2958 - mse: 6.0493e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6032e-04 - val_accuracy: 0.2228 - val_mse: 6.5681e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 238/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0841e-04 - accuracy: 0.2958 - mse: 6.0493e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6021e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 239/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.0878e-04 - accuracy: 0.2952 - mse: 6.0532e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6021e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0124 - val_rmse: 0.0234\n",
      "Epoch 240/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0831e-04 - accuracy: 0.2958 - mse: 6.0489e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6020e-04 - val_accuracy: 0.2228 - val_mse: 6.5675e-04 - val_mae: 0.0124 - val_rmse: 0.0234\n",
      "Epoch 241/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0843e-04 - accuracy: 0.2956 - mse: 6.0501e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6015e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 242/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0863e-04 - accuracy: 0.2953 - mse: 6.0522e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6015e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 243/300\n",
      "571/571 [==============================] - 178s 313ms/step - loss: 6.0872e-04 - accuracy: 0.2952 - mse: 6.0534e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6012e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 244/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0839e-04 - accuracy: 0.2956 - mse: 6.0504e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6010e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 245/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0836e-04 - accuracy: 0.2956 - mse: 6.0501e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6009e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 246/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0837e-04 - accuracy: 0.2956 - mse: 6.0501e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6020e-04 - val_accuracy: 0.2228 - val_mse: 6.5684e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 247/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0844e-04 - accuracy: 0.2955 - mse: 6.0512e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6008e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 248/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0850e-04 - accuracy: 0.2954 - mse: 6.0517e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6020e-04 - val_accuracy: 0.2228 - val_mse: 6.5687e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 249/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0842e-04 - accuracy: 0.2955 - mse: 6.0513e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6004e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 250/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0857e-04 - accuracy: 0.2952 - mse: 6.0523e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6007e-04 - val_accuracy: 0.2228 - val_mse: 6.5678e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 251/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0821e-04 - accuracy: 0.2957 - mse: 6.0496e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5999e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 252/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0857e-04 - accuracy: 0.2952 - mse: 6.0532e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5998e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 253/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0820e-04 - accuracy: 0.2957 - mse: 6.0498e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5997e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 254/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0850e-04 - accuracy: 0.2952 - mse: 6.0527e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.6012e-04 - val_accuracy: 0.2228 - val_mse: 6.5689e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 255/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0809e-04 - accuracy: 0.2958 - mse: 6.0491e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.6005e-04 - val_accuracy: 0.2228 - val_mse: 6.5683e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 256/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0805e-04 - accuracy: 0.2958 - mse: 6.0487e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5994e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 257/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0790e-04 - accuracy: 0.2960 - mse: 6.0472e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5990e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 258/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0813e-04 - accuracy: 0.2956 - mse: 6.0497e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5988e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 259/300\n",
      "571/571 [==============================] - 178s 313ms/step - loss: 6.0821e-04 - accuracy: 0.2955 - mse: 6.0508e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5986e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 260/300\n",
      "571/571 [==============================] - 185s 325ms/step - loss: 6.0834e-04 - accuracy: 0.2953 - mse: 6.0524e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5985e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 261/300\n",
      "571/571 [==============================] - 186s 326ms/step - loss: 6.0855e-04 - accuracy: 0.2950 - mse: 6.0545e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5983e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 262/300\n",
      "571/571 [==============================] - 184s 322ms/step - loss: 6.0830e-04 - accuracy: 0.2953 - mse: 6.0523e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5982e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 263/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.0849e-04 - accuracy: 0.2950 - mse: 6.0543e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5988e-04 - val_accuracy: 0.2228 - val_mse: 6.5680e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 264/300\n",
      "571/571 [==============================] - 180s 316ms/step - loss: 6.0789e-04 - accuracy: 0.2959 - mse: 6.0483e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5978e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 265/300\n",
      "571/571 [==============================] - 180s 316ms/step - loss: 6.0790e-04 - accuracy: 0.2958 - mse: 6.0486e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5977e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 266/300\n",
      "571/571 [==============================] - 181s 317ms/step - loss: 6.0819e-04 - accuracy: 0.2954 - mse: 6.0516e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5986e-04 - val_accuracy: 0.2228 - val_mse: 6.5683e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 267/300\n",
      "571/571 [==============================] - 181s 316ms/step - loss: 6.0808e-04 - accuracy: 0.2955 - mse: 6.0510e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5973e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 268/300\n",
      "571/571 [==============================] - 180s 316ms/step - loss: 6.0803e-04 - accuracy: 0.2956 - mse: 6.0504e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5973e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 269/300\n",
      "571/571 [==============================] - 181s 316ms/step - loss: 6.0802e-04 - accuracy: 0.2955 - mse: 6.0506e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5975e-04 - val_accuracy: 0.2228 - val_mse: 6.5676e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 270/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0814e-04 - accuracy: 0.2954 - mse: 6.0517e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5972e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0124 - val_rmse: 0.0234\n",
      "Epoch 271/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0825e-04 - accuracy: 0.2952 - mse: 6.0529e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5981e-04 - val_accuracy: 0.2228 - val_mse: 6.5685e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 272/300\n",
      "571/571 [==============================] - 180s 315ms/step - loss: 6.0794e-04 - accuracy: 0.2956 - mse: 6.0499e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5972e-04 - val_accuracy: 0.2228 - val_mse: 6.5677e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 273/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0790e-04 - accuracy: 0.2956 - mse: 6.0499e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5966e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 274/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0797e-04 - accuracy: 0.2955 - mse: 6.0507e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5963e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 275/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0791e-04 - accuracy: 0.2956 - mse: 6.0501e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5964e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 276/300\n",
      "571/571 [==============================] - 178s 312ms/step - loss: 6.0801e-04 - accuracy: 0.2954 - mse: 6.0513e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5962e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 277/300\n",
      "571/571 [==============================] - 177s 311ms/step - loss: 6.0793e-04 - accuracy: 0.2955 - mse: 6.0508e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5959e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 278/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0797e-04 - accuracy: 0.2954 - mse: 6.0513e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5957e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 279/300\n",
      "571/571 [==============================] - 178s 311ms/step - loss: 6.0767e-04 - accuracy: 0.2958 - mse: 6.0485e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5983e-04 - val_accuracy: 0.2228 - val_mse: 6.5699e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 280/300\n",
      "571/571 [==============================] - 183s 320ms/step - loss: 6.0786e-04 - accuracy: 0.2956 - mse: 6.0505e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5955e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 281/300\n",
      "571/571 [==============================] - 198s 346ms/step - loss: 6.0789e-04 - accuracy: 0.2955 - mse: 6.0509e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5954e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 282/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 197s 345ms/step - loss: 6.0806e-04 - accuracy: 0.2952 - mse: 6.0528e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5958e-04 - val_accuracy: 0.2228 - val_mse: 6.5678e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 283/300\n",
      "571/571 [==============================] - 180s 315ms/step - loss: 6.0805e-04 - accuracy: 0.2952 - mse: 6.0528e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5961e-04 - val_accuracy: 0.2228 - val_mse: 6.5683e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 284/300\n",
      "571/571 [==============================] - 180s 315ms/step - loss: 6.0758e-04 - accuracy: 0.2959 - mse: 6.0483e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5956e-04 - val_accuracy: 0.2228 - val_mse: 6.5679e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 285/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.0767e-04 - accuracy: 0.2957 - mse: 6.0494e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5950e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 286/300\n",
      "571/571 [==============================] - 180s 316ms/step - loss: 6.0786e-04 - accuracy: 0.2954 - mse: 6.0514e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5948e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0124 - val_rmse: 0.0234\n",
      "Epoch 287/300\n",
      "571/571 [==============================] - 180s 316ms/step - loss: 6.0781e-04 - accuracy: 0.2955 - mse: 6.0510e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5945e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 288/300\n",
      "571/571 [==============================] - 181s 318ms/step - loss: 6.0791e-04 - accuracy: 0.2953 - mse: 6.0521e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5943e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 289/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.0770e-04 - accuracy: 0.2956 - mse: 6.0501e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5944e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0124 - val_rmse: 0.0234\n",
      "Epoch 290/300\n",
      "571/571 [==============================] - 181s 317ms/step - loss: 6.0763e-04 - accuracy: 0.2957 - mse: 6.0497e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5943e-04 - val_accuracy: 0.2228 - val_mse: 6.5675e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 291/300\n",
      "571/571 [==============================] - 181s 317ms/step - loss: 6.0778e-04 - accuracy: 0.2954 - mse: 6.0511e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5944e-04 - val_accuracy: 0.2228 - val_mse: 6.5677e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 292/300\n",
      "571/571 [==============================] - 179s 314ms/step - loss: 6.0773e-04 - accuracy: 0.2955 - mse: 6.0508e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5938e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 293/300\n",
      "571/571 [==============================] - 181s 318ms/step - loss: 6.0753e-04 - accuracy: 0.2957 - mse: 6.0489e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5936e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 294/300\n",
      "571/571 [==============================] - 181s 317ms/step - loss: 6.0771e-04 - accuracy: 0.2955 - mse: 6.0509e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5936e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 295/300\n",
      "571/571 [==============================] - 182s 319ms/step - loss: 6.0755e-04 - accuracy: 0.2957 - mse: 6.0495e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5938e-04 - val_accuracy: 0.2228 - val_mse: 6.5676e-04 - val_mae: 0.0124 - val_rmse: 0.0235\n",
      "Epoch 296/300\n",
      "571/571 [==============================] - 181s 318ms/step - loss: 6.0758e-04 - accuracy: 0.2956 - mse: 6.0498e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5932e-04 - val_accuracy: 0.2228 - val_mse: 6.5672e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 297/300\n",
      "571/571 [==============================] - 180s 316ms/step - loss: 6.0767e-04 - accuracy: 0.2955 - mse: 6.0510e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5941e-04 - val_accuracy: 0.2228 - val_mse: 6.5682e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 298/300\n",
      "571/571 [==============================] - 179s 313ms/step - loss: 6.0756e-04 - accuracy: 0.2956 - mse: 6.0501e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5930e-04 - val_accuracy: 0.2228 - val_mse: 6.5673e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n",
      "Epoch 299/300\n",
      "571/571 [==============================] - 181s 317ms/step - loss: 6.0752e-04 - accuracy: 0.2957 - mse: 6.0496e-04 - mae: 0.0116 - rmse: 0.0218 - val_loss: 6.5930e-04 - val_accuracy: 0.2228 - val_mse: 6.5674e-04 - val_mae: 0.0124 - val_rmse: 0.0234\n",
      "Epoch 300/300\n",
      "571/571 [==============================] - 188s 329ms/step - loss: 6.0762e-04 - accuracy: 0.2955 - mse: 6.0508e-04 - mae: 0.0116 - rmse: 0.0219 - val_loss: 6.5926e-04 - val_accuracy: 0.2228 - val_mse: 6.5671e-04 - val_mae: 0.0123 - val_rmse: 0.0234\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.25, random_state=42)\n",
    "\n",
    "history2 = model.fit(x_train,y_train,batch_size=2048,epochs=300, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"Model_File/gru_relu.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"Model_File/gru_relu.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "[0.0006592384306713939, 0.22406166791915894, 0.0006567109376192093, 0.012324623763561249, 0.023422222584486008]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.25, random_state=42)\n",
    "\n",
    "from keras.models import model_from_json\n",
    "json_file = open('Model_File/gru_relu.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"Model_File/gru_relu.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "loaded_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),loss='mse',metrics=['accuracy','mse','mae',rmse])\n",
    "print(loaded_model.evaluate(x_train, y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13518/13518 [==============================] - 28s 2ms/step - loss: 6.5882e-04 - accuracy: 0.2249 - mse: 6.5629e-04 - mae: 0.0123 - rmse: 0.0234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0006588164833374321,\n",
       " 0.22491858899593353,\n",
       " 0.0006562928319908679,\n",
       " 0.012329255230724812,\n",
       " 0.02341914176940918]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(loaded_model.evaluate(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40554/40554 [==============================] - 86s 2ms/step - loss: 6.5924e-04 - accuracy: 0.2241 - mse: 6.5671e-04 - mae: 0.0123 - rmse: 0.0234\n",
      "[0.0006592384306713939, 0.22406166791915894, 0.0006567109376192093, 0.012324623763561249, 0.023422222584486008]\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.evaluate(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb41f52c198>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAxkklEQVR4nO3deZxcVZn/8c9T1dXVa9Jr9kAWwg4GCRFZVAZQENlcABkcdBxxw9HfqD9xHFGZnzPqjI6j4gAiM47IJopkMMqiAXHYEnYSCFkgSWdPel9re35/3Nuh0qlOKtCV6u76vl+vfvWtc5d6bldynzrn3HuOuTsiIiJDRYodgIiIjE5KECIikpMShIiI5KQEISIiOSlBiIhITkoQIiKSkxKECGBm/2Vm/y/PbV81szMKHZNIsSlBiIhITkoQIuOImZUVOwYZP5QgZMwIm3a+aGbPmVmPmf3UzCab2e/MrMvMHjCz+qztzzOz5WbWbmYPmtkRWeuOM7Onwv1uByqGvNd7zOyZcN9HzOzYPGM8x8yeNrNOM9tgZl8fsv6U8Hjt4foPh+WVZvZdM1tnZh1m9uew7B1m1pLj73BGuPx1M7vTzG42s07gw2a20MweDd9js5n9yMzKs/Y/yszuN7NWM9tqZn9vZlPMrNfMGrO2e7OZbTezWD7nLuOPEoSMNe8DzgQOBc4Ffgf8PdBM8O/5bwHM7FDgVuBz4brFwP+YWXl4sfwN8HOgAfhleFzCfY8DbgI+DjQC1wOLzCyeR3w9wF8BdcA5wCfN7ILwuAeH8f4wjGk+8Ey4378CxwMnhTH9XyCT59/kfODO8D1/AaSB/wM0AW8FTgc+FcZQCzwA/B6YBhwC/MHdtwAPAhdlHfdDwG3unswzDhlnlCBkrPmhu291943Aw8Dj7v60u/cDdwHHhdtdDPzW3e8PL3D/ClQSXIBPBGLA99096e53Akuz3uMK4Hp3f9zd0+7+M2Ag3G+v3P1Bd3/e3TPu/hxBknp7uPpS4AF3vzV8353u/oyZRYC/Bj7r7hvD93zE3Qfy/Js86u6/Cd+zz92fdPfH3D3l7q8SJLjBGN4DbHH377p7v7t3ufvj4bqfAZcBmFkU+CBBEpUSpQQhY83WrOW+HK9rwuVpwLrBFe6eATYA08N1G333kSrXZS0fDHw+bKJpN7N2YGa4316Z2VvMbEnYNNMBfILgmzzhMdbk2K2JoIkr17p8bBgSw6Fmdo+ZbQmbnf4pjxgA7gaONLPZBLW0Dnd/4nXGJOOAEoSMV5sILvQAmJkRXBw3ApuB6WHZoIOyljcA33T3uqyfKne/NY/3vQVYBMx094nAdcDg+2wA5ubYZwfQP8y6HqAq6zyiBM1T2YYOyfwfwEvAPHefQNAElx3DnFyBh7WwOwhqER9CtYeSpwQh49UdwDlmdnrYyfp5gmaiR4BHgRTwt2YWM7P3Aguz9v0J8ImwNmBmVh12Ptfm8b61QKu795vZQoJmpUG/AM4ws4vMrMzMGs1sfli7uQn4nplNM7Oomb017PN4GagI3z8G/AOwr76QWqAT6Dazw4FPZq27B5hqZp8zs7iZ1ZrZW7LW/zfwYeA8lCBKnhKEjEvuvpLgm/APCb6hnwuc6+4Jd08A7yW4ELYS9Ff8OmvfZcDHgB8BbcDqcNt8fAq4xsy6gKsJEtXgcdcD7yZIVq0EHdRvCld/AXieoC+kFfg2EHH3jvCYNxLUfnqA3e5qyuELBImpiyDZ3Z4VQxdB89G5wBZgFXBa1vr/Jegcf8rds5vdpASZJgwSkWxm9kfgFne/sdixSHEpQYjILmZ2AnA/QR9KV7HjkeJSE5OIAGBmPyN4RuJzSg4CqkGIiMgwVIMQEZGcxs3AXk1NTT5r1qxihyEiMqY8+eSTO9x96LM1wDhKELNmzWLZsmXFDkNEZEwxs2FvZ1YTk4iI5KQEISIiORU0QZjZWWa20sxWm9lVOdZ/wsyeD8fd/7OZHZm17svhfivN7F2FjFNERPZUsD6IcFCxawke628BlprZIndfkbXZLe5+Xbj9ecD3gLPCRHEJcBTBCJoPmNmh7p7enxiSySQtLS309/ePwBmNbhUVFcyYMYNYTHO7iMjIKGQn9UJgtbuvBTCz2wgmNtmVINy9M2v7al4blfJ8golKBoBXzGx1eLxH9yeAlpYWamtrmTVrFrsP3Dm+uDs7d+6kpaWF2bNnFzscERknCtnENJ3dx6lvCct2Y2afNrM1wHcIZwPLd9996e/vp7GxcVwnBwAzo7GxsSRqSiJy4BS9k9rdr3X3ucCXCIYyzpuZXWFmy8xs2fbt24fbZgSiHP1K5TxF5MApZBPTRoIJWgbNCMuGcxvBRCd57+vuNwA3ACxYsEBjhsiI2dE9wBOvtNLZl6S+upzG6nIaqstJZZw127rpSaQ5bHItR02bQDKTIZV2NrT1sqMrQVU8ykENVaQzTnk0wtodPcxqrKKrP8XOngRd/UkmVMaY3VjN5o5+4rEIz25opyIWpb6qnObacuY212Bm9CfTrNvZy9Pr24hFIzTVxmmsLideFiHjsGZ7Nw3V5dRXlTOzoZJk2imLGD2JFMm0s6Wjn7aeBJXlUZpq4phBZSxKTbwMB6rKowx+t4iY0daT4NmWDroHkpw0t4nK8ig7uxNsaO0llcnQn8zwtkOb2dLRz8b2PubPrKM8GmFdaw+ptFMdL2N2UzVbOvpZubWLI6dOoC+RJho1nt3QzvEH11NfVY7jPPzyDmY2VLG1s59DJ9cSicDEyhjxsiid/Um6+1P0JtIsfbWVo6ZNoL6qnBc2dtCbSNNQU86Muko6+pK09SZJpjMcOrmGjr4kO7sTzGqq5qCGKnb2JNjY1kfGnXhZhKaaOOVlEcoiRl8yTXtvkqaaODu6B6iJl/HMhna6+pP0JdMcO6OOGfWVTJ5QQSwaIZNx2noTPPDiVuJlUd58UD1pd3oTKarLy6itKKM6XsbLW7voS6SZWBWjL5FmQmWM3oE0O3oG6OhNMmlCnOaaODMbgnmgHnhxK8l0hqaaOE01cRpryukdSLO5o5/aijJq4mVsaOulPBrBzEhlMjRUlwPQ3pskFo0ws76SSRMqRvz/QSETxFJgXjh94UaCTufsyVMws3nuvip8eQ7B2PQQzMh1i5l9j6CTeh4wJqc+bG9v55ZbbuFTn/rUfu337ne/m1tuuYW6urrCBCY5feLnT/LImh10D6TI5PGVI2Lktd3+mjKhglQmw47uRN77lEWMVCGC2U9TJlSwpXPvzZ218TK6BlI51zVUl9Pak/95F1pZxKirKqetN0EsavQnMyNyXLMgKadH4DM7evoE7vnMqSMQ1e4KliDcPWVmVwL3AlHgJndfbmbXAMvcfRFwpZmdASQJJma5PNx3uZndQdChnQI+vb93MI0W7e3t/PjHP94jQaRSKcrKhv/zL168uNChyRCPrtnJ75dv4dR5TcyfWcfpR0ymuTZOW0+CnT0JWnsGiJgxt7mG6ngZy15t5ZUdPVTHy4iYMbOhkuaaOB19STa29xGNGF39KeY2V7OpvZ+JlTEaasqZUFHGju4Ea7f3MKO+kq7+FMcdVAdAW0+CDW29/OnlHdRWlDG9rpIZDZXMn1mPEdRsdnQnSKaDi9RBDVW09Sbo6k+xYnMnNfEyzKAqFqUiFqWxJs7kCXF6E2l2dA/gDt0DKfqTaQzoSQT/rTIZJ+PQUFPO7MZqKsujLN/UQSKVoaq8jLnN1UQiRiKV4en1bTTXxpk6sZIVmztJpDLMbqomXhahpa2Px1/ZyYcPmsURUyewcksndZXldA+kOGLqBJ7f2E7PQJqWtj7OPHIS7b1JptZVsmprF+VlEdp6kmzp7GNGfRVNNeVEIxGOmFrLE6+0EotGOHbGRCZWxtjRPUBLWx+1FWU011QQicDja1upiZdx6JRa1u3sYf3OXqriZRwW1k76k2l2dCdIpDLB+ZsxoaKM1p4ETTVx2vuSnHJIE3VVMaIR44WNHWzu6Gfdzl62dw3QVFtOz0CKS044CDN4dkMHleURKmNR+pJpOnqTtPclOWxyLbUVMTr6klSWR+joS1JdXkZjTZyJlWVs6RhgZ88Ar+zoIZHKcNLcJqbVVbCjOxF+vgNUxqJMnVhJV3+S3kSaqRMrSKQzmBmxqNHWkwSgripGIp0hUqAm5nEzmuuCBQt86FAbL774IkcccUSRIgpccskl3H333Rx22GHEYjEqKiqor6/npZde4uWXX+aCCy5gw4YN9Pf389nPfpYrrrgCeG3okO7ubs4++2xOOeUUHnnkEaZPn87dd99NZWXlHu81Gs43Hys2dfLgy9s4dnod0YixalsXHb1J3jq3kVd29DCjvorV27t58KVtHDK5hkQqw+QJFWTcwwtWlGTa6U+mGUhlmFgZYyCZpnsgzRFTa1kwq4GHV23n8CkTaKwpZ8WmTlZu6WJOczVTJlSQzDgrNnWypaOPqXWVzJtUQ08izXfvW0l/Ms1DXzyNili02H8mkQPCzJ509wW51o2bsZj25Rv/s5wVmzr3veF+OHLaBL527lF73eZb3/oWL7zwAs888wwPPvgg55xzDi+88MKu21FvuukmGhoa6Ovr44QTTuB973sfjY2Nux1j1apV3HrrrfzkJz/hoosu4le/+hWXXXbZiJ7LgbDkpW18+/cvsWZ7N8l0ji8m9+/+cnpdJUtWbiNeFnxDG8oMyqMRBlIZzCBeFhm2+m8GQ78L1VaU0dX/WjPHtIkV/PCDb1ZyEAmVTIIYLRYuXLjbswo/+MEPuOuuuwDYsGEDq1at2iNBzJ49m/nz5wNw/PHH8+qrrx6ocEdMJuN8c/GLdPenuOzEg/nISbPZ0NZLxp1DJtWQcXjilZ0cMXVCUJ2viXP4lFoyTthUE3TGxaIRehMpYtEI8bLIro7coAMPVmzuZOkrrRwzo46XtnRSHo1w5LQJHDKphhc2Bs0hZVHj4MYqJtVWsLN7gA1tfZRFjEMm1Sg5iGQpmQSxr2/6B0p1dfWu5QcffJAHHniARx99lKqqKt7xjnfkfJYhHo/vWo5Go/T19R2QWEfS/S9uZfW2bv79kvmcPz94pOWgxqrdtrnwuBkAHD7ltbJo2LRaW/HaE+LZy8BuF/Wjpk3kqGkTATj+4Prdthv6GqCxJk5jTXyPchEZBc9BjHe1tbV0deWevbGjo4P6+nqqqqp46aWXeOyxxw5wdAeGu/PjB9dwUEMV5xwztdjhiEieSqYGUSyNjY2cfPLJHH300VRWVjJ58uRd68466yyuu+46jjjiCA477DBOPPHEIkY6slp7Etzz3CZWbe2mtSfBsxva+eaFR1MW1XcSkbFCdzGNI6PpfK/61XPctnQDEyrKdj0AdveVJ6uNX2SU0V1McsA98Uorpx8+iRsvX6BhQETGKNX3ZcTt6B5g7Y4eTpjdoOQgMoYpQciIe3JdGwAnzNrzriERGTuUIGTEPbmujfJohKOnTyx2KCLyBihByIh7vqWDI6ZNIF6mDmmRsUwJQkaUu7N8UwdHTZtQ7FBE5A1SgiiwwdFcX4/vf//79Pb2jnBEhdXS1kdnf4ojpypBiIx1ShAFVmoJYnk4IKJqECJjn56DKLCrrrqKNWvWMH/+fM4880wmTZrEHXfcwcDAABdeeCHf+MY36Onp4aKLLqKlpYV0Os1Xv/pVtm7dyqZNmzjttNNoampiyZIlxT6VYWUyzr3Lt7BsXRtPr28jYnD4FCUIkbGudBLE766CLc+P7DGnHANnf2uvm2QP933fffdx55138sQTT+DunHfeefzpT39i+/btTJs2jd/+9rdAMEbTxIkT+d73vseSJUtoamoa2bjzlExn+P0LW2jvS3JQQxWv7uhh2bo2qmJRTpjdwAsbO9ja2c+qbd2s3tZNZSxKdbyMc980jcpydVCLjHWlkyBGgfvuu4/77ruP4447DoDu7m5WrVrFqaeeyuc//3m+9KUv8Z73vIdTTx35qQP3VybjXHz9ozy1vn238ul1lXT2J7l92QbKoxGm1lUwoSLGjy49jrOPnko0ogfjRMaL0kkQ+/imfyC4O1/+8pf5+Mc/vse6p556isWLF/MP//APnH766Vx99dVFiPA1i1/YzFPr27n6PUfy7mOmsr61l8aacuY215BMZ9jQ2ktdVfmuydNFZPwpnQRRJNnDfb/rXe/iq1/9Kn/5l39JTU0NGzduJBaLkUqlaGho4LLLLqOuro4bb7xxt3331cTk7jmHtGjvTVBbEWNjWx+PvbKTkw9pYnpd5a51T61vY1ZjNX3JNK09CZ5Z387Dq3bQ2Z/k1Z09zJtUw+UnzSIaMaZMrNh13Fg0wpzmmpH6E4nIKKUEUWDZw32fffbZXHrppbz1rW8FoKamhptvvpnVq1fzxS9+kUgkQiwW4/s//BGpdIbL//qjnPnOdzF16lTuWnwffYk0ZpBIZUimnVjUyDj0JdJEIrC9s58P/b8HOHxKLb2JFE+tb6csYqQywYi91eXBRPblZRG2dPbvMQUnwDHTJzKzoYqFsxt2JQcRKU0a7nuUGEim2dE9QHtfknQm92dSFgnuSi4vixCLGsm0YwZVsSgZh1dWv8xdrxBMtVkW4dR5zQwk00yrq+SIqRP4xePriJdFSKWdgxurOWF2PSu3dFFXFWPqxErmNtfQXKvZ1URKiYb7HqXcnZ09Cdp6EvSnMhgwoTJGTTxKOhMkgqryaPhN34lFI3sdHbWzppzvXjR8Qlw4u2GPspPmFucOKREZ/ZQgiiSdydDS1kdHX5Kq8iiN1eU018aJacY1ERklxn2CGK4Dt5jcnfWtfXT3p5g6sYKmmvgbjnG8NBWKyOgxrr+uVlRUsHPnzlF38dzZk6CrP8m0ugqaaytGJDns3LmTioqKfW8sIpKngtYgzOws4N+BKHCju39ryPq/A/4GSAHbgb9293XhujQw+Ojzenc/b3/ff8aMGbS0tLB9+/Y3cBYjK5NxtnT2Ux6NEOuKs22EjltRUcGMGTNG6GgiIgVMEGYWBa4FzgRagKVmtsjdV2Rt9jSwwN17zeyTwHeAi8N1fe4+/43EEIvFmD179hs5xIj7p8UvcuPDm/ndZ9/GYVNqix2OiMiwCtnEtBBY7e5r3T0B3Aacn72Buy9x98HhSh8DxvVX4I6+JL94bB3nvmmakoOIjHqFTBDTgQ1Zr1vCsuF8FPhd1usKM1tmZo+Z2QW5djCzK8Jtlo2mZqTh3L50PT2JNB87dU6xQxER2adRcReTmV0GLADenlV8sLtvNLM5wB/N7Hl3X5O9n7vfANwAwYNyByzg18Hdue2JDZwwq15zNYvImFDIGsRGYGbW6xlh2W7M7AzgK8B57j4wWO7uG8Pfa4EHgeMKGGvBPbW+jbU7evjAgpn73lhEZBQoZIJYCswzs9lmVg5cAizK3sDMjgOuJ0gO27LK680sHi43AScD2Z3bY86dT26kMhblnGOmFjsUEZG8FKyJyd1TZnYlcC/Bba43uftyM7sGWObui4B/AWqAX4bPAgzeznoEcL2ZZQiS2LeG3P00pqTSGe5dvoUzj5xMdXxUtOqJiOxTQa9W7r4YWDyk7Oqs5TOG2e8R4JhCxnYgPba2ldaeBO9W7UFExpBx/ST1aHHPc5uoLo/yjsOaix2KiEjelCAKrKM3yd3PbOKcY6dSEdM8zSIydihBFNgvn9xAXzLN5SfNKnYoIiL7RQmigNIZ52ePvsoJs+o5apqefRCRsUUJooCWvLSNDa19fPik0TUelIhIPpQgCujnj61jyoQK3nnU5GKHIiKy35QgCmRLRz8Pr9rOBxbM0CxxIjIm6cpVIL96qoWMw/uPH9cD1IrIOKYEUQD9yTQ/f3QdJ85p4ODG6mKHIyLyuihBFMDtSzewpbOfz/zFvGKHIiLyuilBjLD+ZJofP7iahbMaOGluY7HDERF53ZQgRthtT6xna+cAnztjHuEAhCIiY5KGFh1h9zy3mWOmT+Stqj3s7uV74d6/B88UOxKR8Wfy0XDxz0f8sEoQI6ylrY9T5jWp9jDU8t9A11Y47KxiRyIy/jQUZhpjJYgRlEhl2NrVz/S6ymKHMvpsWw4zT4D33VjsSEQkT+qDGEFbOvpxh+n1ShC7yaRh+0qYdGSxIxGR/aAEMYJa2nsBVIMYqnUtpPph8lHFjkRE9oOamEbQxrY+QAkCd+jdGfwG2PB48Fs1CJExRQliBG1sDxLE1LqKIkdSZA99Gx78593LImXQfFhx4hGR10UJYgRtbOtjUm2ceFmJzxy37UWomQJv+8JrZY1zIVbiNSuRMUYJYgRt6uhjWqk3L0HQvNQwBxZ+rNiRiMgboE7qEdTak6SpprzYYRRfzw6oaih2FCLyBilBjKDOviQTKmPFDqP4endAdVOxoxCRN0gJYgR19CWZWOoJIpOB3lao0lAjImOdEsQISaUzdA+klCD628HTUKUahMhYV9AEYWZnmdlKM1ttZlflWP93ZrbCzJ4zsz+Y2cFZ6y43s1Xhz+WFjHMkdPanAJQgencGv9XEJDLmFSxBmFkUuBY4GzgS+KCZDX1S6mlggbsfC9wJfCfctwH4GvAWYCHwNTOrL1SsI6GjLwnAhAolCECd1CLjQCFrEAuB1e6+1t0TwG3A+dkbuPsSd+8NXz4GDE7g/C7gfndvdfc24H5gVA8D2hkmiJKvQfTsCH6riUlkzCtkgpgObMh63RKWDeejwO/2Z18zu8LMlpnZsu3bt7/BcN+YwRrExKoSTxC9YYJQE5PImDcqOqnN7DJgAfAv+7Ofu9/g7gvcfUFzc3NhgstTh2oQgV1NTLqLSWSsK+ST1BuBmVmvZ4RluzGzM4CvAG9394Gsfd8xZN8HCxLlCCnpBLF9JaxcHCyv/gPEqjWshsg4UMgEsRSYZ2azCS74lwCXZm9gZscB1wNnufu2rFX3Av+U1TH9TuDLBYz1DSvZBNG1Ff7rHOjJauI76K3Fi0dERkzBEoS7p8zsSoKLfRS4yd2Xm9k1wDJ3X0TQpFQD/DKconO9u5/n7q1m9o8ESQbgGndvLVSsI6GzL0l5NEK8bFS02hWWO2xdDqvuhWX/BQPd8PGHoWlesD4aL2p4IjIyCjpYn7svBhYPKbs6a/mMvex7E3BT4aIbWR3hMBvjdi7qVALW/DFoSlp1P3RtCspnnggX/BimHlvc+ERkxGk01xHS2Z9kYuU4+nMuuwk2PAGZFCR6YN0jwVPS5bUw9zSY90445AyYMLXYkYpIgYyjK1pxjatxmHaugd9+HiobIF4LsaogIRzzfphzGpRpxFqRUqAEMUI2t/dz6OTaYofx+qQGYNsKaF8P3dtgxd0QLYdPPQo1k4odnYgUiRLECOjqT7J2Rw8XHre35wCLKJWAnm2wczVsfxm2LYdX/gTd2yHZGwyul80icPrVSg4iJU4JYgSs2NQJwNHTJxbmDTLpYAjtTApw8Ez4469tM9AZ9BnEJ8DW56FlGXRtDoa+GOjc/XjxCXDwyXDoWcHzCmWVwZSgTYcGSaGqESIlPm2qiChBjITnN3YAI5wgtq6Ax68LOofb10E6kf++kRhMOw6mvTkY8qKqKfjdMBuaDoPaKTBe77YSkRGjBDEClm/qZMqECpqrY0E7fnnN/o9mmknDpmdg7R9hzYOw/pGgc3j22+Dwc2DiDIiUBc0/ZsFvsi7y0RhMPx5S/cF80HqSWUTeICWIvVn3KDQfts+L/YqNbfxr+fXwzQ9CeiC4eM98Cxx2Nhz1XqibOfzOm5+FP/1r0CfQ3x6UTTkGTvk7eOunNWy2iBRNXgnCzH4N/BT4nbtnChvSKHLz++CQv4CLb95V9O8PrKLGevlI8g4i3ZvJpFN8rX01J0WWw5suhZknBMNPrFwM918dXPzf+5PgNtHIkKes1yyBOy4Pvv0f/p7g+YLZb4ea4g48KCIC+dcgfgx8BPiBmf0S+E93X1m4sEaBTAaSPfDiPbBjFTTNI5NO07nk37i07B6wLqg/iFQmwgy6WDPnQ8y94Ievte2f9uXgeYJbPwi3XgzYnu3+noH62XD5/+y9liEiUgR5JQh3fwB4wMwmAh8MlzcAPwFudvdkAWMsjvTgwLIO//vvcO4PSNz+Yb4aW8TD6aN5eMYV/P3HL+feZzfxmVuf5ndnnrpnAmicC1c8CC/9FnbkyKe1U2H+peovEJFRKe8+CDNrBC4DPkQwVegvgFOAy9l9aO7xIRUmiPIaePY2qJhIxcuL+E7yIn6cPp/jM0HfwMtbu4hGjDnN1bmPU14Fx37gAAUtIjJy8hp61MzuAh4GqoBzwxFXb3f3zxCMxjr+pMNK0YKPBE1Bj/6IjVNO58fp8zly6kTaeoPbTldu6WJ2UzXxMj03ICLjS741iB+4+5JcK9x9wQjGM3oMNjE1zoNL7wBP88u1M4ise5Vjpk/kvhVbAFi9vZtDJ43RITZERPYi38kLjjSzusEXZlZvZp8qTEijxGATU1kc5p0Bh76LV9oTTJ1YyaQJcTr6kqTSGVpa+zi4saq4sYqIFEC+CeJj7t4++MLd24CPFSSi0WLwyeXoayOXrm/t5eDGKuqqysk4rNrWTSKdYUaDEoSIjD/5JoioZc2EY2ZRYHyP+ZxdgwDcnVd39HBwYxUN1cGw3s+3BENszKzXXUgiMv7k2wfxe+B2M7s+fP3xsGz82lWDCBLE9q4B2nqTHDq5lrqqIDc+29IOwEGqQYjIOJRvgvgSQVL4ZPj6fuDGgkQ0WoQJYk1bgvqeBC9t6QLgsCm1VJcHf7bnWjowg+mqQYjIOJTvg3IZ4D/Cn9IQNjF9ZdHLHL7lYKbXBUng8CkT6O5PAcEorlMmVOgWVxEZl/Idi2ke8M/AkUDFYLm7zylQXMUX1iB60lGea2mnqz/FpNo4DdXllEVfe2JazUsiMl7l28T0n8DXgH8DTiMYlynfDu6xKaxBJChj9eYu+pIZDpsSPO9QG3/tz3bsjAJNEiQiUmT5XuQr3f0PgLn7Onf/OnBO4cIaBcIaRNJi9CXTvLi5k/kz6wDIuqGLvzl1/FaiRKS05VuDGDCzCLDKzK4ENjJeh9gYFNYgjj14EmtfCcbhu2jBayOufnDhQTTXxpkysWK4I4iIjGn5JojPEozD9LfAPxI0M11eqKBGA08nMODQaY1UtHRy8twmZmb1N/zze48pXnAiIgfAPpuYwofiLnb3bndvcfePuPv73P2xPPY9y8xWmtlqM7sqx/q3mdlTZpYys/cPWZc2s2fCn0X7dVYjIJ0MahDl8Qpu/uhblBBEpOTsswbh7mkzO2V/DxwmlmuBM4EWYKmZLXL3FVmbrQc+DHwhxyH63H3+/r7vSMkk+wGIxipYMEvTfopI6cm3ienp8Fv8L4GewUJ3//Ve9lkIrHb3tQBmdhtwPrArQbj7q+G6UTeN6WANIlI2vkcUEREZTr4JogLYCfxFVpkDe0sQ04ENWa9bgLfsR2wVZrYMSAHfcvffDN3AzK4ArgA46KCD9uPQ+5ZJ9pN2o6xcCUJESlO+T1J/pNCB5HCwu280sznAH83seXdfMySuG4AbABYsWOAj+eaZ1AAJYsSi4/txDxGR4eT7JPV/EtQYduPuf72X3TYCM7NezwjL8uLuG8Pfa83sQeA4YM1edxpBnhwgQRnlShAiUqLybWK6J2u5ArgQ2LSPfZYC88xsNkFiuAS4NJ83M7N6oNfdB8ysCTgZ+E6esY4ITyVIUKYahIiUrHybmH6V/drMbgX+vI99UuFDdfcCUeAmd19uZtcAy9x9kZmdANwF1APnmtk33P0o4Ajg+rDzOkLQB7FimLcqiNeamGzfG4uIjEP51iCGmgdM2tdG7r4YWDyk7Oqs5aUETU9D93sEKO6DB6kBEl5GrEw1CBEpTfn2QXSxex/EFoI5IsYtTydIEFMfhIiUrHybmGoLHciokxpQH4SIlLS8rn5mdqGZTcx6XWdmFxQsqtFAfRAiUuLy/Xr8NXfvGHzh7u0E80OMW5ZJklQNQkRKWL5Xv1zbvd4O7rEhnSDhZZSrk1pESlS+V79lZvY9M5sb/nwPeLKQgRWbpQcYIEZZRE1MIlKa8k0QnwESwO3AbUA/8OlCBTUaRNJ6UE5ESlu+dzH1AHvM5zCe2eBtrmpiEpESle9dTPebWV3W63ozu7dgUY0CkUyChGuwPhEpXfle/ZrCO5cAcPc28niSeiyLZJIkieo2VxEpWfkmiIyZ7ZpwwcxmkWN01/EkkklouG8RKWn53qr6FeDPZvYQYMCphBP1jFfRTFIJQkRKWr6d1L83swUESeFp4DdAXwHjKrqoJ0lZGVHd5ioiJSrfwfr+BvgswcirzwAnAo+y+xSk40cmg+G4RYsdiYhI0eTbfvJZ4ARgnbufRjC7W3uhgio6Twe/IuP7YXERkb3JN0H0u3s/gJnF3f0l4LDChVVkmRQAphqEiJSwfL8it4TPQfwGuN/M2oB1hQqq6DJBDYKIEoSIlK58O6kvDBe/bmZLgInA7wsWVbGFTUwW0R1MIlK69ruR3d0fKkQgo0pGfRAiIvqKnEuYICJKECJSwpQgcnH1QYiIKEHkkhnsg1CCEJHSpQSRy+BtrmpiEpESpgSRy+BdTFHVIESkdClB5JLJAOqkFpHSVtAEYWZnmdlKM1ttZnvMSGdmbzOzp8wsZWbvH7LucjNbFf5cXsg49zDYxKQahIiUsIIlCAvGqbgWOBs4EvigmR05ZLP1wIeBW4bs2wB8DXgLsBD4mpnVFyrWPex6UE41CBEpXYWsQSwEVrv7WndPALcB52dv4O6vuvtzQGbIvu8C7nf31nD2uvuBswoY6+7Cu5iiuotJREpYIRPEdGBD1uuWsGzE9jWzK8xsmZkt2759++sOdA+7OqljI3dMEZExZkx3Urv7De6+wN0XNDc3j9yBB5+kLlMNQkRKVyETxEZgZtbrGWFZofd943YNtaEEISKlq5AJYikwz8xmm1k5cAmwKM997wXeaWb1Yef0O8OyAyNsYoqoiUlESljBEoS7p4ArCS7sLwJ3uPtyM7vGzM4DMLMTzKwF+ABwvZktD/dtBf6RIMksBa4Jyw4ITycBiOg2VxEpYQW9j9PdFwOLh5RdnbW8lKD5KNe+NwE3FTK+4SRTKcqB8lh5Md5eRGRUGNOd1IUykAhqEPFyPQchIqVLCSKH/l0JIl7kSEREikcJIoeBRAKAeLk6qUWkdClB5DCYICrjShAiUrqUIHJIJIMmpoq4mphEpHQpQeTwWie1ahAiUrqUIHJIhAmiKq7bXEWkdClB5JDc1cSkBCEipUsJIodEKkgQ1RUVRY5ERKR4lCByGKxB6EE5ESllShA5DCYIzSgnIqVMCSKHZDKYkxolCBEpYUoQOaRSwYNymP48IlK6dAXMIZUK5oNAEwaJSAlTgsghGd7FhClBiEjpUoLIIZ1WH4SIiBJEDpnUYIJQDUJESpcSRA6pwQShJiYRKWFKEDmk0ykcg4j+PCJSunQFHOJ/V+8gk06S0S2uIlLidBUEWnuC5x66B1J85L+WUl8R1VPUIlLySj5BbGjt5R3/soR/XvwiKzZ1kkhlOGlOPRF1UItIiSv5r8nNtXHOfdM0rv/TWh56eTsADVVR3eIqIiWv5GsQFbEo37zwGOY2V/PSli4qY1FqY2iYDREpeboKhk45pAmAQyfXYJ7RMxAiUvIKmiDM7CwzW2lmq83sqhzr42Z2e7j+cTObFZbPMrM+M3sm/LmukHECnLQrQdSCp9XEJCIlr2BXQTOLAtcCZwItwFIzW+TuK7I2+yjQ5u6HmNklwLeBi8N1a9x9fqHiG+rEOY3UVpSxYFY9bErpITkRKXmF/Jq8EFjt7msBzOw24HwgO0GcD3w9XL4T+JGZWQFjGtbEyhiPfvl0qmJRaFETk4hIIZuYpgMbsl63hGU5t3H3FNABNIbrZpvZ02b2kJmdmusNzOwKM1tmZsu2b9/+hgOuiZcRiVjQxKROahEpcaP1KrgZOMjdjwP+DrjFzCYM3cjdb3D3Be6+oLm5eeTePaM+CBGRQiaIjcDMrNczwrKc25hZGTAR2OnuA+6+E8DdnwTWAIcWMNbdZVJqYhKRklfIBLEUmGdms82sHLgEWDRkm0XA5eHy+4E/urubWXPYyY2ZzQHmAWsLGOvuPK1OahEpeQVrR3H3lJldCdwLRIGb3H25mV0DLHP3RcBPgZ+b2WqglSCJALwNuMbMkkAG+IS7txYq1j1kMmpiEpGSV9CroLsvBhYPKbs6a7kf+ECO/X4F/KqQse1VJqWhvkWk5OkqmIuamERElCByyqTVSS0iJU8JIpdMSn0QIlLylCBy8YyamESk5ClB5JJJq5NaREqeroK5aDRXEREliJwyGs1VREQJIhfdxSQiogSRkzqpRUSUIHLSYH0iIkoQOamJSURECSInDbUhIqIEkZMmDBIRUYLISU1MIiJKEDlpTmoRESWInFSDEBFRgshJo7mKiChB5KS7mERElCByymTUxCQiJU8JIhdXH4SIiBIEQDoFv/08rP5D8FqjuYqIKEEAsOkpWHoj3PxeWLNEdzGJiKAEEVj7UPC7ehL8+mPqpBYRQQki8MpDMPkY+Ku7ob8zKFMNQkRKnBJEsg82PAFz3g6Tj4RPPgIn/S0cdWGxIxMRKaqCJggzO8vMVprZajO7Ksf6uJndHq5/3MxmZa37cli+0szeVbAg+zvhiHNh3juD102HwDv/EZoPK9hbioiMBQV7XNjMosC1wJlAC7DUzBa5+4qszT4KtLn7IWZ2CfBt4GIzOxK4BDgKmAY8YGaHunt6xAOtnQzv/+mIH1ZEZKwrZA1iIbDa3de6ewK4DTh/yDbnAz8Ll+8ETjczC8tvc/cBd38FWB0eT0REDpBCJojpwIas1y1hWc5t3D0FdACNee6LmV1hZsvMbNn27dtHMHQRERnTndTufoO7L3D3Bc3NzcUOR0RkXClkgtgIzMx6PSMsy7mNmZUBE4Gdee4rIiIFVMgEsRSYZ2azzaycoNN50ZBtFgGXh8vvB/7o7h6WXxLe5TQbmAc8UcBYRURkiILdxeTuKTO7ErgXiAI3uftyM7sGWObui4CfAj83s9VAK0ESIdzuDmAFkAI+XZA7mEREZFgWfGEf+xYsWODLli0rdhgiImOKmT3p7gtyrRvTndQiIlI446YGYWbbgXVv4BBNwI4RCqfYxsu5jJfzAJ3LaKVzgYPdPedtoOMmQbxRZrZsuGrWWDNezmW8nAfoXEYrncveqYlJRERyUoIQEZGclCBec0OxAxhB4+Vcxst5gM5ltNK57IX6IEREJCfVIEREJCclCBERyankE8S+Zr0b7czsVTN73syeMbNlYVmDmd1vZqvC3/XFjjMXM7vJzLaZ2QtZZTljt8APws/pOTN7c/Ei39Mw5/J1M9sYfjbPmNm7s9YdmBkTXwczm2lmS8xshZktN7PPhuVj6rPZy3mMuc/FzCrM7AkzezY8l2+E5bPD2ThXh7Nzloflw87WuV/cvWR/CMaIWgPMAcqBZ4Ejix3Xfp7Dq0DTkLLvAFeFy1cB3y52nMPE/jbgzcAL+4odeDfwO8CAE4HHix1/HufydeALObY9Mvy3Fgdmh/8Go8U+h6z4pgJvDpdrgZfDmMfUZ7OX8xhzn0v4t60Jl2PA4+Hf+g7gkrD8OuCT4fKngOvC5UuA21/P+5Z6DSKfWe/GouyZ+n4GXFC8UIbn7n8iGKQx23Cxnw/8twceA+rMbOoBCTQPw5zLcEb1jInuvtndnwqXu4AXCSbsGlOfzV7OYzij9nMJ/7bd4ctY+OPAXxDMxgl7fia5ZuvcL6WeIPKauW6Uc+A+M3vSzK4Iyya7++ZweQswuTihvS7DxT5WP6srw2aXm7Ka+sbMuYRNE8cRfGMds5/NkPOAMfi5mFnUzJ4BtgH3E9Rw2j2YjRN2j3e42Tr3S6kniPHgFHd/M3A28Gkze1v2Sg/qmGPyXuaxHHvoP4C5wHxgM/Ddokazn8ysBvgV8Dl378xeN5Y+mxznMSY/F3dPu/t8ggnUFgKHF/o9Sz1BjPmZ69x9Y/h7G3AXwT+crYNV/PD3tuJFuN+Gi33MfVbuvjX8T50BfsJrzRWj/lzMLEZwUf2Fu/86LB5zn02u8xjLnwuAu7cDS4C3EjTnDc7rkx3vcLN17pdSTxD5zHo3aplZtZnVDi4D7wReYPeZ+i4H7i5OhK/LcLEvAv4qvGPmRKAjq7ljVBrSDn8hwWcDo3zGxLCt+qfAi+7+vaxVY+qzGe48xuLnYmbNZlYXLlcCZxL0qSwhmI0T9vxMcs3WuX+K3Ttf7B+COzBeJmjP+0qx49nP2OcQ3HXxLLB8MH6CtsY/AKuAB4CGYsc6TPy3ElTxkwTtpx8dLnaCuziuDT+n54EFxY4/j3P5eRjrc+F/2KlZ238lPJeVwNnFjn/IuZxC0Hz0HPBM+PPusfbZ7OU8xtznAhwLPB3G/AJwdVg+hyCJrQZ+CcTD8orw9epw/ZzX874aakNERHIq9SYmEREZhhKEiIjkpAQhIiI5KUGIiEhOShAiIpKTEoTIKGBm7zCze4odh0g2JQgREclJCUJkP5jZZeG4/M+Y2fXhAGrdZvZv4Tj9fzCz5nDb+Wb2WDgo3F1Z8yccYmYPhGP7P2Vmc8PD15jZnWb2kpn94vWMvikykpQgRPJkZkcAFwMnezBoWhr4S6AaWObuRwEPAV8Ld/lv4EvufizBk7uD5b8ArnX3NwEnETyBDcFoo58jmJdgDnBygU9JZK/K9r2JiIROB44HloZf7isJBqzLALeH29wM/NrMJgJ17v5QWP4z4Jfh2FnT3f0uAHfvBwiP94S7t4SvnwFmAX8u+FmJDEMJQiR/BvzM3b+8W6HZV4ds93rHrxnIWk6j/59SZGpiEsnfH4D3m9kk2DVH88EE/48GR9S8FPizu3cAbWZ2alj+IeAhD2Y2azGzC8JjxM2s6kCehEi+9A1FJE/uvsLM/oFgBr8IwcitnwZ6gIXhum0E/RQQDLd8XZgA1gIfCcs/BFxvZteEx/jAATwNkbxpNFeRN8jMut29pthxiIw0NTGJiEhOqkGIiEhOqkGIiEhOShAiIpKTEoSIiOSkBCEiIjkpQYiISE7/H5zrwgu416lOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.25, random_state=42)\n",
    "\n",
    "y_test_pred=loaded_model.predict(x_test)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test[:,0]\n",
    "y_test_pred=y_test_pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "savetxt('ARRAY_DATA/gru_y_test_pred.csv', y_test_pred[:1001], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "savetxt('ARRAY_DATA/gru_y_test.csv', y_test[:1001], delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
